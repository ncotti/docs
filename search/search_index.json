{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"My docs","text":"<p>Placeholder text.</p> <p>Based on</p>"},{"location":"about/","title":"About","text":"<p>About what anyways?</p>"},{"location":"arm_assembly/","title":"ARM Assembly","text":"<p>In this section an overview of the ARM Cortex architecture and the ISA (Instruction Set Architecture) will be provided.</p> <p>First, the tools required to compile and analyze assembly files are explained in the Binutils section.</p> <p>Then, the assembly directives, instructions and interruptions are explained, and how to combine assembler and C instructions with the ABI.</p> <p>Also, more advanced topics such as SIMD and pagination are explained.</p>"},{"location":"arm_assembly/abi/","title":"ABI: Application Binary Interface","text":"<p>The ABI is the standard way to communicate assembly code with higher level languages like C, and dictates how the latter will be compiled into binary.</p> <p>A practical example is provided in this repo.</p>"},{"location":"arm_assembly/abi/#register-usage","title":"Register usage","text":"<p>To be able to call a C function from assembly and vice versa, the registers must follow the convention showed on the following image, and described in the ARM ABI page.</p> <ul> <li><code>r0-r3</code>: Arguments of the function (up to four). r0 may be used as return vale. The user must always assume that these values were changed after the function call, and may be freely used inside the function (Caller saved registers).</li> <li><code>r4-r11</code>: Local variables. Inside the function, this values should be stored and retrieved, leaving them unmodified. (Function saved registers).</li> <li><code>r12 (ip)</code>: Intra-procedure scratch register. If the branch instruction is too far away (more than 32 MBytes in memory), the assembler will create a veneer, an intermediate space in memory to jump to reach that place, whose address will be stored in R12. The value of \"r12\" could be overwritten after every \"branch\" instruction (scratch register), and is the responsibility of the caller to preserve it's value. (Caller saved register).</li> <li><code>r13 (sp)</code>: The stack pointer should not be modified inside a function execution. (Function saved).</li> <li><code>r14(lr)</code>: The immediate instruction after the function call is saved in this register; therefore, the link register should be loaded into the program counter at the end of the function's execution to return from it. If another function were to be called inside it, the value of the lr would be overwritten. Because of that, the lr should always be stored in the stack at the beginning of the function call. (Function saved).</li> <li><code>r15(pc)</code>: The value of the lr should be loaded in the pc at the end of the function execution.</li> </ul> <p></p>"},{"location":"arm_assembly/abi/#stack-alignment","title":"Stack alignment","text":"<p>Following the C ABI, the stack address should have an 8 byte alignment before entering a function.</p> <p>The only registers that should be preserved are the four arguments and the scratch register <code>{r0-r3, r12}</code>. However, they occupy 20 bytes, breaking the \"8 byte alignment of the stack\". The easiest and fastest way to fix this is to store an additional \"mock\" register, to have an even number of 4 byte registers stored, and keeping the 8 byte alignment.</p> <p>If all the registers's values want to be preserved, a standard C function call looks like this:</p> <pre><code>push {r0-r3, r4, r12}   // Store modifiable registers, and mock \"r4\"\nldr r0, =arg1           // Load first argument\nldr r1, =arg2           // Load second argument\n//[...]\nbl c_function           // Go to \"C\" function\npop {r0-r3, r4, r12}    // Retrieve old registers\n</code></pre>"},{"location":"arm_assembly/abi/#calling-a-c-function-from-assembly","title":"Calling a C function from Assembly","text":"<p>C code is compiled in Thumb mode by default (16-bit instructions), but it can be changed with the <code>-marm</code> or <code>-mthumb</code> compiler flags.</p> <p>When calling a C function from assembly, these steps must be followed:</p> <ol> <li> <p>Caller saved registers. Store r0, r1, r2, r3, r12 and lr. The stack must remain with 8byte alignment.</p> </li> <li> <p>Load the first four arguments in r0, r1, r2 and r3 respectively. If the argument has 8 bytes, it should be loaded into r0:r1 or r2:r3. If the argument is a struct, its components should be stored one by one as if they were individual arguments.</p> </li> <li> <p>If the function has more than four arguments, the rest must be loaded on the stack. The fifth argument should be at the lowest memory address, and the last argument at the highest address (this is done by default using a register list with the <code>push</code> instruction). No matter the variable size, the stack operation is always word sized.</p> </li> <li> <p>Call the function with a <code>bl &lt;function_name&gt;</code> instruction (the link register should be updated).</p> </li> <li> <p>The return value will be stored in r0 if it has 4 bytes, in r0:r1 if it hast 8 bytes, or in r0:r1:r2:r3 if it has 16 bytes.</p> </li> <li> <p>After execution, clear the stack by popping the same amount of registers that were pushed, or incrementing it's value according to the amount of arguments greater than four loaded in the stack.</p> </li> </ol> <pre><code>// Assembly file\n.global _start\n.extern _stack_addr // Defined in the linker script\n.extern add9        // defined in C file, 9 arguments.\n.text\n_start:\n    ldr sp, =_stack_addr    // Initializing stack pointer\n    mov r0, #1              // Initializing arguments.\n    mov r1, #2\n    mov r2, #3\n    mov r3, #4\n    mov r4, #5\n    mov r5, #6\n    mov r6, #7\n    mov r7, #8\n    mov r8, #9\n    push {r4-r8, r12} // Pushing arguments 5 to 9 into the stack\n    blx add9  // r0= 1 + 2*2 + 3*3 + 4*4 + 5*5 + 6*6 + 7*7 + 8*8 + 9*9 = 285\n    pop {r4-r8, r12} // or use: \"add sp, sp, #24\"\n</code></pre> <pre><code>// Function declared in C\nint add9(int a, short b, char c, int d, int e, int f, unsigned int g,\n    unsigned char h, int i) {\n    return a + 2*b + 3*c + 4*d + 5*e + 6*f + 7*g + 8*h + 9*i;\n}\n</code></pre>"},{"location":"arm_assembly/abi/#calling-an-assembly-function-from-c","title":"Calling an Assembly function from C","text":"<p>Function prototypes and data types are a concept from the C programming language, not from assembly. Therefore, the prototype must be created using the <code>extern</code> keyword, and the data types must be arbitrarily chosen.</p> <pre><code>// C file\n\n// Define the prototype from the assembly function\nextern int add6_from_asm(int a, char b, char c, int d, int e, char f);\n\nint main (void) {\n    add6_from_asm(3, 5, 7, 9, 11, 13);   // Call the function\n}\n</code></pre> <p>These considerations must be followed when writing the assembly function:</p> <ul> <li> <p>The function must be global with: <code>.global &lt;function_name&gt;</code>.</p> </li> <li> <p>Remember to add the <code>.type &lt;function_name&gt;, %function</code> directive, or it won't work properly.</p> </li> <li> <p>First four parameters are stored in registers <code>{r0-r3}</code></p> </li> <li> <p>Return value should be loaded in <code>r0</code>.</p> </li> <li> <p>If the function has more than four arguments, they must be saved on the stack, buy remember that the stack pointer shouldn't be modified. Therefore, you can't use the <code>pop {}</code> instruction to retrieve them. You must instead access the parameters manually. Therefore, the fifth argument is obtained with <code>ldr r1, [sp]</code>, the second with <code>ldr r1, [sp, #4]</code>, and so on.</p> </li> <li> <p>Remember that registers r4-r11 must be left untouched.</p> </li> </ul> <pre><code>.text\n.type add6_from_asm, %function // MANDATORY, or won't work\n.global add6_from_asm\nadd6_from_asm:\n    add r0, r0, r1\n    add r0, r0, r2\n    add r0, r0, r3\n    ldr r1, [sp]        // Access argument 5\n    add r0, r0, r1\n    ldrb r1, [sp, #4]   // Access argument 6, it's a char, 1 byte\n    add r0, r0, r1\n    mov pc, lr\n</code></pre>"},{"location":"arm_assembly/abi/#using-variables-from-assembly-in-c","title":"Using variables from Assembly in C","text":"<p>The variables in the assembly file must be defined with <code>.global</code>; while in the C file they must be declared using <code>extern</code> and given a type.</p> <pre><code>.data\n.global var_from_asm\n.global vector_from_asm\nvar_from_asm: .word 5\nvector_from_asm: .word 0, 1, 2, 3, 4, 5\n</code></pre> <pre><code>extern int var_from_asm;\nextern int vector_From_asm[6];\n\nvar_from_asm += 5;\n</code></pre>"},{"location":"arm_assembly/abi/#using-variables-from-c-in-assembly","title":"Using variables from C in Assembly","text":"<p>Variables in C must be defined globally.</p> <pre><code>int var_from_c = 25;\n</code></pre> <pre><code>.extern var_from_c\n.text\nldr r0, =var_from_c\nldr r1, [r0]        // r1 = 25\nadd r1, r1, #5\nstr r1, [r0]        // var_from_c = 30\n</code></pre>"},{"location":"arm_assembly/abi/#using-header-files-h-in-assembler","title":"Using header files \".h\" in assembler","text":"<p>To include a header file in asm, some special considerations must be taken care of:</p> <ul> <li>You can't use the Assembler (as) alone to compile the assembly code. You must use the C preprocessor (cpp) and later the assembler code as follows:</li> </ul> <pre><code>cpp foo.s | as -o foo.o -\n</code></pre> <ul> <li>You can use the C compiler (gcc), but the assembly files must end with a mayus \".S\". Besides, the C header file must be included with a <code>#include</code>, and only have C preproccessor directives (for example, function prototypes or C variable types are not allowed).</li> </ul> <p>Note: linker variables, when accessed from C, are seen as addresses always.</p> <p>For example, this definition: ld_size = 0x1000; Will be interpreted as a variable in the address 0x1000, with unknown contents.</p> <p>Note: I had a weird bug trying to access the VMA from the linker script inside C. FIXED. If more than one symbol has the same value, then ALL of them will have a value of \"0\" from C (not from assembly).</p>"},{"location":"arm_assembly/abi/#attribute-syntax","title":"Attribute syntax","text":"<p>The <code>__attribute__(())</code> syntax allows to set assembly directives for the C functions and variables.</p> <pre><code>__attribute__((&lt;option&gt;)) target\nextern int __attribute__((aligned(16))) i = 0;    // This variable will be aligned to a multiple of 16.\nint __attribute__((section(\".text\"))) foo (void); // This function will be written to the \".text\" section.\n</code></pre> <p>The complete list of attributes can be view from the GCC manual.</p>"},{"location":"arm_assembly/abi/#inline-assembly-in-c","title":"Inline Assembly in C","text":"<p>Inline assembly allows to access the registers directly, or do some hardware specific instruction like changing operating mode with <code>cps</code>, or putting the processor in idle state with <code>wfi</code>. Only one line of assembly can be written at a time, and <code>\"\"</code> must be used.</p> <pre><code>asm volatile(\"mov r0, #25\");\n</code></pre> <p>It's not possible to access a local variable from a function using inline assembly, but it's possible to access a global variable. That's because local variables are stored in registers or the stack, and do not have a fixed memory address (therefore \"=a\" is not a valid address). Meanwhile, global variables are fixed, and it's location is known at compile time.</p> <pre><code>int b = 25;\nvoid foo(void) {\n    int a = 25;\n    // asm volatile (\"ldr r0, =a\"); This won't work\n    asm volatile(\"ldr r0, =b\");\n    asm volatile(\"ldr r0, [r0]\");    // r0 = 25\n}\n</code></pre>"},{"location":"arm_assembly/avr/","title":"AVR","text":"<p>The AVR 8 bit processors architecture is described in the datasheet of the Microcontroller itself.</p> <p>Therefore, for Arduino boards, we will be looking at the ATMEGA328P Datasheet</p> <p>AVR Instruction Set Manual</p>"},{"location":"arm_assembly/avr/#avr-architecture","title":"AVR Architecture","text":"<p>The architecture is quite similar to ARM's architecture.</p> <p>The register file is composed of 32 8-bit registers, from R0 to R31. Memory addresses are 16-bit long.</p> <p></p> <p>There are 3 couples of special registers, the X-register, Y-register and Z-register that are designed specially to address memory spaces, where one of them is the 8 MSB bits and the other the 8 LSB bits.</p> <p></p> <p>The stack pointer is also implemented as two pairs of 8-bit registers:</p> <p></p>"},{"location":"arm_assembly/avr/#reset-vector","title":"Reset vector","text":"<p>On Section 11, Interrupts we have the Reset and Interrupt vector for the ATmega328P.</p> <p>I DONT THINK I WILL EVER USE THIS. ABORT AVR ANALYSIS FOR NOW.</p>"},{"location":"arm_assembly/binutils/","title":"The GNU Binutils","text":"<p>When calling the GNU C Compiler (GCC), a lot of steps are done for us under the hood. Let's review all these steps, and see the information the binary files have to offer with the GNU Binutils.</p> <p></p> <p>All the steps described below can be conveniently executed from the script buildutils.sh provided in this repo.</p>"},{"location":"arm_assembly/binutils/#1-c-preprocessor-cpp","title":"1. C preprocessor (cpp)","text":"<p>The preprocessor handles all the so called \"preprocessor directives\", which include:</p> <ul> <li> <p><code>#define</code>: macro replacement.</p> </li> <li> <p><code>#include</code>: copying the literal contents of the header file inside the source file.</p> </li> <li> <p>Remove all comments.</p> </li> <li> <p><code>#ifdef | #endif</code>: Conditional compiling.</p> </li> </ul> <pre><code>arm-linux-gnueabihf-cpp main.c &gt; build/main.i\n</code></pre> <p>Check the file generated <code>main.i</code>, and see the changes made in the file.</p>"},{"location":"arm_assembly/binutils/#2-the-gnu-c-compiler-gcc","title":"2. The GNU C Compiler (gcc)","text":"<p>The gcc then parses the C code into Assembly code. In our case, it's ARM assembly.</p> <pre><code>arm-linux-gnueabihf-gcc -S -o build/main.s build/main.i\n</code></pre>"},{"location":"arm_assembly/binutils/#3-the-assembler-as","title":"3. The Assembler (as)","text":"<p>It creates an object file based on the assembly code.</p> <pre><code>arm-linux-gnueabihf-as -o build/main.o build/main.s\n$ file build/main.o\n    build/main.o: ELF 32-bit LSB relocatable, ARM, EABI5 version 1 (SYSV), not stripped\n</code></pre> <p>See that the type of the file is ELF (Executable and Linkable Format), for 32-bit ARM processors.</p>"},{"location":"arm_assembly/binutils/#4-the-linker-ld","title":"4. The linker (ld)","text":"<p>It locates the code in the corresponding memory regions, and generates the final executable file.</p> <pre><code>arm-linux-gnueabihf-ld -o build/main.elf build/main.o\n$ file build/main.elf\n    build/main.elf: ELF 32-bit LSB executable, ARM, EABI5 version 1 (SYSV), statically linked, not stripped\n</code></pre> <p>You may specify the option <code>-Map &lt;map_file&gt;</code> to print a \"map file\", which is a description of the memory addresses.</p> <p>Normally, preprocessing, compiling, assembling and even linking can be done all together with a single call to the GCC.</p>"},{"location":"arm_assembly/binutils/#binary-files-inspection-and-modification-tools","title":"Binary files inspection and modification tools","text":"<p>So far, we have built two ELF files (Executable and Linkable Format): the object file (.o), and the executable file (.elf). Now, let's see what information they provide and how to obtain it.</p>"},{"location":"arm_assembly/binutils/#display-information-of-elf-files-objdump","title":"Display information of ELF files (objdump)","text":"<p><code>objdump</code> is a powerful command that encompasses the functionality of various, more specific, commands, such as:</p> <ul> <li><code>readelf</code>: for reading ELF headers.</li> <li><code>size</code>: for reading assembly regions sizes (.text, .data, etc).</li> <li><code>nm</code>:  for listing the symbol table.</li> </ul> <p>The contents of an ELF file are:</p> <ul> <li> <p>ELF file header: includes file type (ELF32), data endianness, machine (ARM), and operating system (UNIX).</p> </li> <li> <p>Program headers: they show the memory address where code will be loaded.</p> </li> <li> <p>Section headers: shows all the assembly sections (.text, .bss, .data, etc), with their address, size and offset.</p> </li> <li> <p>Symbol table: shows all symbols defined in the file. This is specially useful when the linker has to merge several files together, so it can search for a function or global variable in that object file.</p> </li> </ul> <pre><code>$ arm-linux-gnueabihf-objdump -x build/main.elf\n\nbuild/main.elf:     file format elf32-littlearm\nbuild/main.elf\narchitecture: arm, flags 0x00000112:\nEXEC_P, HAS_SYMS, D_PAGED\nstart address 0x00010094\n\nProgram Header:\n    LOAD off    0x00000000 vaddr 0x00010000 paddr 0x00010000 align 2**16\n         filesz 0x000000d0 memsz 0x000000d0 flags r-x\n    LOAD off    0x000000d0 vaddr 0x000200d0 paddr 0x000200d0 align 2**16\n         filesz 0x00000004 memsz 0x00000004 flags rw-\n   STACK off    0x00000000 vaddr 0x00000000 paddr 0x00000000 align 2**4\n         filesz 0x00000000 memsz 0x00000000 flags rw-\nprivate flags = 5000400: [Version5 EABI] [hard-float ABI]\n\nSections:\nIdx Name          Size      VMA       LMA       File off  Algn\n  0 .text         0000003c  00010094  00010094  00000094  2**2\n                  CONTENTS, ALLOC, LOAD, READONLY, CODE\n  1 .data         00000004  000200d0  000200d0  000000d0  2**2\n                  CONTENTS, ALLOC, LOAD, DATA\n  2 .comment      00000024  00000000  00000000  000000d4  2**0\n                  CONTENTS, READONLY\n  3 .ARM.attributes 00000033  00000000  00000000  000000f8  2**0\n                  CONTENTS, READONLY\nSYMBOL TABLE:\n00010094 l    d  .text  00000000 .text\n000200d0 l    d  .data  00000000 .data\n00000000 l    d  .comment       00000000 .comment\n00000000 l    d  .ARM.attributes        00000000 .ARM.attributes\n00000000 l    df *ABS*  00000000 main.c\n000200d0 g     O .data  00000004 global_var\n000200d4 g       .data  00000000 _bss_end__\n000200d4 g       .data  00000000 __bss_start__\n000100b4 g     F .text  0000001c add\n000200d4 g       .data  00000000 __bss_end__\n000200d4 g       .data  00000000 __bss_start\n00010094 g     F .text  00000020 main\n000200d4 g       .data  00000000 __end__\n000200d4 g       .data  00000000 _edata\n000200d4 g       .data  00000000 _end\n</code></pre> <p>This command can also act as a disassembler, showing the assembly instructions and their position in memory.</p> <pre><code>$ arm-linux-gnueabihf-objdump -d build/main.elf\n\nbuild/main.elf:     file format elf32-littlearm\nDisassembly of section .text:\n\n00010094 &lt;main&gt;:\n   10094:       b580            push    {r7, lr}\n   10096:       b082            sub     sp, #8\n   10098:       af00            add     r7, sp, #0\n   1009a:       230a            movs    r3, #10\n   1009c:       607b            str     r3, [r7, #4]\n   1009e:       230f            movs    r3, #15\n   100a0:       603b            str     r3, [r7, #0]\n   100a2:       6839            ldr     r1, [r7, #0]\n   100a4:       6878            ldr     r0, [r7, #4]\n   100a6:       f000 f805       bl      100b4 &lt;add&gt;\n   100aa:       2300            movs    r3, #0\n   100ac:       4618            mov     r0, r3\n   100ae:       3708            adds    r7, #8\n   100b0:       46bd            mov     sp, r7\n   100b2:       bd80            pop     {r7, pc}\n\n000100b4 &lt;add&gt;:\n   100b4:       b480            push    {r7}\n   100b6:       b083            sub     sp, #12\n   100b8:       af00            add     r7, sp, #0\n   100ba:       6078            str     r0, [r7, #4]\n   100bc:       6039            str     r1, [r7, #0]\n   100be:       687a            ldr     r2, [r7, #4]\n   100c0:       683b            ldr     r3, [r7, #0]\n   100c2:       4413            add     r3, r2\n   100c4:       4618            mov     r0, r3\n   100c6:       370c            adds    r7, #12\n   100c8:       46bd            mov     sp, r7\n   100ca:       f85d 7b04       ldr.w   r7, [sp], #4\n   100ce:       4770            bx      lr\n</code></pre>"},{"location":"arm_assembly/binutils/#discard-symbols-from-object-files-strip","title":"Discard symbols from object files (strip)","text":"<p>The <code>strip</code> command will erase the symbol table from the binary. This is used before shipping a binary to a client to reduce it's size and obscure information about the code (the symbol table is needed only for linking, not for execution).</p> <pre><code># Before stripping, file size = 1064 and symbol table can be found\n$ ls -l build/main.elf\n    -rwxrwxr-x 1 cotti cotti 1064 abr 13 16:44 build/main.elf\n\n$ arm-linux-gnueabihf-objdump -t build/main.elf\n    build/main.elf:     file format elf32-littlearm\n    SYMBOL TABLE:\n    00010094 l    d  .text  00000000 .text\n    000200d0 l    d  .data  00000000 .data\n    ...\n    000200d4 g       .data  00000000 _end\n\n# After stripping, file size = 588, and no symbol table\narm-linux-gnueabihf-strip build/main.elf\n$ ls -l build/main.elf\n    -rwxrwxr-x 1 cotti cotti 588 abr 13 16:46 build/main.elf\n\n$ arm-linux-gnueabihf-objdump -t build/main.elf\n    build/main.elf:     file format elf32-littlearm\n    SYMBOL TABLE:\n    no symbols\n</code></pre>"},{"location":"arm_assembly/binutils/#get-a-binary-file-with-no-information-objcopy","title":"Get a binary file with no information (objcopy)","text":"<p>Files that have the <code>.elf</code> extension have all the headers and symbol tables, which might be useful for loading the code in hardware or execute it later. Files that have the <code>.bin</code> extension had all these information purposefully removed, as well as its code and data cramped together starting from the address 0x00.</p> <pre><code>arm-linux-gnueabihf-objcopy -O binary build/main.elf build/main.bin\n$ file build/main.bin\n    build/main.bin: data\n\n$ ls -l build\n-rwxrwxr-x 1 cotti cotti 65600 abr 13 17:23 main.bin\n-rwxrwxr-x 1 cotti cotti  1064 abr 13 17:20 main.elf\n</code></pre> <p>The final <code>.bin</code> file is larger than it's <code>.elf</code> counterpart, even though header information was removed. Looking again at the section's header, we can see that the address (LMA) of the <code>.text</code> section is 0x10094, and the address of the <code>.data</code> is at 0x200d0, roughly 65500 KBytes apart. What we did was to move the address of the <code>.text</code> section to 0x00, and then keep the 65500 KBytes separation for the <code>.data</code>, filling the file with just \"0\".</p> <pre><code>Sections:\nIdx Name          Size      VMA       LMA       File off  Algn\n  0 .text         0000003c  00010094  00010094  00000094  2**2\n                  CONTENTS, ALLOC, LOAD, READONLY, CODE\n  1 .data         00000004  000200d0  000200d0  000000d0  2**2\n                  CONTENTS, ALLOC, LOAD, DATA\n</code></pre>"},{"location":"arm_assembly/cortex-m/","title":"Cortex-M","text":"<p>Based on the ARMv7-M Architecture Reference Manual.</p> <p>A4.1: \"Armv7-M only supports Thumb instructions\" (either thumb or thumb2).</p> <p>B.1.3.1</p> <p>Supports two operating modes:</p> <ul> <li> <p>Thread Mode: Is entered on reset, and can be entered as a result of an exception return. Privileged or unprivileged.</p> </li> <li> <p>Handler Mode: Is entered as a result of an exception. Always privileged.</p> </li> </ul> <p>Has two stack pointers:</p> <ul> <li> <p>Main stack pointer: used in hnadler mode or thread mode.</p> </li> <li> <p>Process stack pointer: can be only in thread mode.</p> </li> </ul> <p></p> <p>B1.4.2</p> <p>The Program Status Register <code>xPSR</code> holds the information about the program.</p> <p></p> <p>B1.4.3</p> <p>There are special purpose registers that handle exception priority:</p> <p></p> <p>B1.4.4</p> <p>The <code>CONTROL</code> register sets the stack pointer and mode.</p>"},{"location":"arm_assembly/cortex-m/#reset-vector","title":"Reset vector","text":"<p>B1.5.2 &amp; B1.5.3</p> <p></p> <p></p>"},{"location":"arm_assembly/cortex-m/#steps-needed-on-reset","title":"Steps needed on reset","text":"<p>B1.5.5 &amp; B1.5.6</p> <ol> <li>Disable interrupts.</li> <li>Vector table offset to 0.</li> <li>Copy sections from ROM to RAM.</li> <li>Branch to main. 5.</li> </ol> <p></p>"},{"location":"arm_assembly/directives/","title":"Assembly directives","text":"<p>Assembly directives serve the same purpose as C preprocessors directives<sup>1</sup>: they tell The GNU Assembler how to do its job. They all have names that begin with a period (<code>.</code>), e.g. <code>.section</code>, and define sections, variables, macros, etc.</p> <p>The following sections are a summary of the most useful directives. A full list can be found at The GNU Assembler: Assembler Directives.</p>"},{"location":"arm_assembly/directives/#sections","title":"Sections","text":"<p>A section is a set of machine instructions grouped together. The syntax for defining a section is as follows:</p> <pre><code>.section &lt;name&gt; [, &lt;flags&gt;, %&lt;type&gt;]\n</code></pre> <p>For example, the following directives create two sections named <code>._my_text</code> and <code>.my_data</code>, for storing instruction code and variables respectively.</p> <pre><code>.section .my_text, \"ax\", %progbits\n    // Some code\n.section .my_data, \"aw\", %progbits\n    // Some variables\n</code></pre> <p>All instructions following the <code>.section</code> directive will be put inside that section. The <code>&lt;flags&gt;</code> indicate the properties of the section that will be used by the linker, and the <code>%&lt;type&gt;</code> indicate what's in the section. By default, new sections are only allocatable (<code>a</code>) and of type (<code>%nobits</code>):</p> <ul> <li> <p><code>a</code>: Allocatable (uninitialized memory region, same as .bss).</p> </li> <li> <p><code>x</code>: Executable (same as .txt).</p> </li> <li> <p><code>w</code>: Writable (same as .data).</p> </li> <li> <p><code>S</code>: Contains null-terminated strings.</p> </li> <li> <p><code>%progbits</code>: Contains code or initialized data (used for .data, .text)</p> </li> <li> <p><code>%nobits</code>: Uninitialized data.</p> </li> </ul> <p>The C compiler generates the following default sections.</p> <ul> <li> <p><code>.text</code>: holds executable instructions. <code>(\"ax\", %progbits)</code>.</p> </li> <li> <p><code>.data</code>: holds initialized global variables and constants with labels. <code>(\"aw\", %progbits)</code>.</p> </li> <li> <p><code>.rodata</code>: holds initialized read only data. <code>(\"a\", %progbits)</code></p> </li> <li> <p><code>.bss</code> and <code>COMMON</code>: short for \"Block Started by Symbol\", holds data storage areas that should be initialized to zero at the beginning of program execution, e.g. reserving 1000 bytes for a vector. The COMMON section is an alias that some compilers may use. <code>(\"aw\", %nobits)</code>.</p> </li> </ul> <p>These special sections can be used as directives themselves, without specifying section, flags or types:</p> <pre><code>.text\n.data\n.bss\n.rodata\n</code></pre> <p>Besides, an specific symbol can be given a type with the <code>.type</code> directive. Normally, it's not needed to define it, unless you want to call an assembly function from C (as we will see in the ABI section):</p> <pre><code>.type &lt;symbol_name&gt;, %&lt;function | object&gt;\n</code></pre> <pre><code>// Declare a function in section .text\n.text\n.type function_symbol, %function\nfunction_symbol:\n\n// Declare a data object in section .data\n.data\n.type data_symbol, %object\ndata_symbol\n</code></pre>"},{"location":"arm_assembly/directives/#variables-and-constants","title":"Variables and constants","text":"<p>This is a list of the possible types of constants that can be defined:</p> <pre><code>char:   .byte   0       // 1 byte variable i=0\nshort:  .hword  1       // 2 byte variable (half word) j=1\nint:    .word   2       // 4 byte variable (word) k=2\nasc:    .ascii  \"hello\" // Ascii string without NULL character\nstr:    .string \"hello\" // Ascii string with NULL character\nfloat:  .float  1.2     // Single precision number\ndouble: .double 4.4     // Double precision number\narray:  .word 0,1,2,3,4 // Integer array array[5] = {0,1,2,3,4}\n</code></pre> <p>For example:</p> <pre><code>.global i,j,k,l\n\n.data\ni: .byte 0      // 0x00 -&gt; 0x01\nj: .hword 1     // 0x01 -&gt; 0x03\nk: .word 2,3    // 0x03 -&gt; 0x0b\nl: .word 4      // 0x0b -&gt; 0x0f\n</code></pre>"},{"location":"arm_assembly/directives/#filling-and-alignment","title":"Filling and alignment","text":"<p>Since ARM is a 32-bit architecture, it is desired that variables are stored in memory positions multiples of 4. The alignment directives are as follows:</p> <pre><code>.align  x   // The next address will end with \"x\" zeros.\n.balign x   // The next address will be multiple of \"x\"\n.space size // Create a space of \"size\" bytes with zeros.\n</code></pre> <p>For example:</p> <pre><code>.global i,j,k,l\n\n.data\ni: .byte 0      // 0x00 -&gt; 0x01\n.align 2        // Force two zeros in next address -&gt; 0x04\nj: .hword 1     // 0x04 -&gt; 0x06\n.align 4        // Force four zeros -&gt; 0x10\nk: .word 2,3    // 0x10 -&gt; 0x18\n.balign 16      // Multiple of 16 -&gt; 0x20\n.space 33       // Fill 33 bytes with -&gt; 0x41\nl: .word 4      // 0x41 -&gt; 0x45\n</code></pre>"},{"location":"arm_assembly/directives/#preprocessor-directives","title":"Preprocessor directives","text":"<p>Preprocessor directives are functionally equivalent to the ones that you would see in the C language.</p>"},{"location":"arm_assembly/directives/#setting-and-manipulating-symbols","title":"Setting and manipulating symbols","text":"<p>Giving an alias to a register helps with following the logic of the code.</p> <pre><code>&lt;alias_name&gt; .req &lt;rx&gt;      // Give \"alias_name\" to register \"rx\"\n.unreq &lt;alias_name&gt;         // Undefine previous \"alias_name\"\n</code></pre> <p>The <code>.equ</code> and <code>.alias</code> directive are functionally equivalent to a <code>#define</code>.</p> <pre><code>.equ &lt;symbol&gt;, &lt;expression&gt;\nalias &lt;symbol&gt;, &lt;alias_name&gt;\n</code></pre> <p>By default, all variables are static to the file they are created, unless the <code>.global</code> directive is used:</p> <pre><code>.global &lt;symbol&gt;             // Set visibility outside of the file\n</code></pre> <p>You can use weak aliases to symbols by first declaring the symbol as <code>.weak</code>, and then using <code>.set</code> to associate it to a local symbol or expression. Only local symbols can be weak. A strong symbol is defined as any symbol in other module, externally linked by the linker.</p> <pre><code>.weak &lt;weak_symbol&gt;\n.set &lt;weak_symbol&gt;, &lt;expression&gt;\n</code></pre>"},{"location":"arm_assembly/directives/#conditional-assembly","title":"Conditional assembly","text":"<pre><code>.if expression || .ifdef symbol || .ifndef symbol\n    // do stuff\n.else\n    // do other stuff\n.endif\n</code></pre> <p>Three possible conditional are available:</p> <ul> <li> <p><code>.if &lt;expression&gt;</code>: the expression must be an absolute non-zero value to be evaluated as true.</p> </li> <li> <p><code>.ifdef &lt;symbol&gt;</code>: the symbol must have been defined.</p> </li> <li> <p><code>.ifndef &lt;symbol&gt;</code>: the symbol must not have been defined.</p> </li> </ul>"},{"location":"arm_assembly/directives/#including-files-and-symbols","title":"Including files and symbols","text":"<p>The <code>.include</code> directive replaces the <code>#include</code> one. It copies the file contents in the position where it is called.</p> <pre><code>.include &lt;file&gt;\n</code></pre> <p>The <code>.extern</code> defines a symbol not in this file, whether it was declared in other file with <code>.global</code> or is a linker symbol.</p> <pre><code>.extern &lt;symbol&gt;\n</code></pre>"},{"location":"arm_assembly/directives/#macros","title":"Macros","text":"<p>Macros are a more powerful version of <code>#define</code>. They are text replacements that can have arguments and default values.</p> <p>For example, the following code produces this disassembly of the object file:</p> <pre><code>.macro SHIFT arg1, arg2=5\n    lsl \\arg1, \\arg1, #\\arg2\n.endm\n\n.text\nSHIFT r1, 3\nSHIFT r2\n</code></pre> <pre><code>$ arm-linux-gnueabihf-objdump -d a.out\n00000000 &lt;.text&gt;:\n   0:   e1a01181        lsl     r1, r1, #3\n   4:   e1a02282        lsl     r2, r2, #5\n</code></pre>"},{"location":"arm_assembly/directives/#cpu-mode","title":"CPU mode","text":"<p>By declaring <code>.thumb</code> or <code>.arm</code>, you can force the code to be executed on either Thumb mode (16 bits) or ARM mode (32 bits).</p> <pre><code>.thumb || .code 16\n.arm   || .code 32\n</code></pre>"},{"location":"arm_assembly/directives/#recommended-bibliography","title":"Recommended bibliography","text":"<p>Modern Assembly Language Programming with the ARM Processor, Larry D Pyeatt</p> <ol> <li> <p>C preprocessors directives are the ones that start with a <code>#</code>, such as <code>#define</code>, <code>#ifndef</code>, etc. The directives are always interpreted before the compilation process.\u00a0\u21a9</p> </li> </ol>"},{"location":"arm_assembly/instructions/","title":"Assembly instructions","text":"<p>The ARM assembly instructions are all operations that can be performed between registers and memory. The full list of instructions can be consulted at ARM\u00ae Architecture Reference Manual ARMv7-A and ARMv7-R edition</p>"},{"location":"arm_assembly/instructions/#architecture-review","title":"Architecture review","text":"<p>The following image shows the ARM CPU architecture.</p> <p></p> <p>All ARM instructions depend on two buses: the A bus and the B bus, both corresponding to registers. Only the B bus can store Data out to the memory, or be operated by the Barrel shifter.</p> <p>Arithmetic operations can be performed between the A and B buses; meanwhile, their result or the Data in from the memory, can be stored in another register, while the Address register (program counter) updates the Address bus.</p> <p>All operations, therefore, must be done on registers, and not directly on memory. In the following image there is a list of the available registers under user mode (different modes are explained in the interruptions section).</p> <p></p>"},{"location":"arm_assembly/instructions/#conditional-instructions-and-cpsr","title":"Conditional instructions and CPSR","text":"<p>The CPSR (Current Program Status Registers) holds information about the flow of the program execution:</p> <p></p> Name Logical instruction Arithmetic instruction N (Negative) --- Bit 31 of result is set (negative number) Z (Zero) Result is all zeros Result is \"0\" C (Carry) After shift operation, \"1\" was left in carry flag Result is greater than 32 bits (adding two positive numbers gives a positive and lower number) V (oVerflow) --- Result is corrupted (Adding two positives numbers gave a negative one) <p>If the instruction ends with and <code>S</code>, the flags in the CPSR will be updated. If the instruction ends with one of the following mnemonics, the instruction will be conditionally executed.</p> \\ Flags Math Abbreviation meaning al Any --- Always eq Z=1 A=0 Equal \"0\" ne Z=0 A=0 Not Equal \"0\" ge (N=1 &amp; V=1) | (N=0 &amp; V=0) A \u2265 B Greater or Equal lt (N=1 &amp; V=0) | (N=0 &amp; V=1) A &lt; B Less Than gt Z=0 &amp; ((N=1 &amp; V=1) | (N=0 &amp; V=1)) A &gt; B Greater Than le Z=0 | (N=1 &amp; V=0) | (N=0 &amp; V=1) A \u2264 B Less or Equal hi C=1 &amp; Z=0 A &gt; B Higher ls C=0 | Z=1 A \u2264 B Lower or Same hs | cs C=1 A \u2265 B Higher or Same lo | cc C=0 A &lt; B Lower mi N=1 A &lt; 0 Minus pl N=0 A \u2265 0 Plus vs V=1 --- Overflow Set vc V=0 --- Overflow Clear <p>In the case of a conditional instruction that should update the CPSR, for example <code>addeqs</code>, the operation will be performed and the CPSR will be updated with its result only if the condition holds true.</p> <p>The following is an example of conditionally executed instructions:</p> <pre><code>ldr     r0, =44\nldr     r1, =55\ncmp     r0  r1          // compare r0 and r1\naddlt   r0, r0, #11     // r0 = r0 + 11 if previous comparison gave that r0 &lt; r1 (true)\nsubs    r0, r0, r1      // r0 = r0 - r1 and update flags\naddeq   r0, r0, #22     // r0 = r0 + 22 if previous operation was equal to \"0\" (true)\n</code></pre>"},{"location":"arm_assembly/instructions/#addresses","title":"Addresses","text":"<p>Given a memory address (<code>Rn</code>), its contents can be accessed as follows:</p> Syntax Result <code>[Rn]</code> Access contents of <code>Rn</code>. <code>=&lt;Immediate|symbol&gt;</code> Access contents of the immediate constant or symbol. <code>[Rn, #\u00b1&lt;offset_12bits&gt;]{!}</code> Access contents of <code>Rn \u00b1 &lt;offset&gt;</code>. Offset is a 12 bit number [-4095, 4095]. If it ends with <code>!</code>, then Rn is updated. <code>[Rn, \u00b1Rm, &lt;shift_op&gt; #&lt;shift&gt;]{!}</code> Access contents of <code>Rn \u00b1 (Rm &lt;&lt; shift)</code>. If it ends with <code>!</code>, then Rn es updated. <code>[Rn], #\u00b1&lt;offset_12bits&gt;</code> Access contents of <code>Rn</code>, and then let <code>Rn = Rn \u00b1 &lt;offset&gt;</code>. <code>[Rn], \u00b1Rm, &lt;shift_op&gt; #&lt;shift&gt;</code> Access contents of <code>Rn</code>, and then let <code>Rn = Rn \u00b1 (Rm &lt;&lt; shift)</code>."},{"location":"arm_assembly/instructions/#load-and-store-register-ldr-str-ldm-stm-pop-push","title":"Load and Store register (ldr, str, ldm, stm, pop, push)","text":"<p>For single registers use load <code>ldr</code> and store <code>str</code> instructions:</p> <pre><code>ldr{&lt;cond&gt;}{&lt;size&gt;} Rd, &lt;address&gt;   // Load register: Rd &lt;== *Address\nstr{&lt;cond&gt;}{&lt;size&gt;} Rd, &lt;address&gt;   // Store register: *Address &lt;== Rd\n</code></pre> <ul> <li><code>&lt;size&gt;</code>: By default, it will work on words (32 bits).<ul> <li><code>b</code>: unsigned byte.</li> <li><code>h</code>: unsigned half-word.</li> <li><code>sb</code>: signed byte.</li> <li><code>sh</code>: signed half-word.</li> </ul> </li> </ul> <p>For multiple registers:</p> <pre><code>ldm&lt;variant&gt; Rd{!}, &lt;register_list&gt; // Load multiple\nstm&lt;variant&gt; Rd{!}, &lt;register_list&gt; // Store multiple\n</code></pre> <ul> <li> <p><code>&lt;variant&gt;</code>: How to navigate the memory (normally use full descending mode).</p> <ul> <li><code>ia|fd</code>: Increment after | full descending.</li> <li><code>ib|ed</code>: Increment before | empty descending.</li> <li><code>da|fa</code>: Decrement after | full ascending.</li> <li><code>db|ea</code>: Decrement before | empty ascending.</li> </ul> </li> <li> <p><code>{!}</code>: If included, value of Rd is updated with the new address.</p> </li> <li> <p><code>&lt;register_list&gt;</code>: enclosed with <code>{}</code>, comma separated registers, or range of registers with a <code>-</code>, for example <code>{r1, r3, r6-r8} = r1, r3, r6, r7, r8</code>.</p> </li> </ul> <p>To manage stack variables, the preferred way is to use the following instructions. The stack behaves like a LIFO (Last In, First Out).</p> <pre><code>pop{&lt;cond&gt;}  &lt;reg_list&gt; // Pop from stack. Equivalent to \"ldmfd sp!, &lt;reg_list&gt;\"\npush{&lt;cond&gt;} &lt;reg_list&gt; // Push to stack. Equivalent to \"stmfd sp!, &lt;reg_list&gt;\"\n</code></pre> <p>When using a register list, the lowest register will be stored in the lowest address. For example, if you were to push multiple registers, you'd see in memory:</p> <pre><code>`push {r1, r5, r9-11}`\n`TOP | r11 | r10 | r9 | r5 | r1 | BOTTOM`.\n</code></pre> <p>Likewise, if you were to pop multiple registers like <code>pop {r1, r5, r9-11}</code>, you will retrieve the lowest address' contents into the lowest register, and end up retrieving everything correctly.</p> <pre><code>push {r0, r2, r7-r9}    // TOP | r9 | r8 | r7 | r2 | r0 |    | BOTTOM\npush {r5}               // TOP | r9 | r8 | r7 | r2 | r0 | r5 | BOTTOM\npop {r5}                // TOP | r9 | r8 | r7 | r2 | r0 |    | BOTTOM   r5=r5\npop {r0, r2}            // TOP | r9 | r8 | r7 |    |    |    | BOTTOM   r0=r0; r2=r2\npop {r7-r9}             // TOP |    |    |    |    |    |    | BOTTOM   r7=r7, r8=r8, r9=r9\n</code></pre> <p></p>"},{"location":"arm_assembly/instructions/#branch-b-bl-bx-blx-adr","title":"Branch (b, bl, bx, blx adr)","text":"<p>A label is defined in assembler as a name followed by a colon. Labels are useful to define points in the code to branch to, such as the start of a function, a for loop, or just as a reference.</p> <pre><code>// This is a label\nmy_label:\n    nop\n</code></pre> <p>A branch instruction can be as large as +-32 MBytes in memory, if used with a label. This is because the 32-bit instruction can't hold a 32-bit address, because some of the bits are used to encode the branch instruction itself. If the jump is larger than that, then a veneer is used by the compiler, which means that the address is loaded in the register <code>r12</code>, and jumps from that register.</p> <pre><code>b{&lt;cond&gt;} &lt;label&gt;           // Branch to target label\nbl{&lt;cond&gt;} &lt;label&gt;          // Branch and Link. lr = pc (for returning)\nbx{&lt;cond&gt;} Rn               // Branch and exchange. Change to Thumb (pc_LSB=1) or ARM (pc_LSB=0) mode.\nblx{&lt;cond&gt;} &lt;label&gt;         // Branch, link and exchange. Same as \"bx\", but lr = pc\nadr{&lt;cond&gt;}{s} Rd, &lt;label&gt;  // Copy address from label to register\n</code></pre> <p>A typical application of the branch instruction is to perform a for loop, such as:</p> <pre><code>// This is equivalent to \n// for(i=0; i&lt;5; i++) {}\n\nmov r0, #0\nloop:\n    add r0, r0, #1\n    cmp r0, #5 \n    blt loop\n</code></pre>"},{"location":"arm_assembly/instructions/#data-processing-instructions","title":"Data Processing instructions","text":""},{"location":"arm_assembly/instructions/#second-operand-and-barrel-shifter","title":"Second operand and barrel shifter","text":"<p>The second operand for data processing instruction will go through the barrel shifter, which can do the following in the same clock cycle:</p> <ul> <li>Define an immediate constant of 8 bits (0-255).</li> </ul> <ul> <li>Define an immediate constant of 32 bits, only if that value can be constructed by:<ul> <li>Rotating right an 8 bit constant for an even number from 0 to 30. (For example, 0x400 = 0x40 ROR 28)</li> <li>Making the 1's complement.</li> </ul> </li> </ul> <ul> <li>Rotate left or right the register <code>Rm</code> up to 31 positions.</li> </ul> <p>The list of possible second operands is as follows:</p> <pre><code>#&lt;immediate_value&gt;              // Constant value of 8 bits or specially rotated.\nRm                              // Single register\nRm, &lt;shift_op&gt; #&lt;shift_value&gt;   // Rm &lt;&lt; shift_value (Rotate register by constant)\nRm, &lt;shift_op&gt; Rs               // Rm &lt;&lt; Rs (Rotate register by other register)\nRm, rxx                         // (C|Rm) &gt;&gt; 1 (Rotate right 1 position, including the Carry flag)\n</code></pre>"},{"location":"arm_assembly/instructions/#shifting-lsl-lsr-asr-ror-rrx","title":"Shifting (lsl, lsr, asr, ror, rrx)","text":"<p>All shifting operations can be used as <code>&lt;shift_op&gt;</code> with the barrel shifter, or as independent commands.</p> <pre><code>Rm, lsl #&lt;value&gt;    // Logical shift left\nRm, lsr #&lt;value&gt;    // Logical shift right\nRm, asr #&lt;value&gt;    // Arithmetic shift right (sign preserved)\nRm, ror #&lt;value&gt;    // Rotate Right\nRm, rrx             // Rotate right by 1 position, but the Carry flag is included.\n</code></pre>"},{"location":"arm_assembly/instructions/#comparison-cmp-cmn-tst-teq","title":"Comparison (cmp, cmn, tst, teq)","text":"<p>These instructions only update the CPSR. They perform and arithmetic operation, but discard the result.</p> <pre><code>cmp{&lt;cond&gt;} Rn, Operand2 // Compare: Rn - op2\ncmn{&lt;cond&gt;} Rn, Operand2 // Compare negative: Rn + op2\ntst{&lt;cond&gt;} Rn, Operand2 // Test: Rn &amp; Op2\nteq{&lt;cond&gt;} Rn, Operand2 // Test equivalence: Rn XOR Op2\n</code></pre>"},{"location":"arm_assembly/instructions/#arithmetic-add-adc-sub-sbc-rsb-rsc-neg","title":"Arithmetic (add, adc, sub, sbc, rsb, rsc, neg)","text":"<pre><code>add{&lt;cond&gt;}{s} Rd, Rn, Operand2 // Add: Rd = Rn + op2\nadc{&lt;cond&gt;}{s} Rd, Rn, Operand2 // Add with carry: Rd = Rn + op2 + carry\nsub{&lt;cond&gt;}{s} Rd, Rn, Operand2 // Subtract: Rd = Rn - op2\nsbc{&lt;cond&gt;}{s} Rd, Rn, Operand2 // Subtract with carry: Rd = Rn - op2 + carry - 1\nrsb{&lt;cond&gt;}{s} Rd, Rn, Operand2 // Reverse subtract: Rd = op2 - Rn\nrsc{&lt;cond&gt;}{s} Rd, Rn, Operand2 // Reverse subtract with carry: Rd= op2 - Rn + Carry - 1\nneg{&lt;cond&gt;}{s} Rd, Rn           // Negate: Rd = -Rn. Same as \"rsb Rd, Rn, #0\"\n</code></pre>"},{"location":"arm_assembly/instructions/#logical-and-orr-eor-orn-bic","title":"Logical (and, orr, eor, orn, bic)","text":"<pre><code>and{&lt;cond&gt;}{s} Rd, Rn, Operand2 // Bitwise AND: Rd = Rn &amp; op2\norr{&lt;cond&gt;}{s} Rd, Rn, Operand2 // Bitwise OR: Rd = Rn | op2\neor{&lt;cond&gt;}{s} Rd, Rn, Operand2 // Bitwise XOR: Rd = Rn XOR op2\norn{&lt;cond&gt;}{s} Rd, Rn, Operand2 // Bitwise OR negated: Rd = !(Rn | op2)\nbic{&lt;cond&gt;}{s} Rd, Rn, Operand2 // Bit clear: Rd = Rn &amp; !(op2)\n</code></pre>"},{"location":"arm_assembly/instructions/#data-movement","title":"Data movement","text":"<p>Unlike <code>ldr</code> instructions, which load a value from memory, these instructions load a value from other register or use an immediate value. In the case of the instructions of the type <code>ldr Rn, =&lt;immediate_const&gt;</code>, they will be assembled into an equivalent <code>mov Rn, #&lt;immediate_const&gt;</code> if possible, or load a value in ROM and read it as <code>ldr Rn, [pc, #offset_pc]</code>.</p> <pre><code>mov{&lt;cond&gt;}{s} Rd, Operand2 // Move: Rd = op2\nmvn{&lt;cond&gt;}{s} Rd, Operand2 // Move not: Rd = !op2 (1's complement)\nmovt{&lt;cond&gt;} Rd, #immed16   // Move top: Rd = (immed16 &lt;&lt; 16) | (Rd &amp; 0xFFFF)\n</code></pre>"},{"location":"arm_assembly/instructions/#multiplication-with-32-bits-result-mul-mla","title":"Multiplication with 32 bits result (mul, mla)","text":"<p>Registers Rd and Rm should be different, or a compiler warning may appear.</p> <pre><code>mul{&lt;cond&gt;}{s} Rd, Rm, Rs       // Multiply: Rd = Rm * Rs\nmla{&lt;cond&gt;}{s} Rd, Rm, Rs, Rn   // Multiply and accumulate: Rd = Rm * Rs + Rn\n</code></pre>"},{"location":"arm_assembly/instructions/#multiplication-with-64-bits-result-smull-umull-smlal-umlal","title":"Multiplication with 64 bits result (smull, umull, smlal, umlal)","text":"<p>The 32 LSB will be stored in RdLo, while the 32 MSB will be stored in RdHi (RdHi : RdLo).</p> <pre><code>smull{&lt;cond&gt;}{s} RdLo, RdHi, Rm, Rs // Signed multiply long: RdHi : RdLo = Rm * Rs\numull{&lt;cond&gt;}{s} RdLo, RdHi, Rm, Rs // Unsigned multiply long: RdHi : RdLo = Rm * Rs\nsmlal{&lt;cond&gt;}{s} RdLo, RdHi, Rm, Rs // Signed multiply and accumulate long: RdHi : RdLo = Rm * Rs + RdHi : RdLo\numlal{&lt;cond&gt;}{s} RdLo, RdHi, Rm, Rs // Unsigned multiply and accumulate long: RdHi : RdLo = Rm * Rs + RdHi : RdLo\n</code></pre>"},{"location":"arm_assembly/instructions/#division-sdiv-udiv","title":"Division (sdiv, udiv)","text":"<pre><code>sdiv{&lt;cond&gt;}{s} Rd, Rm, Rn // Signed division: Rd = Rm / Rn\nudiv{&lt;cond&gt;}{s} Rd, Rm, Rn // Unsigned division: Rd = Rm / Rn\n</code></pre>"},{"location":"arm_assembly/instructions/#misc-clz","title":"Misc (clz)","text":"<pre><code>clz{&lt;cond&gt;} Rd, Rm // Count Leading Zeros: Rd = 31 - Int(log_2(Rm))\n</code></pre>"},{"location":"arm_assembly/instructions/#system-instructions","title":"System instructions","text":""},{"location":"arm_assembly/instructions/#nop-nop","title":"Nop (nop)","text":"<pre><code>nop // No operation, equivalent to \"mov r0, r0\"\n</code></pre>"},{"location":"arm_assembly/instructions/#access-cpsr-and-spsr-mrs-msr-cps","title":"Access CPSR and SPSR (mrs, msr, cps)","text":"<pre><code>mrs{&lt;cond&gt;} Rd, &lt;special_reg&gt;{_&lt;fields&gt;} // Move status to register: Rd = &lt;special_reg&gt;\nmsr{&lt;cond&gt;} &lt;special_reg&gt;{_&lt;fields&gt;}, Rd // Move register to status: special_reg = Rd\n</code></pre> <p>The special register can be:</p> <ul> <li>CPSR: Current program status register.</li> <li>SPSR: Saved program status register.</li> <li>xPSR (APSR, IPSR, EPSR): Current program status register, but for Cortex-M processor.</li> <li>PRIMASK|FAULTMASK|BASEPRI: Cortex-M interrupt priority.</li> <li>CONTROL: Cortex-M operation mode.</li> </ul> <p>The optional &lt;fields&gt; is any combination of (see CPSR image for meaning):</p> <ul> <li><code>c</code>: control field.</li> <li><code>x</code>: extension field.</li> <li><code>s</code>: status field.</li> <li><code>f</code>: flag field.</li> </ul> <pre><code>cps #&lt;mode&gt;  // Change Processor State (to certain operation mode)\ncps{ie|id} a|i|f {, #&lt;mode&gt;} // Interrupt Enable or Interrupt Disable any combination of the \"Abort, IRQ, or FIQ\" interrupts.\n</code></pre> \\ User FIQ IRQ Supervisor Abort Undef System Code 0x10 0x11 0x12 0x13 0x17 0x1B 0x1F"},{"location":"arm_assembly/instructions/#software-interrupt-swi-svc-wfi-srs-rfe","title":"Software interrupt (swi, svc, wfi, srs, rfe)","text":"<pre><code>svc{cond} #&lt;syscall_number&gt; // SuperVisor Call\nswi{cond} #&lt;syscall_number&gt; // Software interrupt, same as SVC\n\nSVC_handler:\n    ldrb r0, [lr, #-4]  // Get in r0 the syscall_number\n    movs pc, lr\n</code></pre> <pre><code>WFI{cond} // Wait for interrupt. Suspends execution until IRQ, FIQ or Data Abort.\n</code></pre> <p>The <code>srs</code> instruction (Save Return Status) saves the Link Register (lr) and the SPSR of the current mode in the stack of the &lt;mode&gt; specified. The <code>rfe</code> instruction (Return From Interrupt) is the opposite, and must be used always in conjunction with the <code>srs</code> one.</p> <pre><code>srs sp{!}, #&lt;mode&gt;  // Store Return Status\ncps #&lt;mode&gt;         // Change to different mode\nrfe sp{!}           // Return From Exception, using the stack pointer of #&lt;mode&gt;\n</code></pre>"},{"location":"arm_assembly/instructions/#recommended-bibliography","title":"Recommended bibliography","text":"<p>Modern Assembly Language Programming with the ARM Processor, Larry D Pyeatt</p>"},{"location":"arm_assembly/interruptions/","title":"Interruptions","text":"<p>An interruption is any abnormal event that triggers a predefined set of instructions to be executed. There are three types:</p> <ul> <li>A hardware interruption is asynchronous and not deterministic.</li> <li>A software interruption is triggered by code, therefore, deterministic.</li> <li>An exception is any internal interruption triggered by the CPU itself, which halts normal instruction execution (Reset, MemoryFault, Opcode error, etc).</li> </ul> <p>The ARMv7 Cortex-R and Cortex-A have 7 operating modes, which are changed depending on the type of interruptions called.</p> Mode Code Privileges Description User 10000 Unprivileged Suitable for most application code. FIQ 10001 Privileged Fast Interrupt. IRQ 10010 Privileged Normal interrupt. Supervisor 10011 Privileged Suitable for running most kernel code. Entered on Reset and on SuperVisor Call (SVC) instruction. Abort 10111 Privileged Data abort exception of prefetch abort exception. Undef 11011 Privileged Intruction related error. System 11111 Privileged Applications that require privileged access. Uses the same \"User\" mode registers. <p>The User mode, being unprivileged, can't access protected system resources or change mode, unless and interruption is raised.</p> <p>The rest of modes can change freely between modes changing the CPSR register directly.</p> <p>To change the mode and the interrupt flags, one may use the move status to register, <code>mrs</code> and <code>msr</code>, instructions, but the preferred way is to use the Change Processor State, <code>cps</code>, instruction.</p> <pre><code>cps &lt;mode&gt;\ncps{ie|id} a|i|f {, &lt;mode&gt;} // Interrupt Enable or Interrupt Disable any combination of the \"Abort, IRQ, or FIQ\" interrupts.\n</code></pre> &lt;mode&gt; User FIQ IRQ Supervisor Abort Undef System Code 0x10 0x11 0x12 0x13 0x17 0x1B 0x1F <p>In the next image, we can see that the first 5 bits of the CPSR correspond to the operation mode, while the bits [8:5] correspond to the interrupt disable flags.</p> <p></p> <p>Some registers are shared between modes, but others are exclusive to that operation mode. As seen in the next image, share registers <code>{r0-r12}</code>, except for the FIQ mode; while each mode has it's own stack pointer, link register and SPSR.</p> <p></p>"},{"location":"arm_assembly/interruptions/#exception-list-and-the-vector-table","title":"Exception list and the vector table","text":"<p>The vector table is a space in memory where the code execution will branch to in case of an exception.</p> <p>It's defined as an instruction that loads the program counter with the address of the exception handler <sup>1</sup>.</p> <pre><code>    ldr pc, =RESET_handler\n    ldr pc, =UND_handler\n    ldr pc, =SVC_handler\n    ldr pc, =PREF_handler\n    ldr pc, =ABT_handler\n    ldr pc, =0x00\n    ldr pc, =IRQ_handler\n    ldr pc, =FIQ_handler\n</code></pre> <p></p> <p>The process of handling an interruption is as follows:</p> <ol> <li> <p>The Core receives the interrupt and does these steps for us (for example for IRQ):</p> <pre><code>mov lr_irq, pc          // Save program counter in the new mode link register.\nmov spsr_irq, cpsr      // Save CPSR in the SPSR of the new mode.\ncpsid i, #irq_mode      // Change the mode, and disable IRQ interrupts.\nldr pc, =IRQ_VEC_TABLE  // Jump to the vector table address\n</code></pre> </li> <li> <p>Execute the instruction inside the vector table.</p> <pre><code>0x000000010 ldr pc, =irq_handler\n</code></pre> </li> <li> <p>Inside the handler, do what's needed.</p> <pre><code>irq_handler:\n    push {r0-r3, r12, lr}   // Store registers, \"lr\" will be modified\n    bl identify_source      // Identify IRQ source (returns on r0 the handler address)\n    bl r0                   // Jump to the appropriate handler\n    pop {r0-r3, r12, lr}    // Retrieve registers\n    subs pc, lr, #4         // Return to the next instruction before interrupt occurred\n</code></pre> <p>When returning from an interruption, the most common way is to use the syntax <code>subs pc, lr, #4</code> (the \"s\" for changing the CPSR is essential, any instruction ending with \"s\" will copy the SPSR to the CPSR). Because of the way the pipeline of \"fetching, decoding and executing\" works, the program counter always points to the instruction being \"fetched\", not the one being processed.</p> <p>Looking at the image, if the program counter is in the first cycle, and we are executing the instruction in the third cycle (pc -8), and the interrupt occurs, then we should return to the second cycle (pc -4).</p> <p></p> </li> </ol> <p>Here is a list of Exceptions in ARM:</p> Exception Priority Mode Base LR value LR offset (ARM/Thumb) Preferred Return address Description Reset 1 svc Unknown -/- - Complete system initialization. Must load the interrupt vector and setup the memory. Data abort 2 abt Address of aborted instruction +8 / +8 lr-8 Generated by the MMU (Memory Management Unit) when requesting access to an non existing or unauthorized memory region. FIQ 3 fiq Address of next instruction to execute +4 / +4 lr-4 Pin \"nFIQ\" low. \"I=1\", \"F=1\" in the CPSR. IRQ 4 irq Address of next instruction to execute +4 / +4 lr-4 Pin \"nIRQ\" low. \"I=1\" in the CPSR. Prefetch Abort 5 abt Address of aborted instruction +4 / +4 lr-4 Fetching an invalid memory address. \"I=1\" in the CPSR. Software Interrupt 6 svc Address of SVC instruction +4 / +2 lr Enters when the instruction \"SVC\" is called from the user mode. Undefined Instruction 6 und Address of undefined instruction +4 / +2 lr Executing invalid instruction."},{"location":"arm_assembly/interruptions/#nested-interrupts","title":"Nested interrupts","text":"<p>If, while handling an IRQ exception, we reenable the IRQ interrupts and another IRQ triggers, the processor will overwrite the \"lr_irq\" and the \"spsr_irq\" registers. Therefore, the return address will be permanently lost. This wouldn't happen if another kind of interruption gets called, because each one has it's own SPSR and LR.</p> <p>Therefore, the LR_IRQ and the SPSR_IRQ must be saved before reenabling interrupts. However, this must be made from the \"System\" mode, and not from the same \"IRQ\" mode.</p> <p>Let's consider the next example:</p> <pre><code>// This implementation is faulty.\nirq_handler:\n    sub lr, lr, #4          // Change the link register to the actual return address\n    srs sp!, #0x12          // Store SPSR and LR in the stack of the IRQ mode stack.\n    push {r0-r3, r12, lr}   // Store registers\n    cpsie i                 // Enable IRQ\n    bl foo                  // Link register is changed\n    cpsid i                 // Disable IRQ\n    pop {r0-r3, r12, lr}    // Retrieve registers\n    rfe sp!                 // Return from interrupt, loading the SPSR into the CPSR and the LR into the PC\n\nfoo:\n    nop // Interrupt trigger here, \"lr = pc\", and can't return from here\n    mov pc, lr\n</code></pre> <p>If an interrupt triggers inside the \"foo\" function, the link register will be lost. The current program counter (pointing to the \"nop\" instruction), will be stored in the link register of the IRQ mode, erasing the previous \"lr\" value which pointed to the \"cpsid i\" instruction.</p> <p>To avoid this, we should change to \"System\" mode, so that the link register doesn't get overwritten.</p> <pre><code>irq_handler:\n    sub lr, lr, #4          // Change the link register to the actual return address\n    srs sp!, #0x1F          // Store SPSR and LR in the stack of the System mode stack.\n    cps #0x1F               // Change to System mode\n    push {r0-r3, r11, r12}  // Store registers, r11 is stored to keep 8 byte alignment\n    cpsie i                 // Enable IRQ\n    bl foo                  // Link register is changed\n    cpsid i                 // Disable IRQ\n    pop {r0-r3, r11, r12}   // Retrieve registers\n    rfe sp!                 // Return from interrupt, loading the SPSR into the CPSR and the LR into the PC\n\nfoo:\n    nop // Interrupt trigger here.\n</code></pre> <p>Now, in case of an interruption, the program counter will be stored in the link register of the IRQ mode, and the link register of the System mode is preserved.</p>"},{"location":"arm_assembly/interruptions/#interrupt-controllers","title":"Interrupt controllers","text":"<p>The way hardware interruptions are handled is independent from the processor Core, and each chip may have a different one.</p>"},{"location":"arm_assembly/interruptions/#gic-arm-generic-interrupt-controller","title":"GIC ARM: Generic Interrupt Controller","text":"<p>ARM suggested interrupt controller. It has all the interrupt sources connected and controls their priority, state and masks by a set of memory mapped registers. It's made of two parts:</p> <ul> <li> <p>The distributor: which receives all the interrupt sources and has several registers to set their priorities, their state (active, pending, inactive, etc) and establishes to which CPU core they'll be sent to. Interrupts are given an Interrupt ID from 0 to 1020.</p> </li> <li> <p>The CPU interface: which is unique to each CPU core. Receives the IRQs from the distributor.</p> </li> </ul> <p>Therefore, interrupts can be separated in three types:</p> <ul> <li> <p>Software Generated Interrupts (SGI) (0-15): generated by writing in the Interrupt Controller Distributor Software Generated Interrupt Registers ICDSGIR. It's used for multi-core synchronization.</p> </li> <li> <p>Private Peripheral Interrupts (PPI) (16-31): generated and used by a determined core (for example, the Systick).</p> </li> <li> <p>Shared Peripheral Interrupts (SPI) (31-1020): generated from and to any core (for example, SPI communication).</p> </li> </ul> <p>When an interrupt appears, it normally follows these steps:</p> <ol> <li> <p>The priority and list of cores able to handle the interruption are determined in the Distributor. Their state is changed to Pending or Active and Pending, and eventually feed into the CPU interface, lowering the FIQ or IRQ pins.</p> </li> <li> <p>The CPU's handler function executes, and reads the Interrupt ID from the CPU interface Interrupt Acknowledge Register. Reading from this register set's the interrupt state to \"active\".</p> </li> <li> <p>Before leaving the handler, it must access the CPU interface End of Interrupt Register and mark the interruption as \"completed\", so that the GIC can mark it as Inactive.</p> </li> </ol>"},{"location":"arm_assembly/interruptions/#differences-for-cortex-m-microprocessors","title":"Differences for Cortex-M microprocessors","text":"<ul> <li> <p>Cortex-M only works on Thumb mode (either Thumb1 or Thumb2).</p> </li> <li> <p>Only two operation modes: \"Handler\" for interruptions and \"Thread\" for user code. Besides, \"Supervisor\" and \"User\" indicate the execution privileges.</p> </li> <li> <p>Only one set of registers, except for the \"MSP\" (Main Stack Pointer) and PSP (Program Stack Pointer), which are changed between handler and thread mode.</p> </li> <li> <p>Interruptions store on the stack automatically <code>r0-r3, r12, lr, xPSR, pc</code>.</p> </li> <li> <p>The interrupt vector holds addresses instead of instructions.</p> </li> <li> <p>The \"CPSR\" is now called \"xPSR\", and holds the elements show in the figure.</p> </li> </ul> <ul> <li>In addition to the \"xPSR\" register, there are 4 more:<ul> <li>PRIMASK: if \"1\", enables NMI (Non Maskable Interrupt) and Hard Fault exceptions.</li> <li>FAULTMASK: if \"1\", enables only NMI.</li> <li>BASEPRI: 9 bits register; disables all interruptions with higher or equal priority value (lower values mean higher priorities).</li> <li>CONTROL[1]: if \"1\" uses the PSP, if \"0\" uses the MSP.</li> <li>CONTROL[0]: if \"1\" User Thread Mode, if \"0\", Supervisor Thread Mode.</li> </ul> </li> </ul> <p></p> <p>The Cortex-M family has its own interrupt controller on chip: The NVIC (Nested Vector Interrupt Controller). It handles multiple interrupt sources, and leaves \"pending\" the interrupt signals for later processing, depending on their priority.</p> <p>The most remarkable registers are:</p> <ul> <li>IPR_xx: Interrupt Priority. Each register has 8 bits of priority for interrupt (4 interrupts per register, total of 60 registers, total of 240 interrupts).</li> <li>ISER0-ISER7: Interrupt Set Register. If \"1\", enables the interruption.</li> <li>ICER0-ICER7: Interrupt Clear Enable Register. If \"1\" is written, disables the interruption.</li> <li>ISPR0-ISPR7: Interrupt Set Pending Register. If \"1\", the interruptions is set \"pending\" of being executed, probably because a higher priority interrupt is being processed.</li> <li>ICPR0-ICPR7: Interrupt Clear Pending Registers. If \"1\" is written, cleans the pending status.</li> <li>IABR0-IABR7: Interrupt Active Register. If \"1\", indicates which interrupt line is active.</li> <li>STIR: Software Trigger Interrupt Register. When written, a software interrupt will be generated identified by the first byte.</li> </ul> <p></p> <ol> <li> <p>That's only for Cortex-A and Cortex-R. For Cortex-M, instead of a <code>ldr</code> instruction, the processor expects only the address's value as a word such as: <code>.word =RESET_handler</code>.\u00a0\u21a9</p> </li> </ol>"},{"location":"arm_assembly/pagination/","title":"ARM pagination","text":"<p>In this section we will describe how to implement pagination for virtual memory in an ARMv7 Cortex-A processor using VMSA (Virtual Memory System Architecture). The MMU (Memory Management Unit) is the hardware that handles the translation from VA (Virtual Address) to PA (Physical Address).</p>"},{"location":"arm_assembly/pagination/#enabling-the-mmu","title":"Enabling the MMU","text":"<p>Most operations for memory management are handled by the coprocessor 15 (CP15). ARM has a special instruction to access coprocessor registers:</p> <pre><code>mrc{cond} p&lt;coproc_number&gt;, #&lt;opcode1&gt;,  Rm, cp&lt;x&gt;, cp&lt;y&gt;, #&lt;opcode2&gt; // Move to register from coprocessor\nmcr{cond} p&lt;coproc_number&gt;, #&lt;opcode1&gt;,  Rm, cp&lt;x&gt;, cp&lt;y&gt;, #&lt;opcode2&gt; // move to coprocessor from register\n</code></pre> <p>The \"opcode1\" and \"opcode2\" are defined for each operation, and the \"cp\" are the register number in the coprocessor. \"Rm\" is the ARM register.</p>"},{"location":"arm_assembly/pagination/#the-sctlr-register","title":"The SCTLR register","text":"<p>This register holds most of the MMU configuration.</p> <pre><code>MRC p15,0,&lt;Rt&gt;,c1,c0,0 // Read CP15 System Control Register\nMCR p15,0,&lt;Rt&gt;,c1,c0,0 // Write CP15 System Control Register\n</code></pre> <p>The most relevant to modify (the rest are fine with default value):</p> Name Description If \"0\" If \"1\" Default TE [30] Thumb exception enable Exceptions are handled in ARM state Exceptions are handled in Thumb state 0 AFE [29] Access flag enable No access flag. Full permission range Access flag. Simplified model for permissions 0 TRE [28] TEX remap enable TEX[2:0], C and B are used to describe memory regions TE[0], C and B are sed to describe memory regions 0 HA [17] Hardware Access Flag Enable Hardware management of the access flag disabled Hardware management of the access flag enabled 0 A [1] Alignment bit Alignment fault disabled Alignment fault enabled 0 M [0] MMU enable bit MMU disabled MMU enabled 0"},{"location":"arm_assembly/pagination/#first-level-page-table-entry","title":"First level page table entry","text":"<p>The first level page table entry describes how a single 1MB VA region is mapped. To be able to represent all the physical memory (4GB), it must have 4K entries, and with 32-bit addresses, occupies 16KB in memory (4 bytes per entry).</p> <p>The first level page table entry can contain any of the following, determined by the two LSB bits (page offset is a memory address inside the page):</p> <ul> <li> <p>Supersection: 16MB block of memory. As such, 2^24 bits of the VA are used as page offset, and only 2^8 are used as table index. However, this is an invalid bit distribution. If the table has 4K entries, we need at least 2^12 bits of table index. Because of that, the 4 MSB of the page offset and the 4 LSB of the page address are overlapped, making the latter random. Therefore, a supersection must be written 16 times in the table, aligned to a multiple of 16th.</p> </li> <li> <p>Section: 1MB block of memory. As such, 2^20 bits of the VA are used as page offset, and only 2^12 are used as table index.</p> </li> <li> <p>Page table: Pointer to a second order page table, with 256 entries. As such, 2^12 bits of the VA are used as table index for the first table, 2^8 bits of the VA are used as an index for the second level page table, and the remaining 2^12 remain free for the page offset.</p> </li> <li> <p>Fault entry.</p> </li> </ul> <p></p>"},{"location":"arm_assembly/pagination/#second-level-page-table-entry","title":"Second level page table entry","text":"<p>The second level page table entries describe how a 4KB VA region is mapped. They contain physical addresses.</p> <p>Second level page table entries have 256 entries, occupying 1KB of memory each.</p> <p>Can contain any of the following:</p> <ul> <li> <p>Large page: 64KB page. As such, 2^16 bits of the VA are used as page offset, and only 2^16 are used as page index. This is an invalid bit distribution. Coming from the first table, we only had 2^12 bits free. Therefore, the 4 LSB of the table index are used as the 4 MSB of the page offset. Because of that, the large page entry should be repeated 16 times in the table.</p> </li> <li> <p>Small page: 4KB page. As such, 2^12 bits of the VA are used as page offset, and only 2^20 are used as table index (12bits for first table, and 8bits for second table).</p> </li> </ul> <p>A complete diagram of the VA, table entries for a second order table entry:</p> <p></p>"},{"location":"arm_assembly/pagination/#memory-permissions","title":"Memory permissions","text":"<p>Failing to follow the permissions defined for a memory page, provided that the domain was configured as client, will result in a \"Permission Fault\".</p>"},{"location":"arm_assembly/pagination/#ap-access-properties","title":"AP: Access properties","text":"<p>Its behavior depends of the configuration of the SCTRL.AFE bit.</p> <p>If SCTRL.AFE = 0 (No access flag), the complete access properties can be defined.</p> AP[2:0] Privileged permissions User permissions 000 No access No access 001 Read/write No access 010 Read/write Read only 011 Read/write Read/write 100 - - 101 Read only No access 110 - - 111 Read only Read only <p>If SCTRL.AFE = 1 (access flag enabled), then the simplified access properties are to be used. Besides, the access flag can be used to know if a memory region was \"accessed\" since the access flag was set to \"0\". It's strongly recommended to active the hardware control SCTRL.HA=1.</p> AP[2:1] Privileged permissions User permissions 00 Read/write No access 01 Read/write Read/write 10 Read only No access 10 Read only Read only AP[0] Description 0 The memory region was \"not accessed\". If the memory region is accessed, it will trigger an \"Access Flag Fault\". 1 The memory region was \"accessed\". Should be set to \"1\" after the \"Access Flag Fault\". If SCTRL.HA=1, it's done automatically by hardware"},{"location":"arm_assembly/pagination/#xn-execute-never","title":"XN: Execute never","text":"XN Description 0 The content of the memory can be prefetched. 1 Trying to fetch an instruction from this address will generate a Prefetch abort exception, with a Permission fault."},{"location":"arm_assembly/pagination/#domain","title":"Domain","text":"<p>A domain encapsulates a whole second level page table, or a section. The domain bits are 4, marking 16 possible domains.</p> <p>Each of the 16 domains can be marked in the DACR (Domain Access Control Register) as:</p> <p></p> DACRx [1:0] Description 00 No access. Any access generates Domain Fault 01 Client. Accesses are checked against AP (access permissions) 10 - 11 Manager. Accesses are not checked. Permission Faults can't be generated <pre><code>MRC p15,0,&lt;Rt&gt;,c3,c0,0 // Read CP15 Domain Access Control Register\nMCR p15,0,&lt;Rt&gt;,c3,c0,0 // Write CP15 Domain Access Control Register\n</code></pre>"},{"location":"arm_assembly/pagination/#memory-region-attributes","title":"Memory region attributes","text":"<p>This define how the memory behaves.</p>"},{"location":"arm_assembly/pagination/#s-shareable-ng-non-global-ns-non-secure","title":"S: shareable, nG: non global, NS: non secure","text":"<p>If \"S=0\", region is non shareable. If \"S=1\", region is shareable. Shareable flag is ignored if the memory entry is a \"Device\" or \"Strongly-ordered\" memory.</p> <p>If \"nG=0\", the translation is global. This means that the TLB value will remain in cache even after a context switch, and can be shared between processes. If \"nG=1\", the translation is process specific.</p> <p>If \"NS=0\", the region is secure. Only matters if the security extensions are enabled.</p>"},{"location":"arm_assembly/pagination/#tex-c-b","title":"TEX, C, B","text":"<p>The behavior of these bits depend on the value of the SCTRL.TRE bit.</p> <p>If SCTRL.TRE = 0, the TEX remap is disabled.</p> TEX[2:0] C B Description Memory type Shareable 000 0 0 Strongly-ordered Strongly-ordered Yes 000 0 1 Shareable device Device Yes 000 1 0 Outer and Inner write through, no write allocate Normal S bit 000 1 1 Outer and Inner write back, no write allocate Normal S bit 001 0 0 Outer and Inner non cacheable Normal S bit 001 1 1 Outer and Inner write back, write allocate Normal S bit 010 0 0 Non shareable device Device No 1BB A A AA = Inner attribute; BB = Outer attribute (next table) Normal S bit <p>The inner and outer attributes for \"AA\" and \"BB\" are defined as such:</p> 00 Non cacheable 01 Write back, write allocate 10 Write through, no write allocate 11 Write back, no write allocate <p>If SCTRL.TRE = 1, the TEX remap will be used. Now the values of TEX[2:1] will be user defined, and the values of TEX[0], C and B correspond to one of the 8 configurable memory modes that can be stored in the PRRR (Primary Region Remap Register) and NMRR (Normal Memory Remap Register).</p> <p></p>"},{"location":"arm_assembly/pagination/#ttbr-translation-table-base-registers","title":"TTBR: Translation Table base registers","text":"<p>TTBR1 holds the address of the first level page table. This table is used for the operating system and I/O addresses. It has 4K entries, occupying 16KB of memory. Besides, the memory attributes for the PA obtained from the translation table can be defined.</p> <p></p> Name Description If \"0\" If \"1\" Default NOS [5] Not Outer Shareable Outer shareable Inner shareable 0 RGN [4:3] Region bits \"00\"= Outer Non-cacheable; \"01\"= Outer write-back write-allocate cacheable \"10\"= Outer write-through cacheable; \"11\"= Outer write-back no write-allocate cacheable 0 S [1] Shareable bit Non-shareable Shareable 0 C [0] Cacheable bit Inner non-cacheable Inner cacheable 0 <p>TTBR0 holds the address of the first level page table of the current process in execution (remember that normally, each process has it's own VA space, so we need one table per process). This table, however, has a catch. The amount of entries of this table can be arbitrarily chosen (see the value \"14-N\" in the size of the address). All other properties remain the same.</p> <p></p> <p>TTBCR (Translation Table Base Control Register) indicates the size of the TTBR0 table. This, then, is dictating the size of the VA for the process. Remember that each entry in the table represent 1MB.</p> <p></p> <p>N [2:0]: Determines the size of the first level page table. if \"N=0\", it will have 4K entries, 16KB of size, so the table index will be 2^12. If \"N=7\", there will be 32 entries, 128B of size, so the table index will be 2^7.</p> <pre><code>MRC p15,0,&lt;Rt&gt;,c2,c0,0 // Read CP15 Translation Table Base Register 0\nMCR p15,0,&lt;Rt&gt;,c2,c0,0 // Write CP15 Translation Table Base Register 0\n\nMRC p15,0,&lt;Rt&gt;,c2,c0,1 // Read CP15 Translation Table Base Register 1\nMCR p15,0,&lt;Rt&gt;,c2,c0,1 // Write CP15 Translation Table Base Register 1\n\nMRC p15,0,&lt;Rt&gt;,c2,c0,2 // Read CP15 Translation Table Base Control Register\nMCR p15,0,&lt;Rt&gt;,c2,c0,2 // Write CP15 Translation Table Base Control Register\n</code></pre>"},{"location":"arm_assembly/pagination/#memory-faults","title":"Memory faults","text":"<p>Memory faults can cause either a Data abort exception or a prefetch abort exception.</p> <ul> <li> <p>Alignment Fault: Unaligned memory access (with SCTRL.A == 1).</p> </li> <li> <p>Translation Fault: translation table entry is defined as \"fault entry\" (LSB == 00).</p> </li> <li> <p>Access Flag Fault: Access to a table entry with the AP[0] == 0, and the SCTRL.AFE == 1.</p> </li> <li> <p>Domain fault: Access to a domain marked as \"no access\".</p> </li> <li> <p>Permission fault: Access to the table entry doesn't follow the AP (access permissions).</p> </li> <li> <p>External abort: Produced by memory accesses from external devices.</p> </li> </ul>"},{"location":"arm_assembly/pagination/#data-abort-exception","title":"Data abort exception","text":"<p>When a Data abort occurs, the values in the DFSR (Data Fault Status Register) will have the reason:</p> <p></p> <p>Besides WnR, bit [11] if \"0\", abort caused by read access, if \"1\", abort caused by write access.</p> <p>The DFAR (Data Fault Address Register) will have the address that caused the exception, if the access was synchronous.</p> <pre><code>MRC p15,0,&lt;Rt&gt;,c5,c0,0 // Read CP15 Data Fault Status Register\nMCR p15,0,&lt;Rt&gt;,c5,c0,0 // Write CP15 Data Fault Status Register\n\nMRC p15,0,&lt;Rt&gt;,c6,c0,0 // Read CP15 Data Fault Address Register\nMCR p15,0,&lt;Rt&gt;,c6,c0,0 // Write CP15 Data Fault Address Register\n</code></pre>"},{"location":"arm_assembly/pagination/#prefetch-abort-exception","title":"Prefetch abort exception","text":"<p>When a Prefetch abort occurs, the IFSR (Instruction Fault Status Register) will have the reason:</p> <p></p> <p>The IFAR (Instruction Fault Address Register) holds the VA that caused exception, if it was synchronous.</p> <pre><code>MRC p15,0,&lt;Rt&gt;,c5,c0,1 // Read CP15 Instruction Fault Status Register\nMCR p15,0,&lt;Rt&gt;,c5,c0,1 // Write CP15 Instruction Fault Status Register\n\nMRC p15,0,&lt;Rt&gt;,c6,c0,2 // Read CP15 Instruction Fault Address Register\nMCR p15,0,&lt;Rt&gt;,c6,c0,2 // Write CP15 Instruction Fault Address Register\n</code></pre>"},{"location":"arm_assembly/pagination/#special-instruction-dsb-and-isb","title":"Special instruction: DSB and ISB","text":"<p>DSB (Data Synchronization Barrier). No instruction will execute until this instruction completes. This instruction completes when:</p> <ul> <li>All memory accesses before this instruction are complete.</li> <li>All Cache, branch and TLB maintenance operations complete.</li> </ul> <p>ISB (Instruction Synchronization Barrier). Flushes the pipeline, so all new instructions must be re-fetched from cache or memory.</p>"},{"location":"arm_assembly/pagination/#cortex-r-mpu-a-review","title":"Cortex-R MPU: a review","text":"<p>The Cortex-R, as a real time device, doesn't have time for this \"pagination\" stuff. The PMSA (Protected Memory System Architecture, replaces VMSA) uses the MPU (Memory Protection Unit, replaces MMU) to statically define \"memory regions\" and places the code and data on those regions. These regions are defined by its base address, arbitrary size, attributes and permissions; most of which are the same as described above.</p>"},{"location":"arm_assembly/riscv/","title":"RISCV","text":""},{"location":"arm_assembly/simd/","title":"SIMD: Single Instruction Multiple Data","text":"<p>In ARM, SIMD is implemented in three different ways:</p> <ul> <li> <p>ARM SIMD instructions: integrated assembly instructions.</p> </li> <li> <p>With NEON: a special bank of SIMD registers.</p> </li> <li> <p>With FPU: a hardware floating point unit.</p> </li> </ul> <p>This topic is better explained by example, so let's start.</p>"},{"location":"arm_assembly/simd/#arm-simd-instructions","title":"ARM SIMD instructions","text":"<p>In ARM, registers have 32 bits. If we wanted to operate with pixels in an image, which only use 8 bits, then we would be wasting 24 bits per operation. So, a sensible thing to do would be to put four pixels in a single register, and do four 8-bit operations with a single 32-bit register. This can be done with the instruction <code>UADD8</code> as follows:</p> <pre><code>ldr r1, =0x11223344\nldr r2, =0x55667788\nuadd8 r0, r1, r2    // r0 = 0x6688AACC\n</code></pre> <p></p> <p>A small list of these instructions, just to have an idea:</p> <pre><code>uadd16 r0, r1, r2   // r0[0:15] = r1[0:15] + r2[0:15]\nuadd8 r0, r1, r2    // r0[0:7] = r1[0:7] + r2[0:7]\nuhadd16 r0, r1, r2  // r0[0:15] = (r1[0:15] + r2[0:15])/2\nuhadd8 r0, r1, r2   // r0[0:7] = (r1[0:7] + r2[0:7])/2\n</code></pre>"},{"location":"arm_assembly/simd/#introduction-to-neon-and-vfps-bank-of-registers","title":"Introduction to NEON and VFP's bank of registers","text":"<p>NEON is the name given to the \"Advanced SIMD extension\" from ARM. It's implemented on coprocessors 10 and 11 <code>cp10, cp11</code>. In addition, the VFP (Virtual Floating Point) extension is also implemented on coprocessors <code>cp10, cp11</code>. A CPU might have both NEON and VFP, one of them, or none. These coprocessors have their own bank of registers, therefore, NEON and VFP operations are not performed using the general purpose registers <code>{r0-r15}</code>.</p> <p>The NEON register bank consists of 32 64-bit registers, which can be seen as:</p> <ul> <li>Sixteen 128-bit \"quad word (Q)\" registers <code>Q0-Q15</code>.</li> <li>Thirty two 64-bit \"double word (D)\" registers <code>D0-D31</code></li> </ul> <p>Meanwhile, the VPF register bank consists of 16 64-bit registers, which can be seen as:</p> <ul> <li>Sixteen 64-bit \"double word (D)\" registers <code>D0-D15</code>.</li> <li>Thirty two 32-bit \"single word (S)\" registers <code>S0-S31</code>.</li> </ul> <p>Notice that <code>D0-D15</code> are shared between NEON and VFP.</p> <p></p>"},{"location":"arm_assembly/simd/#neon-fundamentals","title":"NEON fundamentals","text":"<p>All NEON or VFP instructions start with a <code>V</code>, for \"vectorized operation\". Each instruction must indicate the size and the number of the registers, as well as data type. Output and input registers might be of different size.</p> <pre><code>VADD.I16 Q0, Q1, Q2     // Add eight 16-bit integers\nVADD.U8 D0, D1, D2      // Add eight 8-bit unsigned integers\nVMULL.S16 Q2, D8, D9    // Multiply four 16-bit signed integers, and store the result in four 32-bit spaces.\n</code></pre> <p>To set a scalar into a NEON register, the data type, the register number, and the index must be specified:</p> <pre><code>VMOV.8 D0[3], R3    // Move the 8 LSB from R3 into the fourth byte of the register D0.\n</code></pre> <p>So, data types are separated from the instruction name by a dot. All possible data types are:</p> <p></p> <p>Sometimes, only the size of the data type is needed. In that case, the syntax is <code>.8 ; .16 ; .32</code>, etc.</p>"},{"location":"arm_assembly/simd/#enabling-neon","title":"Enabling NEON","text":"<p>These are the GCC compiler flags needed:</p> <pre><code>-ftree-vectorize    # Enables automatic vectorization while compiling\n-mfpu=neon          # Enables NEON instructions\n-mcpu=cortex-a7     # Indicates the CPU\n</code></pre> <p>This is a sample initialization code:</p> <pre><code>VMRC p15,0,r0,c1,c0,2   // Read CPACR\nORR r0,r0,#0x00f00000   // Enable full access to NEON/VFP by enabling access to Coprocessors 10 and 11\nMCR p15,0,r0,c1,c0,2    // Write CPACR\nISB\nMOV r0,#0x40000000\nVMSR FPEXC,r0           // Set EN bit in FPEXC\n</code></pre> <p>The special NEON registers are described in the next sub-sections.</p>"},{"location":"arm_assembly/simd/#cpacr-coprocessor-access-control-register","title":"CPACR: Coprocessor Access Control Register","text":"<p>This register enables and disables access to all coprocessors, except the 15th one. The value written in each coprocessor state indicate the access permissions:</p> <ul> <li><code>00</code>: Access denied. Any attempt to access the coprocessor generates an Undefined instruction exception.</li> <li><code>01</code>: Privileged access only. Accessing in User mode triggers an Undefined Instruction exception.</li> <li><code>10</code>: Reserved.</li> <li><code>11</code>: Full access.</li> </ul> <p></p>"},{"location":"arm_assembly/simd/#fpexc-floating-point-exception-register","title":"FPEXC: Floating Point Exception Register","text":"<ul> <li><code>[30]</code> Enable bit. If \"1\", the NEON unit and VFP are enabled.</li> </ul>"},{"location":"arm_assembly/simd/#fpscr-floating-point-status-and-control-register","title":"FPSCR: Floating Point Status and Control Register","text":"<p>This register is the same as the CPSR (Current Program Status Register), but used for the NEON registers. The relevant bits are:</p> <ul> <li> <p><code>[31:28]</code> N, Z, C and V flags for NEON operations. They cannot be used to control conditional execution until they have been copied into the status flags in the CPSR.</p> </li> <li> <p><code>[27]</code> QC, cumulative saturation. It's set if saturation occurs in NEON saturating instructions.</p> </li> <li> <p><code>[15, 12:8, 7, 4:0]</code> Enable exception trapping (division by zero, overflow, underflow, etc).</p> </li> </ul>"},{"location":"arm_assembly/simd/#neon-instructions-syntax","title":"NEON instructions syntax","text":"<p>The general syntax is:</p> <pre><code>V{mod}&lt;op&gt;{shape}.&lt;data_type&gt; Q0, Q1, Q2\n</code></pre>"},{"location":"arm_assembly/simd/#modifiers","title":"Modifiers","text":"<ul> <li> <p><code>Q</code>: Saturation. The result is set to either the maximum or minimum if it exceeds the representable range.</p> </li> <li> <p><code>H</code>: Halved. Divide all results by 2 (in reality, shift right one space).</p> </li> <li> <p><code>D</code>: Double before saturation.</p> </li> <li> <p><code>R</code>: Rounded.</p> </li> </ul>"},{"location":"arm_assembly/simd/#shape","title":"Shape","text":"<p>All instructions have the same number of operands and results, but no necessarily the same size. If &lt;shape&gt; is specified, then different size registers can be used for input and output:</p> <ul> <li> <p><code>L</code>: Long. Result is twice as big as input. <code>VADDL.S16 Q0, D2, D3</code>.</p> </li> <li> <p><code>N</code>: Narrow. Result is half as big as input. <code>VADDN.S16 D0, Q1, Q2</code>.</p> </li> <li> <p><code>W</code>: Wide. Result and first operand are twice as big as the second operand. <code>VAddW.S16 Q0, Q1, D4</code>.</p> </li> </ul>"},{"location":"arm_assembly/simd/#neon-and-arm-pipeline","title":"NEON and ARM pipeline","text":"<p>The flow of the program may have several ARM and NEON instructions. The NEON instructions are read from the ARM code flow, and then they are added to the NEON instruction queue of the coprocessors 10 and 11. Next, the main core executes the following ARM instruction in the next clock cycle, while the NEON instruction is being processed in parallel, which might take around 20 cycles.</p> <p>ARM code will continue to execute normally until either the NEON queue gets full, or an operation between NEON and ARM general purpose registers is requested. This last condition puts the instruction as the last element in the NEON queue, and the ARM code flow can't execute the next instruction until all pending NEON instructions are finished.</p>"},{"location":"arm_assembly/simd/#neon-instruction-set","title":"NEON instruction set","text":"<p>Only a subset will be specified. A complete list can be found in the NEON Programmer's Guide. Most instructions specified here support the shape and modifiers.</p> <p>All conditional execution is checked against the ARM CPSR, not the NEON FPSCR. If you want to check if a NEON instruction produced certain result, you have two options:</p> <ul> <li>All logical NEON instructions return \"1\" if true, or \"0\" if false, so you may check against that.</li> <li>Copy FPSCR ALU flags into the CPSR. This operation will halt the ARM core until all NEON instructions are complete.</li> </ul>"},{"location":"arm_assembly/simd/#general-data-processing-instructions","title":"General data processing instructions","text":"<pre><code>vcvt{cond}.&lt;type1&gt;.&lt;type2&gt; qd, qm     // Convert Vector from data_type2 to data_type1\n</code></pre> <pre><code>vdup{cond}.&lt;size&gt; qd, &lt;Rm | Dm[x]&gt;    // Duplicate general purpose register into NEON register.\n</code></pre> <pre><code>vmov{cond}.&lt;type&gt; qd, &lt;#imm | Qm&gt;  // Move immediate value or reg to NEON reg.\nvmvn{cond}.&lt;type&gt; qd, &lt;#imm | Qm&gt;  // Move ~imm value to NEON reg (negated).\n</code></pre>"},{"location":"arm_assembly/simd/#shift-instructions","title":"Shift instructions","text":"<pre><code>vshl{cond}.&lt;type&gt; Qd, Qm, #imm  // Shift left\nvshr{cond}.&lt;type&gt; Qd, Qm, #imm  // Shift right\n</code></pre>"},{"location":"arm_assembly/simd/#logical-and-compare","title":"Logical and compare","text":"<pre><code>If true, \"Qd\" will be equal to all \"1\" in the corresponding bits for each element.\nvacgt.&lt;type&gt; Qd, Qn, Qm     // |Qn| &gt; |Qm|\nvacge.&lt;type&gt; Qd, Qn, Qm     // |Qn| &gt;= |Qm|\nvcgt.&lt;type&gt; Qd, Qn, Qm      // Qn &gt; Qm\nvcge.&lt;type&gt; Qd, Qn, Qm      // Qn &gt;= Qm\nvclt.&lt;type&gt; Qd, Qn, Qm      // Qn &lt; Qm\nvcle.&lt;type&gt; Qd, Qn, Qm      // Qn &lt;= Qm\nvceq.&lt;type&gt; Qd, Qn, Qm      // Qn == Qm\nvceq.&lt;type&gt; Qd, Qn, Qm      // Qn &amp; Qm\n</code></pre> <pre><code>vand{cond}.&lt;type&gt; Qd, Qn, Qm            // Qd = Qn &amp; Qm\nvorr{cond}.&lt;type&gt; Qd, Qn, &lt;#imm | Qm&gt;   // Qd = Qn | Qm\nvbic{cond}.&lt;type&gt; Qd, &lt;#imm | Qm&gt;       // Bit clear. Qd &amp;= ~(imm)\nveor{cond}.&lt;type&gt; Qd, Qn, Qm            // Qd = Qn xor Qm\nvorn{cond}.&lt;type&gt; Qd, Qn, Qm            // Qd = Qn | ~(Qm)\n</code></pre>"},{"location":"arm_assembly/simd/#arithmetic-instructions","title":"Arithmetic instructions","text":"<pre><code>vaba{cond}.&lt;type&gt; Qd, Qn, Qm    // Qd = Qd + |Qn - Qm|\nvabd{cond}.&lt;type&gt; Qd, Qn, Qm    // Qd = |Qn - Qm|\nvabs{cond}.&lt;type&gt; Qd, Qn        // Qd = |Qn|\n</code></pre> <pre><code>vadd{cond}.&lt;type&gt; Qd, Qn, Qm    // Qd = Qn + Qm\nvsub{cond}.&lt;type&gt; Qd, Qn, Qm    // Qd = Qn - Qm\nvneg{cond}.&lt;type&gt; Qd, Qn        // Qd = ~Qn\n</code></pre> <pre><code>vmul{cond}.&lt;type&gt; Qd, Qn, &lt;Qm | Dm[x]&gt;    // Qd = Qn * Qm\nvmla{cond}.&lt;type&gt; Qd, Qn, &lt;Qm | Dm[x]&gt;    // Qd = Qd + Qn * Qm\nvmls{cond}.&lt;type&gt; Qd, Qn, &lt;Qm | Dm[x]&gt;    // Qd = Qd - Qn + Qm\n</code></pre> <pre><code>vmax{cond}.&lt;type&gt; Qd, Qn, Qm    // Qd = Max{Qn, Qm}\nvmin{cond}.&lt;type&gt; Qd, Qn, Qm    // Qd = Min{Qn, Qm}\n</code></pre>"},{"location":"arm_assembly/simd/#load-and-store-instructions","title":"Load and Store instructions","text":"<p>These instructions are used to move values from NEON registers to ARM registers and vice versa. All these instructions stall the ARM code execution until all NEON operations in the queue complete.</p> <pre><code>vmov{cond} Dm, Rd, Rn           // Dm[63:32] = Rd; Dm[31:0] = Rn\nvmov{cond} Rd, Rn, Dm           // Rd = Dm[63:32]; Rn = Dm[31:0]\nvmov{cond}.&lt;type&gt; Dn[x], Rd     // Dn[x] = Rd\nvmov{cond}.&lt;type&gt; Rd, Dn[x]     // Rd = Dn[x]\n</code></pre> <p>Loading/storing single register.</p> <pre><code>vldr{cond} Dm, [Rn{, #offset}]  // Dm = *Rn\nvldr Dm, =&lt;label&gt;               // Dm = *label\nvstr Dm, [Rn{, #offset}]        // *Rn = Dm\nvstr Dm, =&lt;label&gt;               // *label = Dm\n</code></pre> <p>Loading/storing multiple registers.</p> <pre><code>vldm&lt;mode&gt; Rn{!}, &lt;reg_list&gt;\nvstm&lt;mode&gt; Rn{!}, &lt;reg_list&gt;\nvpop &lt;reg_list&gt;\nvpush &lt;reg_list&gt;\n</code></pre> <p>Loading from memory location. <code>&lt;D_reg_list&gt;</code> is a list of \"n\" \"Double word\" registers, where \"n\" is given by the instruction name from 1 to 4. They can be specified in three ways, which vary the instruction functionality:</p> <ul> <li> <p><code>{D0[x], D1[x]}</code>: Load one single element from memory <code>[Rn]</code> to the specified section of the register.</p> </li> <li> <p><code>{D0[], D1[]}</code>: Load one single element from memory <code>[Rn]</code> into all sections of the register.</p> </li> <li> <p><code>{D0, D1}</code>: Load multiple elements from memory <code>[Rn]</code> into the various sections of the registers.</p> </li> </ul> <p>All data must be 8-byte aligned.</p> <pre><code>vld1{cond}.&lt;type&gt; &lt;D_reg_list&gt;, [Rn]{!}\nvld2{cond}.&lt;type&gt; &lt;D_reg_list&gt;, [Rn]{!}\nvld3{cond}.&lt;type&gt; &lt;D_reg_list&gt;, [Rn]{!}\nvld4{cond}.&lt;type&gt; &lt;D_reg_list&gt;, [Rn]{!}\n</code></pre> <p>Storing from memory location.</p> <pre><code>vst1{cond}.&lt;type&gt; &lt;D_reg_list&gt;, [Rn]{!}\nvst2{cond}.&lt;type&gt; &lt;D_reg_list&gt;, [Rn]{!}\nvst3{cond}.&lt;type&gt; &lt;D_reg_list&gt;, [Rn]{!}\nvst4{cond}.&lt;type&gt; &lt;D_reg_list&gt;, [Rn]{!}\n</code></pre> <p>Example</p> <pre><code>.text\nldr r0, =neon_load\nvld2.u16 {d0, d1}, [r0] // D0 = 1 | 2 | 3 | 4 ; D1 = 10 | 20 | 30 | 40\nvadd.u16 d0, d0, d1     // D0 = 11 | 22 | 33 | 44\nvst1.u16 {d0}, [r0]\nldrh r1, [r0], #2\nASSERT_EQ r1, #0x11\nldrh r1, [r0], #2\nASSERT_EQ r1, #0x22\nldrh r1, [r0], #2\nASSERT_EQ r1, #0x33\nldrh r1, [r0], #2\nASSERT_EQ r1, #0x44\n\n.data\n.balign 8\nneon_load:\n    .hword 0x1\n    .hword 0x10\n    .hword 0x2\n    .hword 0x20\n    .hword 0x3\n    .hword 0x30\n    .hword 0x4\n    .hword 0x40\n</code></pre> <p>Loading/storing special registers.</p> <pre><code>vmrs Rd, FPSCR  // Rd = FPSCR\nvmsr FPSCR, Rd  // FPSCR = Rd\n</code></pre>"},{"location":"arm_assembly/simd/#neon-intrinsics-c-library","title":"NEON intrinsics (C library)","text":"<p>Including the header file <code>arm_neon.h</code>, you can use NEON in the C programming language. All functions and data types mapped one to one with a corresponding NEON instruction or register, so no overhead is added.</p> <p>Next, a full list of the NEON data types.</p> <p></p> <p>To access scalar values, as <code>Dm[x]</code>, each data type is defined as a struct with a <code>val</code> vector member:</p> <pre><code>struct int16x4_t {\n    int16_t val[4];\n}\n</code></pre> <p>Variables are defined as any other normal variable.</p> <p>The NEON instructions are called with the same name, but as C functions with arguments. For example, the following are the same in C or assembly:</p> <pre><code>#include &lt;arm_neon.h&gt;\nuint8x8_t a, b, c;\na = vdup_n_u8(0x12);\nb = vl\nc = vadd_u8(uint8x8_t a, uint8x8_t b);\n</code></pre> <pre><code>vadd d0, d1, d2\n</code></pre>"},{"location":"arm_assembly/simd/#recommended-bibliography","title":"Recommended bibliography","text":"<p>Introducing NEON Development Article: An introduction to SIMD and NEON.</p> <p>NEON Programmer's Guide: This is the most complete one, with the full instruction set and examples.</p>"},{"location":"bare_metal/","title":"Bare-metal","text":"<p>This guide explains all the topics related to code execution in an embedded device.</p> <p>This sections is going to be a chronicle about the STM32 Nucleo Board.</p>"},{"location":"bare_metal/#the-stm32f401-nucleo-board","title":"The STM32F401 Nucleo Board","text":"<p>Congratulations, you just bought the STM32F401 Nucleo Board!</p> <p></p> <p>Following the instructions on the webpage, you install the STM32Cube IDE, and start a sample project. Then, configure the pinout using the GUI, and write a simple blinking LED as such:</p> <pre><code>HAL_Delay(1000);\nHAL_GPIO_TogglePin(LD2_GPIO_Port, LD2_Pin);\n</code></pre> <p></p> <p>Then, it is as simple as pressing the \"run\" button on the IDE, and the code is compiled and flashed into the device.</p> <p>However, there are a lot of things that were done under the hood for us. Just look at the project contents:</p> <p></p> <p>From there, we can infer that the following contents were auto-generated:</p> <ul> <li><code>startup_stm32f401retx.s</code>: Bootloader written in assembler, that moves the code from FLASH to RAM to be executed.</li> <li><code>STM32F401RETX_FLASH.ld</code> and <code>STM32F401RETX_RAM.ld</code>: Linker scripts.</li> <li><code>Drivers</code>: Both the CMSIS drivers and the STM HAL library.</li> <li>All source files: Handle clock and peripheral initialization.</li> <li>A cross-compiler toolchain was built for us: When inspecting the terminal, you can see calls to <code>arm-none-eabi-gcc</code>.</li> <li>Debugger and flasher.</li> </ul> <p>It would be foolish to rewrite from scratch the bootloader and linker scripts, adn the GUI for configuring the board is quite convenient!</p> <p>Therefore, what we will do is the following:</p> <ol> <li>Use the CubeIDE to generate all the required files.</li> <li>Configure the device with all the peripherals and pins as needed.</li> <li>Make sure that you have a minimal example working.</li> <li>Migrate everything to your own IDE.</li> </ol>"},{"location":"bare_metal/#installing-cross-compiler-toolchain","title":"Installing cross-compiler toolchain","text":"<p>Let's use crosstool-NG to install the required toolchain.</p> <p>Install a released tarball as indicated in the installation guide.</p> <pre><code>./configure --enable-local\nmake\n./ct-ng help\n\n./ct-ng list-samples\nStatus  Sample name\n[L...]   aarch64-ol7u9-linux-gnu\n[L...]   aarch64-ol8u10-linux-gnu\n[L...]   aarch64-ol8u6-linux-gnu\n[L...]   arm-none-eabi\n[L...]   riscv64-unknown-elf\n[L...]   riscv64-unknown-linux-gnu\n\n\n./ct-ng show-arm-none-eabi\n[L...]   arm-none-eabi\n    Languages       : C,C++\n    OS              : bare-metal\n    Binutils        : binutils-2.45\n    Compiler        : gcc-15.2.0\n    Linkers         :\n    C library       : newlib-4.5.0.20241231 picolibc-1.8.10\n    Debug tools     :\n    Companion libs  : gmp-6.3.0 isl-0.27 mpc-1.3.1 mpfr-4.2.2 newlib-nano-4.5.0.20241231 newlib-nano-4.5.0.20241231 zlib-1.3.1 zstd-1.5.7\n    Companion tools :\n\n./ct-ng arm-none-eabi\n</code></pre> <pre><code>./ct-ng nconfig\n</code></pre> <p>Modifications:</p> <p>Paths and misc options     -&gt; Local tarballs directory ()     -&gt; Prefix directory (\\({CT_PREFIX:-&lt;path_to_repo&gt;/x-tools}/\\){CT_HOST:+HOST-\\({CT_HOST}/}\\)) <p>Target options     -&gt; Default instruction set mode (thumb)     -&gt; Build a multilib toolchain (N)     -&gt; Use the MMU (N)     -&gt; Emit assembly for CPU (cortex-m4)     -&gt; Use specific FPU (fpv4-sp-d16)     -&gt; Floating point: (hardware (FPU))</p> <p>Toolchain options     -&gt; Tuple's vendor string (cotti)     -&gt; Tuple's alias (arm-cortex-m4) # Toolchain will be called like arm-cortex-m4-gcc</p> <p>C-library     -&gt; C library (newlib)</p> <p>C compiler     -&gt; Build libstdcxx (N)</p> <p>Companion libraries     -&gt; newlib-nano (N)     -&gt; picolibc (N)</p> <p>Debug facilities     gdb (Y)</p> <p>After that, build the toolchain with:</p> <pre><code>./ct-ng build\n</code></pre> <pre><code>arm-none-eabi-gcc \"../Core/Src/main.c\" -mcpu=cortex-m4 -std=gnu11 -g3 -DDEBUG -DUSE_HAL_DRIVER -DSTM32F401xE -c -I../Core/Inc -I../Drivers/STM32F4xx_HAL_Driver/Inc -I../Drivers/STM32F4xx_HAL_Driver/Inc/Legacy -I../Drivers/CMSIS/Device/ST/STM32F4xx/Include -I../Drivers/CMSIS/Include -O0 -ffunction-sections -fdata-sections -Wall -fstack-usage -fcyclomatic-complexity -MMD -MP -MF\"Core/Src/main.d\" -MT\"Core/Src/main.o\" --specs=nano.specs -mfpu=fpv4-sp-d16 -mfloat-abi=hard -mthumb -o \"Core/Src/main.o\"\n\narm-none-eabi-gcc -o \"hello_world.elf\" @\"objects.list\"   -mcpu=cortex-m4 -T\"/home/cotti/STM32CubeIDE/workspace_1.19.0/hello_world/STM32F401RETX_FLASH.ld\" --specs=nosys.specs -Wl,-Map=\"hello_world.map\" -Wl,--gc-sections -static --specs=nano.specs -mfpu=fpv4-sp-d16 -mfloat-abi=hard -mthumb -Wl,--start-group -lc -lm -Wl,--end-group\n</code></pre> <p>Note</p> <p>If you have doubts on what to configure here, check the compilation logs from the vendor IDE.</p>"},{"location":"bare_metal/arduino/","title":"Arduino","text":"<p>Let's start with the simplest example: the Arduino Nano.</p> <p>This example is very valuable because not only we will learn about the clone.</p> <p>From the Datasheetarduino_nano_datasheet and the Schematics, we expect our chip to have the following:</p> <p>Expected | actual LM1117 | AMS1117 ATMega328P | ATMega328P FT232RL | CP210x</p> <p></p> <p>The UART-USB adapter's chip does not have any writing on top, is blank.</p> <p>Programming the chip from the Arduino IDE is straight forward:</p> <ul> <li>Install the program.</li> <li>Use one of the example programs in File-&gt;Examples-&gt;01.Basics-&gt;Blink.</li> <li>Select the Arduino Nano in <code>/dev/ttyUSB0</code>.</li> <li>Configure Tools-&gt;Processor-&gt;\"ATmega328P (Old Bootloader)\".</li> <li>Press \"Upload\" button.</li> </ul>"},{"location":"bare_metal/arduino/#identifyng-the-usb-serial-interface","title":"Identifyng the USB-serial interface","text":"<p>Since we now that, when connecting the Arduino, a <code>/dev/ttyUSB0</code> is being created, let's get more info. Starting with <code>dmesg</code>:</p> <pre><code>$ sudo dmesg\n[39612.052359] usb 1-3: new full-speed USB device number 30 using xhci_hcd\n[39612.177275] usb 1-3: New USB device found, idVendor=1a86, idProduct=7523, bcdDevice= 2.54\n[39612.177290] usb 1-3: New USB device strings: Mfr=0, Product=2, SerialNumber=0\n[39612.177293] usb 1-3: Product: USB2.0-Serial\n[39612.211320] usbcore: registered new interface driver ch341\n[39612.211345] usbserial: USB Serial support registered for ch341-uart\n[39612.211363] ch341 1-3:1.0: ch341-uart converter detected\n[39612.212318] usb 1-3: ch341-uart converter now attached to ttyUSB0\n</code></pre> <p>The kernel logs already tells us that the chip used is a \"ch341\", but we lack device path.</p> <pre><code>$ udevadm info -an ttyUSB0\n  looking at device '/devices/pci0000:00/0000:00:14.0/usb1/1-3/1-3:1.0/ttyUSB0/tty/ttyUSB0':\n    KERNEL==\"ttyUSB0\"\n    SUBSYSTEM==\"tty\"\n    DRIVER==\"\"\n\n  looking at parent device '/devices/pci0000:00/0000:00:14.0/usb1/1-3/1-3:1.0/ttyUSB0':\n    KERNELS==\"ttyUSB0\"\n    SUBSYSTEMS==\"usb-serial\"\n    DRIVERS==\"ch341-uart\"\n    ATTRS{port_number}==\"0\"\n\n  looking at parent device '/devices/pci0000:00/0000:00:14.0/usb1/1-3/1-3:1.0':\n    KERNELS==\"1-3:1.0\"\n    SUBSYSTEMS==\"usb\"\n    DRIVERS==\"ch341\"\n\n  looking at parent device '/devices/pci0000:00/0000:00:14.0/usb1/1-3':\n    KERNELS==\"1-3\"\n    SUBSYSTEMS==\"usb\"\n    DRIVERS==\"usb\"\n    ATTRS{idProduct}==\"7523\"\n    ATTRS{idVendor}==\"1a86\"\n    ATTRS{product}==\"USB2.0-Serial\"\n    ATTRS{version}==\" 1.10\"\n</code></pre> <p>TODO check avrdude</p>"},{"location":"bare_metal/openocd/","title":"OpenOCD: On-chip debugger","text":"<p>OpenOCD</p> <p>Install with:</p> <pre><code>sudo apt install openocd\n</code></pre> <p>OpenOCD uses TCL.</p>"},{"location":"bare_metal/openocd/#debug-adapter-hardware","title":"Debug adapter hardware","text":"<p>A dongle is a small device that plugs into a computer and serves as an adapter from the PC's USB port to the electrical JTAG/SWD interface.</p>"},{"location":"bare_metal/openocd/#using-openocd","title":"Using OpenOCD","text":"<p>There are two elements:</p> <ul> <li>The dongle.</li> <li>Te target hardware.</li> </ul> <p>Usually, openocd is executed by calling two configuration scripts:</p> <pre><code>openocd -f interface/ADAPTER.cfg -f board/MYBOARD.cfg\n</code></pre> <p>telnet localhost 4444</p>"},{"location":"bare_metal/openocd/#interfaces","title":"Interfaces","text":"<p>Inside the interface folder, you can see 4 folders than stand out:</p> <p>ftdi:</p> <p>This driver is for adapters using the MPSSE (Multi-Protocol Synchronous Serial Engine) mode built into many FTDI chips, such as the FT2232, FT4232 and FT232H.</p> <p>microchip:</p> <p>ft232r</p> <p>This driver is implementing synchronous bitbang mode of an FTDI FT232R, FT230X, FT231X and similar USB UART bridge ICs by reusing RS232 signals as GPIO.</p> <p>https://github.com/openocd-org/openocd/tree/master/tcl/interface</p>"},{"location":"bare_metal/udev/","title":"Udev: Dynamic device management","text":"<p>Udev rules are a response from user space to new devices created by the kernel space.</p> <p>There are two locations where Udev rules can be found:</p> <ul> <li>For user-written rules: <code>/etc/udev/rules.d</code>.</li> <li>For system-written rules: <code>/usr/lib/udev/rules.d</code></li> </ul> <p>This document is divided in two parts. First, we will define the possible events that can trigger an Udev rule. Then, the actions that can be taken and how to write the actual rules.</p> <p>For reference, you may consult the Arch Linux Wiki, the man pages for udev and udevadm, or this tutorial.</p>"},{"location":"bare_metal/udev/#udev-events-finding-your-device","title":"Udev events: Finding your device","text":"<p>To act upon a device, we first need to know its attributes, like its name, serial number, type, etc. All the properties of a device are stored in a directory inside the linux sysfs at <code>/sys/</code>.</p> <p>There are several ways to find this directory. The first approach is to check the kernel logs. The following output was obtained after disconnecting and connecting an USB mouse:</p> <pre><code>$ sudo dmesg\n[21383.608789] usb 1-1: USB disconnect, device number 6\n[21388.767865] usb 1-1: new low-speed USB device number 7 using xhci_hcd\n[21388.897705] usb 1-1: New USB device found, idVendor=1c4f, idProduct=0048, bcdDevice= 1.10\n[21388.897711] usb 1-1: New USB device strings: Mfr=1, Product=2, SerialNumber=0\n[21388.897713] usb 1-1: Product: Usb Mouse\n[21388.897715] usb 1-1: Manufacturer: SIGMACHIP\n[21388.900928] input: SIGMACHIP Usb Mouse as /devices/pci0000:00/0000:00:14.0/usb1/1-1/1-1:1.0/0003:1C4F:0048.0003/input/input13\n[21388.901030] hid-generic 0003:1C4F:0048.0003: input,hidraw0: USB HID v1.10 Mouse [SIGMACHIP Usb Mouse] on usb-0000:00:14.0-1/input0\n</code></pre> <p>Another way to get the sysfs path is by using the <code>udevadm monitor</code> command, which will listen to kernel events:</p> <pre><code>$ udevadm monitor\nKERNEL[22994.196016] add      /devices/pci0000:00/0000:00:14.0/usb1/1-1/1-1:1.0/0003:1C4F:0048.0013/input/input29/mouse0 (input)\n</code></pre> <p>With the device's path in the sysfs, you can get all its info and its parents' info with the <code>udevadm info</code> command:</p> <pre><code>$ udevadm info -ap /devices/pci0000:00/0000:00:14.0/usb1/1-1/1-1:1.0/0003:1C4F:0048.0013/input/input29/mouse0\n  [...]\n  looking at device '/devices/pci0000:00/0000:00:14.0/usb1/1-1/1-1:1.0/0003:1C4F:0048.0013/input/input29/mouse0':\n    KERNEL==\"mouse0\"\n    SUBSYSTEM==\"input\"\n    DRIVER==\"\"\n  [...]\n  looking at parent device '/devices/pci0000:00/0000:00:14.0/usb1/1-1':\n    KERNELS==\"1-1\"\n    SUBSYSTEMS==\"usb\"\n    DRIVERS==\"usb\"\n    ATTRS{idProduct}==\"0048\"\n    ATTRS{idVendor}==\"1c4f\"\n    ATTRS{manufacturer}==\"SIGMACHIP\"\n    ATTRS{product}==\"Usb Mouse\"\n</code></pre> <p>By convention, the device's attributes are singular <code>ATTR{}</code>, while their parents's are plural <code>ATTRS{}</code>.</p> <p>The same information can be retrieved by using the device node name in the <code>/dev</code> directory, with:</p> <pre><code>udevadm info -an /input/mouse0\n</code></pre>"},{"location":"bare_metal/udev/#udev-rules-actions-on-devices","title":"Udev rules: actions on devices","text":"<p>All Udev rules consist of two parts:</p> <ol> <li>The \"match\" part: defines the conditions for the rule to be applied. These conditions are usually a list of attributes that the device and its parents must have to be recognized as the target device.</li> <li>The \"action\" part: defines the actions to be performed when the conditions are met.</li> </ol> <p>The syntax for the rule is a series of comma-separated keys with an operator and a value:</p> <pre><code>&lt;KEY&gt;&lt;OPERATOR&gt;&lt;VALUE&gt;, &lt;KEY&gt;&lt;OPERATOR&gt;&lt;VALUE&gt;\n</code></pre> <p>The following is an example Udev rule that detects when the USB mouse gets connected and creates a symbolic link in <code>/dev/mymouse</code>, and a log file in <code>tmp/udev_log.txt</code>.</p> <pre><code>ACTION==\"add\", \\\nKERNEL==\"mouse*\" \\\nSUBSYSTEMS==\"usb\", \\\nATTRS{idProduct}==\"0048\", \\\nATTRS{idVendor}==\"1c4f\", \\\nSYMLINK+=\"mymouse\", \\\nRUN+=\"/bin/bash -c 'echo Mouse_connected &gt;&gt; /tmp/udev_log.txt'\"\n</code></pre> <p>The operator can be any of the typical assignment (<code>=</code>, <code>+=</code>, <code>-=</code>) or comparison (<code>==</code>, <code>!=</code>) ones.</p> <p>The full list of keys and operators can be found in the Udev man page. The following is a summary of the most important keys:</p> Key Description ACTION Match the name of the event action. There are only four meaningful types: <code>add/remove</code> when the device node in <code>/dev</code> is created/removed, and <code>bind/unbind</code>, when the driver is attached/detached. KERNEL[S] Match the name of the event device [or of its parents] SUBSYSTEM[S] Match the subsystem of the event device [or of its parents] DRIVER[S] Match the driver event of the event device [or of its parents] ATTR[S]{filename} Match sysf attribute value of the event device [or of its parents]. \"filename\" is an actual file located in the sysfs. OWNER, GROUP, MODE Set the permissions for the device node. RUN Execute a program. It must be a named script with arguments. SYMLINK Creates a symbolic link in <code>/dev/</code>. This will only work if the device already creates a device node in <code>/dev/</code>, for example <code>/dev/ttyUSB0</code>."},{"location":"bare_metal/udev/#executing-the-rule","title":"Executing the rule","text":"<p>The rules start with a number, such as <code>66-my-udev.rules</code>, and are processed in lexical order, meaning that the lower the number, the higher the priority.</p> <p>Create a file inside the <code>/etc/udev/rules.d</code> directory and reload Udev to detect your new rule:</p> <pre><code>sudo udevadm control --reload\n</code></pre> <p>After that, you may simulate the events generated by a device by using <code>udevadm test</code>. You can see that the \"run\" commands are prepared to execute, but they won't actually be executed.</p> <pre><code>udevadm test &lt;device_path&gt;\n</code></pre>"},{"location":"bare_metal/interfaces/interfaces_overview/","title":"Interfaces: the connection from the target to the real world","text":"<p>When working with embedded devices, the focus is always on the application: write your code, press some magic button in a GUI, and see how it magically starts executing in the target.</p> <p>The process of flashing and debugging the code is different for each chip vendor. In this section, we will try to shed light on the matter in order to avoid depending on vendor-locked solutions.</p> <p>The following table is a comparison of commercially available debuggers<sup>1</sup>, pointing their price and the targets they work on:</p> Debugger Price<sup>2</sup> [U$D] Comments J-Link $450 Works with almost any device. Lauterbatch TRACE32 $5000 Expensive, vendor-specific. JTAG Live $5000 Expensive, vendor-specific. ST-LINK/V3 $35 Only works for STM chips. Black Magic Probe $75 x FTDI based module $30 Compatible with OpenOCD, configurable. CP21XX based module $40 Only works for USB-to-UART. <p>My two cents is that debuggers are expensive because of ignorance. People pay for what they don't know.</p> <p>The following sections give a brief introduction to each debugger, but the focus is in the FTDI debuggers.</p>"},{"location":"bare_metal/interfaces/interfaces_overview/#ftdi-based-probes","title":"FTDI based probes","text":"<p>TODO</p>"},{"location":"bare_metal/interfaces/interfaces_overview/#black-magic-probe","title":"Black Magic Probe","text":"<p>The Black Magic Probe (BMP) goes for just $75 bucks. However, it</p>"},{"location":"bare_metal/interfaces/interfaces_overview/#st-link","title":"ST-LINK","text":""},{"location":"bare_metal/interfaces/interfaces_overview/#segger-j-link","title":"SEGGER J-Link","text":"<p>Check: https://www.segger.com/products/debug-probes/j-link/models/other-j-links/st-link-on-board/</p> <p>The old J-Link we all know and love. The J-Link BASE and the J-Link PLUS are the exact same hardware, the only difference being than the PLUS comes with extra software licenses, Ozone, the GUI debugger.</p> <p>The BASE only gives you access to the J-Link Commander, a CLI tool that can only be used for flashing programs and debugging.</p> <p>The hardware goes at $450, while the [Ozone software][ozone] has a free license for students and non commercial use, but for commercial goes at $1000.</p> <p>With JLink Commander, you can:</p> <ul> <li>Connect to the target MCU via JTAG or SWD.</li> <li>Ran and write memory addresses.</li> <li>Load and program flash (.elf, .bin, .hex).</li> <li>Control execution with debugging instructions.</li> <li>Reset target.</li> <li>Get device information (detect core, flash size, etc).</li> <li>SWO/UART logging</li> </ul> <p>JLink.exe -CommanderScript flash.jlink</p> <p>For example, this jlink script programs the STM32F401:</p> <pre><code>; Specify device and SWD interface speed\ndevice STM32F401RE\nif SWD\nspeed 4000\n\n; Reset, halt and erase flash\nr\nh\nerase\n\n; Load binary into memory address\nloadbin firmware.bin, 0x08000000\nverifybin firmware.bin, 0x08000000\n\n; Reset and run\nr\ngo\nexit\n</code></pre> <p>JLINK is primarly a flasher / debugger with a JTAG interface. For boundary-scan, you need to use external tools that talk to JLink.</p> <p>The JTAG interface only specifies 5 pins, but the JLink device has a pinout of 20. Most of them are boilerplate GND and extra signals that aren't really needed.</p> <p></p>"},{"location":"bare_metal/interfaces/interfaces_overview/#lauterbach-and-jtag-technologies","title":"Lauterbach and JTAG Technologies","text":"<p>All these companies are really expensive. They are meant to be used for companies only, since the real value comes from the proprietary software and customer support.</p> <p>Basically, by buying an using these products you are paying their engineers to solve your problems. You don't get any real experience or knowledge besides on how to use their products, since they purposefully abstract everything to make you reliant on their solutions.</p> <p>I can only think of one specific use case for these devices, and that is if you absolutely a very high speed debugging interface with a large memory to store trace information.</p> <ol> <li> <p>The words debugger, flasher and probe are using indistinctly and all refer to a device capable of accessing the chip's registers and memories.\u00a0\u21a9</p> </li> <li> <p>Prices include hardware + software.\u00a0\u21a9</p> </li> </ol>"},{"location":"bare_metal/interfaces/jtag/","title":"JTAG/Boundary-scan","text":""},{"location":"bare_metal/interfaces/jtag/#background","title":"Background","text":"<p>JTAG/Boundary-scan comes from the 1149.1-2013 - IEEE Standard for Test Access Port and Boundary-Scan Architecture.</p> <p>The actual technology is Boundary-scan, JTAG refers to the creators: the Joint Test Action Group. However, nowadays every talks about the \"JTAG technology\".</p> <p>Boundary-scan was born as a solution to properly test embedded devices. At the beginning, when almost all components were Through-Hole, you could use a \"bed of nails\" to access all the pins of an IC and forcefully inject and read signal values. Nowadays, with all components being SMD, it is not possible. How can you know if one of the BGA balls from the chip is not soldered properly?</p> <p></p> <p>Boundary-scan, as its name implies, can read and write all the externals pins of an IC (in the \"boundary\" of the IC). You connect to the device by a 5-signal Test Access Port (TAP). Configure some internal registers, and then choose the electrical state of the pins by writing to the TDI pin, and read their electrical state from the TDO pin.</p> <p>Boundary-scan relies on the fact that each pin of the IC must have a multiplexor that connects it to the Core or to a Drive/Sense cell (D/S cell).</p> <p></p> <p>The following image shows a full board being tested with Boundary-scan. In yellow lines, all the external pins of the devices are being driven to connect to every component of the board: memories, I2C devices, etc.</p> <p></p> <p>I recommend watching the Webinars from JTAG Technologies, specially the \"Introduction to boundary-scan\" and \"Programming Devices via the JTAG Interface\". Also, the JTAG Technologies page in general has good \"general culture\" documentation on this topic that is worth looking, specially the tutorial and the boundary-scan overview</p>"},{"location":"bare_metal/interfaces/jtag/#jtag-programming","title":"JTAG programming","text":"<p>There are two ways to program a device:</p> <p>The indirect method uses the Boundary-scan register to drive external boot devices connected to pins of the IC, like a NOR/NAND flash or a serial flash with I2C/SPI interface.</p> <p></p> <p>The direct method uses the Emulation/Debug mode of the JTAG standard. It is used to control things inside the Core, like an integrated Flash in the chip that cannot be accessed from externals pins.</p> <p></p>"},{"location":"bare_metal/interfaces/jtag/#physical-connection","title":"Physical connection","text":"<p>The Test Access Port (TAP) only has 4 compulsory pins, with an optional fifth:</p> <ul> <li>TCK (Test Clock).</li> <li>TMS (Test Mode Select). Changes on rising edge.</li> <li>TDI (Test Data Input). Changes on rising edge.</li> <li>TDO (Test Data Out). Changes on falling edge.</li> <li>TRST* (Test Reset). Optional, resets controller when \"0\".</li> </ul>"},{"location":"bare_metal/interfaces/jtag/#state-machine","title":"State machine","text":"<p>The state diagram for boundary-scan is shown below (IEEE section 6):</p> <p></p> <p>It has two modes: either to read the data registers (DR) or the instruction registers (IR).</p> <p>During the Capture-DR, data is loaded into the shift register.</p> <p>When in Shift-DR, the test data register connected between TDI and TDO shifts data from TDI, one stage toward its serial output, and to TDO.</p> <p>The state machine will enter Test-Logic-Reset when TMS is held high for at least five rising edged of TCK.</p>"},{"location":"bare_metal/interfaces/jtag/#instruction-registers","title":"Instruction registers","text":"<p>Instructions define what data register is connected between the TDI and TDO ports, as well as the state of the Drive/Select cells.</p> <p>The full list of instructions can be found in Section 8 of the IEEE norm.</p> <p>TODO make a table.</p> <p>BYPASS: IDCODE: RUNBIST: (etc):</p>"},{"location":"bare_metal/interfaces/jtag/#data-registers","title":"Data registers","text":"<p>TODO</p>"},{"location":"bare_metal/interfaces/jtag/#bsdl-boundary-scan-description-language","title":"BSDL: Boundary Scan Description Language","text":""},{"location":"bare_metal/interfaces/stlink/","title":"STLINK","text":"<p>During this section I want to focus on the importance of the first communication with the board: How to flash your program into the board, how to debug it and how to communicate with a UART.</p> <p>Most development boards come with an USB interface that iss plug-and-play, but let's review what's happening under the hood.</p>"},{"location":"bare_metal/interfaces/stlink/#swd","title":"SWD","text":""},{"location":"bare_metal/interfaces/stlink/#stm32","title":"STM32","text":""},{"location":"bare_metal/interfaces/stlink/#nxp","title":"NXP","text":"<p>Nucleo</p> <p>Manual</p>"},{"location":"bare_metal/interfaces/swd/","title":"SWD: Serial Wire Debug","text":"<p>The SWD interface forms part of the ARM Debug Interface Architecture Specification (ADIv5). SWD just represents the actual physical connection to the whole ADI architecture, which can also be accessed with a JTAG interface.</p> <p>Everything that can be done with a JTAG can be done via SWD provided that the target ARM core supports it.</p> <p>The application note AN11553 from NXP is a great introduction to the whole architecture.</p> <p>ISP (In-System Programming) over serial connections.</p> <p>IAP (In-Application Programming)</p>"},{"location":"bare_metal/interfaces/usb_uart/","title":"USB-UART interfaces: talk to me, board","text":"<p>The USB protocol is something that you need dedicated hardware for. If your chip doesn't have it, then you will need one of these chips for communicating from the board to the PC or vice versa.</p> <p>In this section we will review the different alternatives to achieve data transfers from an embedded device to a computer, without directly using USB or Ethernet.</p>"},{"location":"bare_metal/interfaces/usb_uart/#semihosting","title":"Semihosting","text":"<p>There</p>"},{"location":"bare_metal/interfaces/usb_uart/#the-serial-protocols","title":"The Serial protocols","text":"<p>This serial protocols are meant to transmit UART signals outside of a PCB board, for distances greater than a meter.</p> <p>Most serial protocols like UART, SPI, I2C use TTL levels, from 0V to either 1.8V, 3.3V or 5V. The main purpose of the standards shown below is to have greater voltage swings, between -15V and 15V, to defend against noise.</p>"},{"location":"bare_metal/interfaces/usb_uart/#rs-232","title":"RS-232","text":"<p>The original RS-232 standard defines 9 pins, and was used with a DE-9 serial port. Nowadays, you only see either a 3-wire variation, using only Tx, RX and GND, or a 5-wire variation with RTS/CTS handshaking.</p> <p>The meaning of the signals is as follows:</p> Acronym Signal Direction Functions TxD Transmitted Data Out Carries data to other device. RxD Received Data In Carries data into the device. GND Common Ground Common Zero voltage reference. RTS/RTR Request To Send / Ready To Receive Out The device can receive data from the RxD pin. If RTS is \"0\", all data received through the \"RxD\" pin won't be read. CTS Clear To Send In Data can be sent to the other device through the TxD pin. If CTS is \"0\", all data sen't through the TxD pin won't be read by the other device. <pre><code>        DEVICE A                                   DEVICE B\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      UART / MCU      \u2502                   \u2502      UART / MCU      \u2502\n\u2502                      \u2502                   \u2502                      \u2502\n\u2502   TX \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 RX                   \u2502\n\u2502                      \u2502                   \u2502                      \u2502\n\u2502   RX \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 TX                   \u2502\n\u2502                      \u2502                   \u2502                      \u2502\n\u2502  RTS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 CTS                  \u2502\n\u2502      (I can receive) \u2502                   \u2502 (You may send to B)  \u2502\n\u2502                      \u2502                   \u2502                      \u2502\n\u2502  CTS \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 RTS                  \u2502\n\u2502 (You may send to A)  \u2502                   \u2502  (I can receive)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>The RTS/RTR pin may be confusing for its name. It shares two functions:</p> <ul> <li>The RTS (Request To Send) is assumed to be always asserted, that is, a device is always ready to send data. If it isn't ready, then it just won't send new data.</li> <li>The RTR (Ready To Receive) is the one that is electrically controlled. When asserted, the device can receive data through the \"RX\" pin.</li> </ul> <p></p>"},{"location":"bare_metal/interfaces/usb_uart/#rs-422","title":"RS-422","text":"<p>The RS-422 standard only defines RX and TX as differential pairs. It supports one transmitter and up to 10 receivers.</p> <p>The cable must be though like a transmission line. A parallel termination resistor of 100 or 120 Ohms is required for signal integrity, which matches the characteristic impedance (Z0) of most twisted pair cables.</p> <p></p>"},{"location":"bare_metal/interfaces/usb_uart/#rs-423","title":"RS-423","text":"<p>The RS-423 is very similar to the RS-422, but it is single ended with a GND signal. This standard is seldom used.</p>"},{"location":"bare_metal/interfaces/usb_uart/#rs-485","title":"RS-485","text":"<p>The RS-485 is fully compatible with the RS-422. It also uses differential signaling, but allows for 10 transmitters and 32 receivers. Transmitters have three-state logic, and only one at the time can transmit to avoid bus contention.</p> Specifications RS-232 RS-423 RS-422 RS-485 Mode of Operation Single-Ended Single-Ended Differential Differential Total Drivers/Receivers on One Line 1 Driver / 1 Receiver 1 Driver / 10 Receivers 1 Driver / 10 Receivers 1 Driver / 32 Receivers Maximum Cable Length 15 m 1200 m 1200 m 1200 m Maximum Data Rate 460 kb/s 100 kb/s 10 Mb/s 30 Mb/s Maximum Driver Output Voltage \u00b125 V \u00b16 V \u20130.25 V to +6 V \u20137 V to +12 V Driver Output Level (Loaded, Min.) \u00b15 V to \u00b115 V \u00b13.6 V \u00b12.0 V \u00b11.5 V Driver Output Level (Unloaded, Max.) \u00b125 V \u00b16 V \u00b16 V \u00b16 V Driver Load Impedance (\u03a9) 3k\u20137k \u2265450 100 54 Max Driver Current (High-Z, Power On) N/A N/A N/A \u00b1100 \u00b5A Max Driver Current (High-Z, Power Off) \u00b16 mA @ \u00b12 V \u00b1100 \u00b5A \u00b1100 \u00b5A \u00b1100 \u00b5A Slew Rate (Max) 30 V/\u00b5s Adjustable N/A N/A Receiver Input Voltage Range \u00b115 V \u00b112 V \u201310 V to +10 V \u20137 V to +12 V Receiver Input Sensitivity \u00b13 V \u00b1200 mV \u00b1200 mV \u00b1200 mV Receiver Input Resistance (\u03a9) 3k\u20137k \u22654k \u22654k \u226512k <p></p> <p>Sources: OPTCORE and RS-423.</p>"},{"location":"bare_metal/interfaces/usb_uart/#the-usb-serial-devices-in-linux","title":"THe USB-Serial devices in Linux","text":"<p>/dev/ttyUSBx /dev/ttyACMx</p> <p>HID USB Virtual COM USB</p> <p>RS232</p> <p>RS484</p>"},{"location":"bare_metal/interfaces/usb_uart/#chip-vendors","title":"Chip vendors","text":"<p>There are basically three main chip vendors for UART-USB interfaces. They are ordered from most expensive and reliable to cheapest.</p> <p>The FTDI</p> Vendor Chip number Price Comment FTDI"},{"location":"bare_metal/interfaces/usb_uart/#cp21xx-only-uart-usb","title":"CP21XX: only UART-USB","text":"<p>[CP21XX][cp_modules] from Silicon Labs</p> <p>This is the one I have (check todo micro purchase).</p>"},{"location":"bare_metal/interfaces/usb_uart/#ch340","title":"CH340","text":""},{"location":"bare_metal/interfaces/usb_uart/#ftdi-chips","title":"FTDI chips","text":""},{"location":"build_systems/","title":"Build systems","text":""},{"location":"build_systems/cmake/","title":"CMake: A little messy but gets the job done","text":"<p>CMake is powerful, but hard to master. The main issue with CMake is that its syntax is too convoluted, and to do anything you have to consult the documentation. Whenever I learn CMake, I automatically forget how to use it the next week, and I have to return to the tutorials.</p> <p>Next, a quick guide is provided to learn how to compile C and C++ projects, together with an associated example in this repository.</p>"},{"location":"build_systems/cmake/#quick-guide","title":"Quick guide","text":"<p>Below is a list of the commands needed to build, install and execute a CMake project, with a <code>CMakeLists.txt</code> file:</p> <pre><code>mkdir build\ncd build\ncmake ..\ncmake --build .\ncmake --install . --prefix $(pwd)/../install\n../install/bin/tuto\n</code></pre>"},{"location":"build_systems/cmake/#cmakeliststxt-reference","title":"CMakeLists.txt reference","text":"<p>All compilation, linking, and installation instructions must be written in a <code>CMakeLists.txt</code> file in the project's root directory.</p>"},{"location":"build_systems/cmake/#initial-setup","title":"Initial setup","text":"<p>Setup the CMake version, C language standard, and the project's name.</p> <pre><code>cmake_minimum_required(VERSION &lt;version_number&gt;)\n\nproject([PROJECT_NAME])\n\nset(CMAKE_CXX_STANDARD 11)\nset(CMAKE_CXX_STANDARD_REQUIRED True)\n</code></pre>"},{"location":"build_systems/cmake/#adding-source-files","title":"Adding source files","text":"<p>A <code>target</code> represents an executable file to be compiled. The list of required source files to compile that target must be provided.</p> <pre><code>add_executable(\n    [target_name]\n    [sources ...]\n)\n</code></pre>"},{"location":"build_systems/cmake/#adding-a-library","title":"Adding a library","text":"<p>If the target requires linking to a library, it can be created and then added for linking as follows.</p> <pre><code>add_library(\n    [library_target_name]\n    [sources...]\n)\n\ntarget_link_libraries(\n    &lt;target_name&gt;\n    PUBLIC|PRIVATE|INTERFACE &lt;library_target_name&gt;\n)\n</code></pre> <p>The <code>PUBLIC|PRIVATE|INTERFACE</code> establishes the way in which the library will be included:</p> <ol> <li> <p><code>PUBLIC</code>: Can be seen by the target and every other target that links with it.</p> </li> <li> <p><code>PRIVATE</code>: Can only be seen by the calling target.</p> </li> <li> <p><code>INTERFACE</code>: Can only be seen by subsequent targets, not by the target that included it.</p> </li> </ol>"},{"location":"build_systems/cmake/#adding-header-files","title":"Adding header files","text":"<p>An include directory, where all <code>*.h</code> headers files are stored, can be defined with:</p> <pre><code>target_include_directories ([target_name] [PUBLIC|PRIVATE|INTERFACE] [header_folders ...])\n</code></pre>"},{"location":"build_systems/cmake/#miscellaneous","title":"Miscellaneous","text":"<p>It's possible to define a subdirectory with a nested <code>CMakeLists.txt</code> file to be executed with:</p> <pre><code>add_subdirectory([path_to_CMakeLists.txt])\n</code></pre> <p>A custom linux shell command can be executed with the following syntax:</p> <pre><code>add_custom_command(\n    OUTPUT [output_file]\n    WORKING_DIRECTORY [path]\n    COMMAND [linux command]\n    COMMENT [What to print in terminal]\n    DEPENDS [file]\n)\n</code></pre>"},{"location":"build_systems/cmake/#installation-commands","title":"Installation commands","text":"<p>The installation process consists of cleaning up and moving around the binaries generated, as a mean to expose only useful files to the user, and hide all the compilation ones.</p> <pre><code>install(\n    TARGETS|FILES|DIRECTORY [element]\n    DESTINATION [directory_path]\n)\n</code></pre>"},{"location":"build_systems/cmake/#variables","title":"Variables","text":"<p>A variable, accessible from the <code>CMakeList.txt</code> file, can be created as:</p> <pre><code>set([VAR_NAME] [var_value])\n</code></pre> <p>And be read as follows:</p> <pre><code>${VAR_NAME}\n</code></pre> <p>Some common global variables defined for every CMake project are:</p> <pre><code>${CMAKE_SOURCE_DIR}\n${CMAKE_CURRENT_SOURCE_DIR}\n${CMAKE_BINARY_DIR}\n${CMAKE_CURRENT_BINARY_DIR}\n${PROJECT_SOURCE_DIR}\n${PROJECT_BINARY_DIR}\n</code></pre>"},{"location":"build_systems/makefile/","title":"Makefile: the first and last choice for build systems","text":"<p>The author has mixed feelings about GNU Make. On the one hand, it is a great tool, simple to setup and gives you full control of the compilation chain. On the other hand, it gets hard to maintain for large code bases, and the syntax is hard to read or follow. Nevertheless, understanding Makefiles is a required skill because of the sheer volume of projects that use it as their build system.</p> <p>In my personal experience, you start writing a Makefile in the first steps of a project and, as the code base grows larger, you either end up maintaining a brittle Frankenstein of a build system or you migrate to something more powerful and standard.</p> <p>Makefile Tutorial is a great introduction to the topic. In the next section a more succinct explanation is given on the topic.</p> <p>A comprehensive Makefile example can be found in this repository.</p>"},{"location":"build_systems/makefile/#what-is-a-makefile","title":"What is a Makefile","text":"<p>A Makefile is a shell script with extra steps. Its most prominent feature is the fact that it will execute a list of commands conditionally based on the last modification date of the source files.</p> <p>The building blocks of Makefiles are recipes, which have the syntax shown below. Both targets and prerequisites refer to actual files in your file system, with their path relative to the Makefile. All prerequisites must be existing files or must be other targets in the Makefile with instructions to generate those files.</p> <pre><code>targets: prerequisites\n    command\n    command\n</code></pre> <p>The recipe will be executed based on the following conditions:</p> <ul> <li>Any of the prerequisites have a modification date newer than the target.</li> <li>The target doesn't exist.</li> <li>It is a <code>.PHONY:</code> target (see Special Targets).</li> </ul> <p>Prerequisites can also be targets, with their own commands associated. Order of execution goes from left to right for the prerequisites, and it is the same for the targets.</p> <p>Targets work as menu entries. Executing <code>make</code> on the terminal will process the first target. Calling <code>make &lt;target&gt; [VAR=VALUE ...]</code> will execute the target <code>target</code>, and can be passed a list of environmental variables.</p>"},{"location":"build_systems/makefile/#how-to-write-a-makefile","title":"How to write a Makefile","text":"<p>Under the hood, Makefiles are just a collection of Bash commands. However, <code>make</code> works as a preprocessor and therefore has its own syntax and functions.</p> <p>It is strongly encouraged to use Make's functions and variables. If possible, try to avoid using pure Bash syntax and try to find a Make function to replace that functionality.</p>"},{"location":"build_systems/makefile/#makefile-variables","title":"Makefile variables","text":"<p>There are only two useful assignment operators for variables:</p> <ul> <li>Use <code>var := value</code> for imperative assignment.</li> <li>Use <code>var ?= value</code> for default value assignment (the variable <code>var</code> will only take the value <code>value</code> if it wasn't assigned before).</li> </ul> Info <p>There is a third type of assignment called recursive: <code>=</code>, which is confusing and not recommended. For example, if you have the variable <code>var = $(some_value)</code>, the actual value of <code>var</code> will get resolved at the moment the variable is used, not when it is defined.</p> <p> <pre><code>y = \"old_value\"\nimperative_var := $(y)\nrecursive_var = $(y)\ny = \"new_value\"\n\nall:\n    @echo $(imperative_var) # prints old_value\n    @echo $(recursive_var)  # prints new_value\n</code></pre></p> <p>They are used with <code>$(var)</code>. Their values are literal, and special characters such as quotes <code>\"</code> or inline comments will be included in the value. Bash variables, on the other hand, must be used with a double dollar sign <code>$${var}</code>. All Makefile variables will be replaced with its value before executing any instruction, and can be used as targets or prerequisites.</p> <p>You can <code>export</code> Make variables to use them in shell commands as such:</p> <pre><code>export MAKE_VAR = some_value\nall:\n    @echo $${MAKE_VAR}  # Prints \"some_value\"\n</code></pre>"},{"location":"build_systems/makefile/#automatic-variables","title":"Automatic variables","text":"<p>Full list of Automatic Variables.</p> <ul> <li><code>$@</code>: name of the target.</li> <li><code>$^</code>: all the prerequisites, separated by spaces.</li> <li><code>$?</code>: all the prerequisites newer than the target, separated by spaces.</li> <li><code>$&lt;</code>: the first prerequisite.</li> </ul>"},{"location":"build_systems/makefile/#implicit-variables","title":"Implicit variables","text":"<p>The usage of implicit rules won't be discussed. However, there is a list of standard variables that is good to use, and you might have seen in other Makefiles like <code>CC, CFLAGS, CXX, CXXFLAGS</code> and so on.</p> <p>The important thing to remember is that these variables should always be defined with a default value using <code>?=</code>, and allow the user to modify them from the command line. E.g., running <code>make CC=clang</code> will replace the compiler (1).</p> <ol> <li>Just writing <code>CC ?= &lt;value&gt;</code> would not resolve, because <code>CC</code> always has the default value <code>CC = cc</code>.</li> </ol> <pre><code>ifeq ($(origin CC), default)\n    CC := $(TOOLCHAIN)gcc\nelse\n    CC ?= $(TOOLCHAIN)gcc\nendif\n\nCFLAGS ?= -Wall -g\n</code></pre>"},{"location":"build_systems/makefile/#makefile-functions","title":"Makefile functions","text":"<p>Make functions replace the most common operations needed for path and string manipulation. Here is a short list of the most useful ones:</p> <pre><code># Replace \"pattern\" with \"replacement\" in all\n# whitespace-separated words in \"text\"\n$(patsubst pattern, replacement, text)\n\n# Add \"prefix\" to whitespace-separated \"names\"\n$(addprefix prefix, names\u2026)\n\n# \"list\" is the iterable, \"var\" is the iterator's value (represented as\n# a variable), and \"text\" is what it is done for each \"var\"\n$(foreach var, list, text)\n</code></pre>"},{"location":"build_systems/makefile/#wildcards","title":"Wildcards","text":"<p>Instead of using the <code>*</code> glob expansion for files, it is recommended to use the function <code>$(wildcard *.c)</code><sup>1</sup>.</p> <p>The stem operator <code>%</code> is used for Static Pattern rules. It always appears in pairs: given a glob expansion from a source filename with <code>%</code>, the content that was inferred gets stored in the literal <code>%</code>, and is replicated to form a target filename.</p> <p>Typical usages are to construct recipes, or in functions as shown below:</p> <pre><code>SRCS ?= file1.c file2.c\nOBJS ?= $(patsubst %.c, %.o, $(SRCS))\n\n%.o: %.c\n    command\n</code></pre>"},{"location":"build_systems/makefile/#special-targets-modify-makefiles-default-behavior","title":"Special targets: modify Makefile's default behavior","text":"<p>The following special targets modify the default behavior of the Makefile:</p> Target Default behavior When used <code>SHELL = &lt;shell&gt;</code> Executes commands in <code>/bin/sh</code>. Uses <code>&lt;shell&gt;</code> as the shell. <code>.ONESHELL:</code> Each command is executed in a separate shell. All the commands in a recipe execute in the same shell session. <code>.POSIX:</code> Abort execution on the first shell session returning non zero (if <code>.ONESHELL:</code> is enabled, only the return value of the whole recipe is checked, intermediate commands are allowed to fail). Abort execution on the first command returning non zero, even if <code>.ONESHELL</code> is used. <code>EXPORT_ALL_VARIABLES:</code> Makefile variables are not seen from shell commands, unless explicitly declared with <code>export</code>. All Makefile variables are implicitly exported, and can be seen by shell commands. <code>.DELETE_ON_ERROR:</code> If an error occurs while compiling a target, and the namesake file was generated, it won't be deleted. The target file is deleted on error. <code>.SILENT:</code> Prints to stdout the command being executed and its stdout. If the command starts with an <code>@</code>, then only stdout is printed. Only stdout is printed (as if an implicit <code>@</code> were added before all commands). <code>.DEFAULT_GOAL := &lt;target&gt;</code> The first target in the file is executed when calling <code>make</code>. The target set as the default goal is executed when calling <code>make</code>. <code>.PHONY: &lt;target&gt;</code> The target's commands will be run only if any of the prerequisites are older than the target. If there are no prerequisites, the target won't run if a namesake file exists. The target will always run, regardless of prerequisites. <ol> <li> <p>If <code>*.c</code> is used, this will expand to all files ending in <code>.c</code>, but in the case that no file matches the pattern, it will print the literal <code>*.c</code>. In contrast, <code>$(wildcard *.c)</code> will print an empty string if the are no matches.\u00a0\u21a9</p> </li> </ol>"},{"location":"ci/","title":"CI/CD: Continuous Integration / Continuos Delivery","text":"<p>What is CI/CD? The short answer is: CI = <code>make all</code>, CD = <code>make install</code>. The long answer is that CI is a set of instructions (like compiling or running tests) executed on specific events (like creating pull request or pushing new code), while CD is a set of instructions that deploys the built application into a server or a production environment.</p> <p>This section is going to be a quick tutorial to get some basic workflows running with GitHub Actions. To get started quickly, go check a list of workflow templates.</p>"},{"location":"ci/#github-actions","title":"GitHub Actions","text":"<p>You can configure a workflow, a set of instructions, to be triggered when an event occurs in your repository, such as pull request being opened or an issue being created.</p> <p>All workflows are declared inside the <code>.github/workflows</code> directory, and are perfectly defined by the following components:</p> <ul> <li>The event that initiates the workflow.</li> <li>The runner, where the workflow is executed.</li> <li>The jobs, sets of instructions to be executed.</li> </ul> <p>These three elements are highlighted in the following example workflow, and further explained in the following pages.</p> <pre><code>on: [push]                  # The event: pushing to the repo\njobs:\n  job-name:                 # The job: commands to be executed\n    runs-on: ubuntu-latest  # The runner: VM with ubuntu-latest\n    steps:\n      - uses: actions/checkout@v5\n      - run: echo \"hello workflows\n</code></pre>"},{"location":"ci/#github-expressions","title":"GitHub expressions","text":"<p>The <code>${{ &lt;variable | expression&gt; }}</code> operator, with double braces makes the GitHub workflow runner execute the expression inside and return its result, or substitute the variable's value. All <code>${{ }}</code> are resolved before the workflow is executed<sup>1</sup>.</p> <ol> <li> <p>A common confusion arises with the <code>${variable}</code> operator, which is just Bash's variable substitution that gets replaced at run-time.\u00a0\u21a9</p> </li> </ol>"},{"location":"ci/events/","title":"Events: When workflows run","text":"<p>Use the <code>on</code> key to specify what events trigger your workflow. Check the full list of events.</p> <pre><code>on: push            # Trigger on a push\non: [push, fork]    # Trigger on a push or a fork\n</code></pre> <p>You can filter each event to be more specific, for example, to trigger the workflow only on push to a certain branch, or when certain files are modified:</p> <pre><code># Event triggered when pushed code to branch \"main\",\n# and a file inside the folder \"sources\" was modified\non:\n  push:\n    branches:\n      - main\n    paths:\n      - \"sources/**\"\n</code></pre>"},{"location":"ci/events/#manually-triggered-workflows","title":"Manually triggered workflows","text":"<p>The special event <code>workflow_dispatch</code> allows the workflow to be triggered manually. In the webpage of your GitHub repository go to the \"Actions\" tab. A message mentioning the \"workflow_dispatch event trigger\" should appear, together with a button to run the workflow, as shown in the picture below.</p> <p></p>"},{"location":"ci/events/#conditionally-triggered-workflows","title":"Conditionally triggered workflows","text":"<p>You can add and <code>if</code> conditional expression on a job, using the <code>${{}}</code> operator: if the condition is true, the job will run; if it's false, then the job won't run and will be marked as skipped. The following example only runs the job if the string \"FORCE_CI\" is found in the commit message.</p> <pre><code>name: Run workflow if FORCE_CI is present in commit message\non: push\njobs:\n  force_ci:\n    runs-on: ubuntu-latest\n    if: ${{ contains(github.event.head_commit.message, 'FORCE_CI') }}\n    steps:\n      - run: echo \"Hello world\"\n</code></pre>"},{"location":"ci/jobs/","title":"Jobs: What workflows do","text":"<p>Each job runs a series of steps. Each step can have a <code>name</code>, and can be either an action (<code>uses: &lt;action&gt;</code>) or a shell command (<code>run: &lt;command&gt;</code>).</p> <p>Commands are any valid Bash instruction. Actions are pre-made sets of commands that can be used in your workflow, the most common ones being checkout, to retrieve files from a repository, and setup-python, to install a certain Python version.</p> <p>The syntax for actions is: <code>uses: &lt;action_creator&gt;/&lt;action_name&gt;@v&lt;version_number&gt;</code>. The following example checkouts this repository, installs Python and then runs a simple Python script located in the repository's root path<sup>1</sup>:</p> <pre><code>name: \"Using actions\"\non: push\njobs:\n  job_id:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Checkout repo\"\n        uses: actions/checkout@v5\n\n      - name: \"Install Python\"\n        uses: actions/setup-python@v6\n        with:\n          python-version: \"3.12\"\n\n      - name: \"Run Python script\"\n        run: python3 sample_script.py\n</code></pre> <p>Check the GitHub Actions Marketplace to see the full list of available actions.</p> <p>Tip</p> <p>There are A LOT of actions to choose from. Always try to use actions from verified creators and check if what you want to do hasn't been implemented by someone else already.</p>"},{"location":"ci/jobs/#jobs-execution-order","title":"Jobs' execution order","text":"<p>By default, all jobs run on parallel. You can request sequential execution by using the <code>jobs.&lt;job_id&gt;.needs</code> property. Jobs that depend on others will only execute if the previous ones were successful.</p> <pre><code>name: \"Lots of sequential jobs\"\non: push\njobs:\n  job1:\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"Hello from job1\"\n\n  job2:\n    runs-on: ubuntu-latest\n      needs: [job1]\n      steps:\n        - run: echo \"Hello from job2\"\n\n  job3:\n    runs-on: ubuntu-latest\n    needs: [job1, job2]\n      steps:\n        - run: echo \"Hello from job3\"\n</code></pre>"},{"location":"ci/jobs/#sharing-values-between-steps-and-jobs","title":"Sharing values between steps and jobs","text":"<p>Each job runs on a separate runner (virtual machine), indicated by the <code>runs-on</code> property. Also, each step of a job runs on a separate shell. Therefore, it is not possible to share environmental variables using solely Bash syntax, as shown in the below example.</p> <pre><code>name: \"Failed attempt at sharing env variables\"\non: push\nenv:\n  ENV_VARIABLE: \"0\"\njobs:\n  job1:\n    runs-on: ubuntu-latest\n    steps:\n      - run: |\n          echo \"Original env variable value: $ENV_VARIABLE\"     # Prints 0\n          ENV_VARIABLE=\"1\"\n\n      - run: |\n          echo \"Env variable in new step: $ENV_VARIABLE\"        # Prints 0\n\n  job2:\n    runs-on: ubuntu-latest\n    needs: [job1]\n    steps:\n      - run: |\n          echo \"Env variable value in new job: $ENV_VARIABLE\"   # Prints 0\n</code></pre> <p>To share results between steps in the same job, you can use use the <code>$GITHUB_ENV</code> environment file. This file is sourced by each step's new shell before executing its commands. Therefore, the previous example can be rewritten to save the environment variable in this file instead:</p> <pre><code>name: \"Sharing env variables through GITHUB_ENV\"\non: push\nenv:\n  ENV_VARIABLE: \"0\"\njobs:\n  job1:\n    runs-on: ubuntu-latest\n    steps:\n      - run: |\n          echo \"Original env variable value: $ENV_VARIABLE\"     # Prints 0\n          echo \"ENV_VARIABLE=1\" &gt;&gt; \"$GITHUB_ENV\"\n\n      - run: |\n          echo \"Env variable in new step: $ENV_VARIABLE\"        # Prints 1\n\n  job2:\n    runs-on: ubuntu-latest\n    needs: [job1]\n    steps:\n      - run: |\n          echo \"Env variable value in new job: $ENV_VARIABLE\"   # Prints 0\n</code></pre> <p>However, the second job can't see the changes made in the first job, because it runs in a different virtual machine, therefore a completely different environment. In consequence, it must be GitHub who handles the passage of variables.</p> <p>To share results between jobs, first define an <code>id</code> for the desired step. The variable to be shared should be written to the file <code>$GITHUB_OUTPUT</code> as one of the commands in that step. Then, define the <code>outputs</code> of the job as a list of variables like this: <code>&lt;output_variable_name&gt;: ${{ steps.&lt;step_id&gt;.outputs.&lt;variable_name&gt; }}</code>. Finally, the next job must have a dependency on the previous job (using the <code>needs</code> key), and retrieve the value using <code>${{ needs.&lt;needed_job_name&gt;.outputs.&lt;output_variable_name&gt; }}</code>.</p> <p>The following example demonstrates both sharing an environment variable between steps for job1, and sharing the output of job1 with job2.</p> <pre><code>name: \"Sharing values between steps and jobs\"\non: push\njobs:\n  job1:\n    runs-on: ubuntu-latest\n    env:\n      ENV_VARIABLE: \"0\"\n    outputs:\n      job1_output: ${{ steps.step2.outputs.job1_output }}\n    steps:\n      - id: step1\n        run: |\n          echo \"Original env variable value: $ENV_VARIABLE\" # Prints 0\n          echo \"ENV_VARIABLE=1\" &gt;&gt; \"$GITHUB_ENV\"\n\n      - id: step2\n        run: |\n          echo \"Env variable in new step: $ENV_VARIABLE\"    # Prints 1\n          echo \"job1_output=55\" &gt;&gt; \"$GITHUB_OUTPUT\"\n\n  job2:\n    runs-on: ubuntu-latest\n    needs: [job1]\n    env:\n      ENV_VARIABLE: ${{ needs.job1.outputs.job1_output }}\n    steps:\n        - run: |\n            echo \"Env variable value: $ENV_VARIABLE\"        # Prints 55\n</code></pre> <ol> <li> <p>By default, the runner's default empty working directory <code>GITHUB_WORKSPACE=/home/runner/work/&lt;repo_name&gt;/&lt;repo_name&gt;</code>. After the  <code>actions/checkout</code>, the repository is cloned inside this folder and execution proceeds.\u00a0\u21a9</p> </li> </ol>"},{"location":"ci/runners/","title":"Runners: Where workflows run","text":"<p>Basically, there are three options: run in a predefined GitHub-hosted runner, a custom GitHub-hosted runner or a self-hosted one. The runner is chosen by the <code>jobs.&lt;job_id&gt;.runs-on</code> key:</p> <pre><code>jobs:\n  &lt;job_id&gt;:\n    runs-on: ubuntu-latest\n</code></pre>"},{"location":"ci/runners/#predefined-github-hosted-runners","title":"Predefined GitHub-hosted runners","text":"<p>This type of runners are freshly started, predefined virtual machines that execute the jobs. They are filled with the latest version of development tools to accommodate for all kinds of environments. A simple example is shown below:</p> <pre><code>name: Run hello world\non: push\njobs:\n  hello_world:\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"Hello world\"\n</code></pre> <p>Check the full list of GitHub-hosted runners.</p>"},{"location":"ci/runners/#custom-github-hosted-runners","title":"Custom GitHub-hosted runners","text":"<p>This type of runners execute inside a user-created Docker image that should have been previosuly created and uploaded to DockerHub.</p> <p>Include the <code>jobs.&lt;job_id&gt;.containers.image</code> property to make the job's steps execute inside the Docker container. Below is a full workflow example, that uses the <code>alpine:latest</code> image, with the environment variable <code>CUSTOM_VARIABLE = \"author\"</code></p> <pre><code>name: Run hello world on a Docker container\non: push\njobs:\n  hello_world:\n    runs-on: ubuntu-latest\n    container:\n      image: alpine:latest\n      env:\n        CUSTOM_VARIABLE: \"author\"\n    steps:\n      - run: echo \"Hello ${CUSTOM_VARIABLE}\"\n</code></pre> <p>Note</p> <p>Both <code>runs-on</code> and <code>container</code> should be specified. The container image will run on top of the <code>runs-on</code> operating system by calling the docker CLI.</p>"},{"location":"ci/runners/#self-hosted-runners","title":"Self-hosted runners","text":"<p>Self hosted runners imply having a local machine hooked to the internet, constantly listening for job request from GitHub. This methodology won't be discussed further since it is not needed by the author.</p>"},{"location":"docker/build_images/","title":"Build Docker images with Dockerfile","text":"<p>A Dockerfile is a set of shell instructions used to install packages and tools. The versions installed are frozen in time, giving as a result an immutable and reproducible environment.</p> <p>There are plenty of tutorials on Docker, so in this document I just want to remark the most essential concepts and some of the best practices.</p> <p>This repository's sources includes a complete example of a Dockerfile and a Docker Compose file.</p>"},{"location":"docker/build_images/#how-to-properly-install-packages","title":"How to properly install packages","text":"<p>This is the recommended way to install packages in Debian-based images:</p> <pre><code>RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    &lt;packages to install&gt; \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n</code></pre>"},{"location":"docker/build_images/#multi-stage-builds-make-your-image-smaller","title":"Multi-stage builds make your image smaller","text":"<p>The concept of a multi-stage build is similar at how you would build an embedded software image:</p> <ol> <li>First, you compile all the tools you need in the builder image.</li> <li>Then, you copy only the run-time required files into the target image.</li> </ol> <p>By doing this, you avoid clogging your target with unneeded build-time dependencies, reducing the final image size.</p> <pre><code>FROM ubuntu:24.04 AS builder\n    # Install whatever you need\n\nFROM ubuntu:24.04 AS target\n    # Copy all built binaries from build stages\n    COPY --from=builder &lt;source_path&gt; &lt;dest_path&gt;\n</code></pre>"},{"location":"docker/docker_index/","title":"Docker: build local, run everywhere","text":"<p>Docker solves the long-standing problem of \"but it runs on my machine\".</p> <p>In practical terms, a Docker image is like a virtual machine (VM)<sup>1</sup>: it allows you to run any program you want inside an operating system (OS) of your choice, with any set of packages and libraries installed.</p> <p>This guide is structured in two parts:</p> <ul> <li> <p>How to build Docker images: bundle all your tools inside a reusable and easily shareable Docker image, using a <code>Dockerfile</code>.</p> </li> <li> <p>How to run Docker containers: build your image, execute it, push it to DockerHub, pull it. Everything that you need for using Docker with <code>Docker Compose</code> files.</p> </li> </ul> <p>To install Docker, consult the Docker Engine installation guide.</p> <ol> <li> <p>The main difference with VMs is that Docker images don't actually run their own kernel and bootloader. Instead, each system call executed by the \"simulated\" OS inside the Docker is translated to the OS currently running in your computer.\u00a0\u21a9</p> </li> </ol>"},{"location":"docker/run_containers/","title":"Run containers with Docker Compose","text":"<p>I personally believe that people who learn Docker never bother themselves to learn Docker Compose, which is a real shame. In most Docker tutorials, you will often see some long command-line incantations to build or execute a Docker container with lots of options.</p> <p>Docker Compose is a way to gather all those options in a <code>docker-compose.yaml</code> file, and then it allows you to use Docker with this simple commands:</p> <pre><code># Single service or \"image\"\ndocker compose build &lt;service&gt;\ndocker compose run --rm &lt;service&gt;\ndocker compose pull &lt;service&gt;\ndocker compose push &lt;service&gt;\n\n# Execute multiple services at the same time\ndocker compose up\ndocker compose down\n</code></pre> <p>There are lots of tutorials on this topic, and the Compose file reference is very complete, so in the following sections I will only highlight some useful tips.</p> <p>A complete example of a Docker environment can be found in this repository's sources.</p>"},{"location":"docker/run_containers/#environmental-variables","title":"Environmental variables","text":"<p>By default, upon execution of any <code>docker compose &lt;command&gt;</code> command, the environmental variables in the <code>.env</code> file will be read. These variables can be used for replacement in the <code>docker-compose.yaml</code> file, and can be seen inside the container as well.</p>"},{"location":"docker/run_containers/#volumes","title":"Volumes","text":"<p>Volumes are the way to share information between containers or with the host computer. They are simply shared folders, and you only need to define the host's path and the container's path.</p>"},{"location":"docker/run_containers/#entrypoint","title":"Entrypoint","text":"<p>The container's entrypoint is a bash script that contains all instructions to execute inside the container on boot-up.</p> <p>By default, containers execute with the <code>root</code> user and group. When sharing volumes with the host system, any file created inside the container won't be accessible by the user because of the files' permissions. To avoid this, you should create a replica of the host's user, with the same user ID and group ID.</p> <p>Take a look at the example entrypoint provided with this repository to find the implementation for this.</p>"},{"location":"gdb/","title":"GDB","text":"<p>The GNU Debugger (GDB) is a powerful tool that allows to inspect the state of an executing program.</p> <p>The documentation is organized as follows:</p> <ul> <li>Tutorial: Run a quick demo of GDB to get the feeling of it.</li> <li>Reference: A quick list of the most used commands.</li> <li>How-to guides: Check for an specific problem or use case of gdb.</li> </ul>"},{"location":"gdb/reference/","title":"GDB Reference","text":"<p>In this document each of the most common GDB commands are detailed. For a full list of commands, please consult the bibliography.</p>"},{"location":"gdb/reference/#layout-configuration-and-startup-commands","title":"Layout, configuration and startup commands","text":"<p>Start GDB with a compiled binary having used the <code>-g</code> flag with:</p> <pre><code>gdb [binary_file]\ngdb -x [script.gdb] [binary_file]\n</code></pre> <p>GDB will always execute the commands in the <code>.gdbinit</code>, regardless of the usage of the <code>-x</code> flag.</p> <p>Quit the debugger with</p> <pre><code>(gdb) q[uit]\n</code></pre> <p>The layout of the debugger is configurable. You can see your source code or the CPU registers by typing the following commands, or by activating the eXtra Awesome mode (<code>Ctrl + x; a</code>).</p> <pre><code>(gdb) lay[out] src\n(gdb) lay[out] regs\n</code></pre> <p>Refresh the display or change the focus window (the focused window is the one that responds to the arrow keys for navigation).</p> <pre><code>(gdb) ref[resh]\n(gdb) foc[us] &lt;layout_selected&gt;\n</code></pre> <p>The program won't run until said so. To set command line arguments, type:</p> <pre><code>(gdb) set args [arg_list ...]\n(gdb) r[un]\n</code></pre> <p>Help with any command can be printed out with:</p> <pre><code>(gdb) h[elp] [command]\n</code></pre>"},{"location":"gdb/reference/#flow-control-commands","title":"Flow control commands","text":"<p>Continue the program's normal operation. The flow of execution is usually stopped by a breakpoint or a watchpoint.</p> <pre><code>(gdb) c[ontinue]\n</code></pre> <p>Go directly to the next line of code in the current file, passing over function calls.</p> <pre><code>(gdb) n[ext]\n</code></pre> <p>Step into the next line of code to be executed, even entering function calls.</p> <pre><code>(gdb) s[tep]\n</code></pre> <p>Finish execution of the current function, and go to the next line of code of the calling script.</p> <pre><code>(gdb) fin[ish]\n</code></pre>"},{"location":"gdb/reference/#breakpoints-and-watchpoints","title":"Breakpoints and watchpoints","text":"<p>A breakpoint can be put at the beginning of a function call or in any line number in a file. All breakpoints get assigned a breakpoint number for future reference. If the file name is omitted, it will use the scope of the current file.</p> <pre><code>(gdb) b[reak] [file_name:]function_name|line_number\n</code></pre> <p>Conditional breakpoints that use the program's variables and simple mathematical expressions can be set with an if statement:</p> <pre><code>(gdb) break [file_name:]function_name|line_number [if condition]\n</code></pre> <p>A watchpoint can be put over a variable and it stops execution of the code every time the content of that memory address changes.</p> <pre><code>(gdb) wat[ch] variable_name\n</code></pre> <p>List all the info of currently active breakpoints:</p> <pre><code>(gdb) i[nfo] b[reak]\n\nNum  Type        Disp  Enb  Address  What\n1    breakpoint  keep  y    0xFFFF   in main at primec.c:34\n</code></pre> <p>Delete a breakpoint using the breakpoint number, or delete all breakpoints if no number is specified.</p> <pre><code>(gdb) d[elete] [breakpoint_number ...]\n</code></pre> <p>Disable or enable a breakpoint:</p> <pre><code>(gdb) dis[able] [breakpoint_number ...]\n(gdb) en[able] [breakpoint_number ...]\n</code></pre> <p>Ignore a breakpoint until it has been crossed <code>x</code> times.</p> <pre><code>(gdb) ign[ore] [breakpoint_number ...] [x]\n</code></pre> <p>Create a temporary breakpoint that will be deleted after being reached once.</p> <pre><code>(gdb) tb[reak] [function_name]\n</code></pre>"},{"location":"gdb/reference/#displaying-information","title":"Displaying information","text":"<p>The info command displays all the information needed at the current step in execution. Some notable mentions are:</p> <pre><code>(gdb) i[nfo] r[egisters]    # Print all registers, same info as in layout regs\n(gdb) i[nfo] lo[cals]       # Print all local variables with their values\n(gdb) i[nfo] ar[gs]         # Print arguments passed to function.\n</code></pre> <p>Print the variables' values in scope with:</p> <pre><code>(gdb) p[rint] [variable_name]\n(gdb) p vector[index]\n(gdb) p *vector@[len]\n</code></pre> <p>Display a variable's value each time the execution stops with the <code>display</code> command.</p> <pre><code>(gdb) display [variable_name]\n(gdb) undisplay [variable_name]\n</code></pre> <p>Print the backtrace of the program, which includes all the function calls that needed to be made to be where you are, with its arguments and all the variables in scope.</p> <pre><code>(gdb) bt full\n</code></pre> <p>Use a printf just like in C to obtain nicer outputs.</p> <pre><code>(gdb) printf \"some_text\\n\"\n</code></pre>"},{"location":"gdb/reference/#gdb-scripting","title":"GDB Scripting","text":"<p>Enable logging to a file:</p> <pre><code>set logging enabled [on|off]\nset logging file [file_name]\nset logging overwrite [on|off]\n</code></pre> <p>Specify commands to be executed when a breakpoint is reached:</p> <pre><code>break [file_name:][function_name|line_number]\n    commands\n    # actual commands, usually printing variables and memory values\nend\n</code></pre> <p>Avoid downloading debug info form URLs:</p> <pre><code>set debuginfod enabled off\n</code></pre>"},{"location":"gdb/reference/#bibliography","title":"Bibliography","text":"<ul> <li> <p>gdb QuickStart.</p> </li> <li> <p>gdb Cheatsheet.</p> </li> <li> <p>GDB: The GNU Project Debugger.</p> </li> </ul>"},{"location":"gdb/tutorial/","title":"GDB Tutorial","text":"<p>In this tutorial we will compile, execute and debug a simple C code.</p> <p>Let's first take a look at the code we will be debugging. This code prints the sum of the first prime numbers.</p> <pre><code>#include &lt;stdlib.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;math.h&gt;\n\nint add_array(int *arr, int length) {\n    int sum = 0;\n    for(int i=0; i&lt;length; i++) {\n        sum += arr[i];\n    }\n    return sum;\n}\n\nint is_prime(int x) {\n    if(x &lt; 2) {\n        return 0;\n    } else if(x == 2) {\n        return 1;\n    } else if(x % 2 == 0) {\n        return 0;\n    }\n    for(int i=3; i&lt;=sqrt(x); i+=2) {\n        if(x % i == 0) {\n            return 0;\n        }\n    }\n    return 1;\n}\n\nint *get_first_primes(int number_of_primes) {\n    int* result = (int*) malloc(sizeof(int) *number_of_primes);\n    int i=1, x=3;\n\n    result[0] = 2;\n    while(i &lt; number_of_primes) {\n        if(is_prime(x)) {\n            result[i] = x;\n            i++;\n        }\n        x += 2;\n    }\n    return result;\n}\n\nint main(int argc, char **argv) {\n    int prime_number_qtty = 3;\n    int sum;\n    int* primes;\n\n    if(argc == 2) {\n        prime_number_qtty = atoi(argv[1]);\n    }\n    primes = get_first_primes(prime_number_qtty);\n\n    sum = add_array(primes, prime_number_qtty);\n    printf(\"&gt;&gt;&gt; The sum of the first %d prime numbers is %d.\\n\", \n        prime_number_qtty, sum);\n    free(primes);\n    return 0;\n}\n</code></pre> <p>We will be using GCC to compile it and we need to add the <code>-g</code> flag in order to include the debug information in the binary file. Therefore, create a file called <code>primes.c</code> with the contents of the previous code snippet and then compile with:</p> <pre><code>gcc -Wall -g primes.c -lm\n</code></pre> <p>Let's see that our program works as intended by executing it:</p> <pre><code>./a.out\n&gt;&gt;&gt; The sum of the first 3 prime numbers is 10.\n./a.out 5\n&gt;&gt;&gt; The sum of the first 5 prime numbers is 28.\n</code></pre> <p>Before executing GDB, we need to first setup a few configurations to avoid some warnings showing up:</p> <pre><code>mkdir -p ~/.config/gdb\necho \"set auto-load safe-path /\" &gt;&gt; ~/.config/gdb/gdbinit\necho \"set debuginfod enabled off &gt; .gdbinit\n</code></pre> <p>Let's execute GDB now. you should see a bunch of messages, and the last ones are:</p> <pre><code>gdb a.out\n...\nReading symbols from a.out...\n(gdb) \n</code></pre> <p>Note</p> <p>At any time, you can quit by typing <code>(gdb) quit</code> or <code>(gdb) q</code>.</p> <p>This is the interactive GDB terminal, where we can run our program and see how it executes in real time.</p> <p>The first thing that should be done after starting any GBD terminal is to activate the eXtra Awesome mode, with the combination of keys <code>Ctrl + x; a</code> (first Ctrl + x, then a). You should now see the code and the GDB terminal at once.</p> <p>Lets start by running our program with:</p> <pre><code>(gdb) run\n...\n&gt;&gt;&gt; The sum of the first 3 prime numbers is 10.\n...\n(gdb) set args 5\n(gdb) run\n...\n&gt;&gt;&gt; The sum of the first 3 prime numbers is 28.\n...\n</code></pre> <p>As you can see, our program ran and printed the same message as if it was run from the console. Now, let's try running the code again, but this time step by step. While running these commands, you will first set a breakpoint at the start of the function <code>main</code>, in the file <code>primes.c</code>. Later, you will run the program, and execute the <code>next</code> line of code on that file, skipping the internal execution of the functions. When reaching the call to the function <code>add_array</code>, you will <code>step</code> into the function, and execute some of its lines before <code>finish</code> its execution, and returning to the caller. Finally, we <code>continue</code> execution until the next breakpoint. Since there are none, the program ends.</p> <pre><code>(gdb) break primes.c:main\n(gdb) run\n(gdb) next\n(gdb) n\n(gdb) n\n(gdb) n\n(gdb) step\n(gdb) n\n(gdb) \n(gdb) \n(gdb) \n(gdb) finish\n(gdb) n\n(gdb) n\n(gdb) continue\n</code></pre> <p>Note</p> <p>An empty terminal line like <code>(gdb)</code> means to press enter. It is a shortcut for repeating the last command. The same applies for using a singe letter like <code>n</code> instead of <code>next</code>.</p> <p>We traversed all the aspects of our code, but we still didn't see any of the variables' values, only which lines were executed. We know that our code adds the first prime numbers, but we would like to check that the numbers added are actually prime numbers.</p> <p>To do that, we will first, set a breakpoint in the \"add_array\" function, and <code>watch</code> (add a watchpoint) to the variable sum. This will pause the execution of the program each time that variable changes, and print its value. Besides, we will <code>print</code> the value of the prime number array <code>arr[i]</code> that we are adding each time and finally, we will print the whole primes array.</p> <pre><code>(gdb) break primes.c:add_array\n(gdb) set args 10\n(gdb) run\n(gdb) watch sum\n(gdb) c\n(gdb) c\n(gdb) c\n(gdb) print arr[i]\n(gdb) c\n(gdb) delete 2\n(gdb) finish\n(gdb) print *primes@prime_number_qtty\n(gdb) c\n(gdb) quit\n</code></pre> <p>In this tutorial we covered the basics of using the GNU Debugger. We executed our code line by line and saw the values of the variables as they were changing in real time.</p>"},{"location":"gdb/how-to-guides/how_to_create_a_gdb_script/","title":"How to create a GDB script","text":"<p>This guides shows you how to write a GDB script to automate a debugging session.</p> <p>You can execute GDB with a script using the <code>-x</code> flag, or it will be called automatically if you name it  like <code>.gdbinit</code>.</p> <p>Although all the commands used for interactive debugging can still utilized, while writing a script one must consider two things:</p> <ol> <li>The output will be printed to a file, not to stdout.</li> <li>The debugging session can't block, it should start and end.</li> </ol> <p>Because of (1), you should first log the output to a file instead of stdout.</p> <pre><code>set debuginfod enabled off\nset logging file [file_name]\nset logging overwrite on\n</code></pre> <p>When you set a breakpoint or watchpoint, you need to tell the debugger what commands need to be executed each time it stops, like so:</p> <pre><code>break [file_name:][function_name|line_number]\n    commands\n    # actual commands, usually printing variables and memory values\nend\n</code></pre> <p>After all the breakpoints and actions have been set, enable the logging and run the debugging session:</p> <pre><code>set logging enabled on\nrun\nset logging enabled off\nquit\n</code></pre> <p>And that's how you write a GDB script. For more advanced commands, consult the reference section.</p>"},{"location":"git/best_practices/","title":"Git best practices","text":""},{"location":"git/best_practices/#conventional-commits","title":"Conventional commits","text":"<p>Conventional commits is somewhat like a standard on how to write commit messages. Basically, a commit message must be structured as follows:</p> <pre><code>&lt;type&gt;[optional scope]: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n</code></pre> <p>Where:</p> <ul> <li><code>&lt;type&gt;</code>: <code>fix</code>, <code>feat</code>, <code>docs</code>, <code>ci</code>, etc.</li> <li><code>&lt;description&gt;</code>: \"verb (in lowercase and infinitive)\" + \"action done\"</li> </ul>"},{"location":"git/best_practices/#trunk-based-development","title":"Trunk-Based development","text":"<p>Trunk-Based Development is the best branching strategy for Git.</p> <p>The idea is that the <code>main</code> branch should always hold a stable version. For every new feature or fix, a new short-lived branch should be created. Each developer works in his branch and, when he finishes, opens a pull request to the <code>main</code> branch.</p> <p>This pull request serves two purposes:</p> <ul> <li>For peer reviewing.</li> <li>To trigger the CI runners.</li> </ul> <p>If both conditions are satisfied, then the development branch can be merged to <code>main</code> and later deleted.</p> <p>Both diagrams below show how to do trunk-based development. The branches <code>feature1</code> and <code>feature2</code> are created from the latest version of <code>main</code>. Then, <code>feature1</code> is completed and merged to <code>main</code>. However, now <code>feature2</code> is based on an old version of the <code>main</code> branch and it can't perform a fast-forward merge. In consequence, the solution is shown in the second graph, where a rebase is made from <code>main</code> before merging.</p> <pre><code>gitGraph\n    commit id:\"init\"\n    branch feature1\n    checkout main\n    branch feature2\n    checkout feature1\n    commit id:\"1\"\n    checkout main\n    merge feature1 id:\"3\"\n    checkout feature2\n    commit id:\"2\"</code></pre> <pre><code>gitGraph\n    commit id:\"init\"\n    branch feature1\n    checkout main\n    checkout feature1\n    commit id:\"1\"\n    checkout main\n    merge feature1 id:\"3\"\n    branch feature2\n    checkout feature2\n    commit id:\"rebased-2\"\n    checkout main\n    merge feature2 id:\"4\"</code></pre>"},{"location":"git/best_practices/#semantic-versioning","title":"Semantic versioning","text":"<p>Semantic Versioning gives a meaning to the release numbers. Cited from its page:</p> <p>Quote</p> <p> Given a version number MAJOR.MINOR.PATCH, increment the:</p> <ol> <li>MAJOR version when you make incompatible API changes</li> <li>MINOR version when you add functionality in a backward compatible manner</li> <li>PATCH version when you make backward compatible bug fixes</li> </ol>"},{"location":"licencing/licencing/","title":"Licenses and free/open software","text":""},{"location":"licencing/licencing/#defining-free-software","title":"Defining free software","text":"<p>According to the definition of free software provided by the Free Software Foundation, the word \"free\" is a matter of liberty, not price<sup>1</sup>.</p> <p>A \"free software\" is such if the program's users have the four essential freedoms:</p> <ol> <li>The freedom to run the program as you wish, for any purpose.</li> <li>The freedom to study how the program works, and change it so it does your computing as you wish. Access to the source code is a precondition for this.</li> <li>The freedom to redistribute copies so you can help others.</li> <li>The freedom to distribute copies of your modified versions to others.</li> </ol>"},{"location":"licencing/licencing/#defining-open-source-software","title":"Defining open source software","text":"<p>Instead of emphasizing the users' freedom, the Open Source Software definition focuses on the licensing of the software and its availability.</p> <p>It is a requirement to provide the source code and executable binaries, and to allow free redistribution. However, open source does not bother to specify anything about the software's modified versions. Therefore, the following things might happen:</p> <ol> <li>An open source software can restrict its users from making modified versions.</li> <li>Tivoization: Many products check signatures on their executable programs to block users from effectively using different executables (so called \"secure boot\"); only one privileged company can make executables that can run in the device an use its full capabilities. Even if the executable is made from free source code, the users cannot usefully run modified versions of it, so the executable is de-facto non-free.</li> </ol>"},{"location":"licencing/licencing/#licenses","title":"Licenses","text":"<p>I am not a lawyer. This page has a good summary of the licenses. This page helps you choose the right license for your project.</p> <p>In the following sections first we will discuss the requirements to use the licenses. Then, the most important aspects of the most common ones.</p>"},{"location":"licencing/licencing/#requirements","title":"Requirements","text":"<p>You should include both a copy of the license in the repository, as well as a copyright notice<sup>2</sup> in each source file (REF).</p>"},{"location":"licencing/licencing/#gpl-v2","title":"GPL-v2","text":"<p>Used by Linux. Enforces the four essential freedoms. Only applies to the changes in the Kernel itself. You can use Linux in a closed source application. If you modify it in any way, you need to provide the changes.</p>"},{"location":"licencing/licencing/#gpl-v3","title":"GPL-v3","text":"<p>Used by the GNU project. The GPL-v3 was born in response to the Tivoization issue. It is a copyleft license, meaning that derivate work that uses or modifies the licensed product must use the same license.</p> <p>Therefore, if a project uses a software under the GPL-v3, all the project must adhere to the GPL-v3 license and therefore be \"free software\".</p> <p>There is the exception of the LGPL-v3, which is used for libraries. The whole project doesn't need to be GPL-v3 compliant if linked against a library with LGPL-v3 license.</p>"},{"location":"licencing/licencing/#apache-20","title":"Apache 2.0","text":"<p>Changes made to the licensed material must be documented. It does not grant trademark rights.</p>"},{"location":"licencing/licencing/#mit","title":"MIT","text":"<p>This is the most permissive license. The only requirement being that the copyright and the license must be included on usage and in derivative works.</p> <ol> <li> <p>In Spanish, \"free software\" is translated as \"software libre\", not \"software gratis\".\u00a0\u21a9</p> </li> <li> <p>The license itself should provide you with the copyright notice to copy-paste in each file.\u00a0\u21a9</p> </li> </ol>"},{"location":"linker/linker/","title":"Linker Script","text":"<p>The GNU Linker ld is responsible for mainly three things:</p> <ol> <li>Merging several object files into a single executable file, making sure that any required external symbols are defined and seen correctly.</li> <li>Defining the memory regions where the code and data are going to physically and virtually be stored.</li> <li>Allocating the code sections into those memory regions.</li> </ol> <p>After some definitions, we will see how to write a linker script to perform this three functions.</p>"},{"location":"linker/linker/#definitions","title":"Definitions","text":"<p>A module refers to an object file.</p> <p>A symbol is a label that represents a memory address.</p> <p>A code section (.text, .data, .bss, etc) can be:</p> <ul> <li>Loadable: The contents should be loaded into the memory</li> <li>Allocatable: The space should be reserved, but nothing loaded in there.</li> </ul> <p>Every loadable or allocatable section has a VMA and LMA:</p> <ul> <li> <p>The VMA (Virtual Memory Address) is the address where the section will be executed.</p> </li> <li> <p>The LMA (Load Memory Address) is the address where the section will be loaded. It's the bootloader or startup code responsibility to copy the contents of the LMA into their respective VMA.</p> </li> </ul> <p>Linker scripts usually have the extension <code>.ld</code>. Comments are only allowed using a slash and an asterisk (<code>/**/</code>).</p>"},{"location":"linker/linker/#symbols-in-linker-scripts","title":"Symbols in linker scripts","text":"<p>A symbol is a reference to a memory space, not the value inside it. Take for example the following C code:</p> <pre><code>int foo = 123;  // Value \"123\" stored on address \"foo\".\n</code></pre> <p>In linker terms, the symbol <code>foo</code> represents the memory address where the value \"123\" is stored. The symbol <code>foo</code> by itself does not occupy memory space.</p> <p>A symbol is defined in the same way as a normal C variable, using any of the C equality operators.</p> <pre><code>&lt;symbol&gt; = &lt;memory_address&gt;; // You may use =, +=, -=, *=, /=, &lt;&lt;=, &gt;&gt;=, &amp;=, |=\n</code></pre> <p>Symbols are not exclusive to linkers scripts, as every object file may have a global or local symbol:</p> <pre><code>static int foo_local = 0;   // Local symbol \"foo_local\", only seen within the module.\nint foo_global = 0;         // Global symbol \"foo_global\", may be seen from other modules.\nextern int foo_extern = 0;  // Global symbol foo_extern, expected to be defined by other module.\n</code></pre> <p>Therefore, source code might expect to use global symbols defined in other files or even in the linker script, using the <code>extern</code> directive. The different ways to declare symbols in the linker are:</p> <pre><code>&lt;symbol&gt; = &lt;mem_address&gt;;           /* Declare a global symbol */\nHIDDEN(&lt;symbol&gt; = &lt;mem_address&gt;);   /* Declare a local symbol, only seen within the linker script. */\nPROVIDE(&lt;symbol&gt; = &lt;mem_address&gt;);  /* Declare a default value for a symbol, which will be defined globally ONLY if it was referenced by other module. */\n</code></pre>"},{"location":"linker/linker/#seing-linker-symbols-in-your-code","title":"Seing linker symbols in your code","text":"<p>Linker symbols are always treated as addresses.</p> <pre><code>/* linker_script.ld */\nPROVIDE(ld_memory_addr      = 0x70000000)\nPROVIDE(ld_memory_length    = 0x00010000)\n</code></pre> <p>When working in assembly, we can store the linker symbol as an address into a register:</p> <pre><code>.extern ld_memory_addr, .extern ld_memory_length\nldr r0, =ld_memory_addr     // r0 gets loaded with the value \"0x70000000\"\nldr r1, =ld_memory_length   // r1 gets loaded with the value \"0x00010000\"\n</code></pre> <p>In C, we need to define the variable as <code>extern</code>, and get its address:</p> <pre><code>extern uint32_t ld_memory_addr;\nextern uint32_t ld_memory_length;\n\nuint32_t * memory_addr = &amp;ld_memory_addr;   // memory_addr = 0x70000000\nuint32_t memory_size = &amp;ld_memory_length;   // memory_size = 0x00010000\n</code></pre>"},{"location":"linker/linker/#memory-regions-where-to-place-and-to-execute-the-code","title":"Memory regions: where to place and to execute the code","text":"<p>The <code>MEMORY</code> command creates memory regions where the different sections of the code will be placed. To define a region, you need four properties:</p> <pre><code>MEMORY {\n    &lt;name&gt; [(attributes)] : ORIGIN = &lt;origin_address&gt;, LENGTH = &lt;length&gt;\n}\n</code></pre> <ol> <li> <p>The <code>name</code> of the region: can be anything.</p> </li> <li> <p>The <code>(attributes)</code>, e.g. executable, read only, etc; which may be a combination of any of the following characters:</p> <ul> <li><code>r</code>: Read-only section.</li> <li><code>w</code>: Read/write section.</li> <li><code>x</code>: Executable section.</li> <li><code>a</code>: Allocatable section. (Space in memory should be reserved initialized with zeros).</li> <li><code>i</code>: Initialized section.</li> <li><code>!</code>: Invert the sense of any of the attributes that follow.</li> </ul> </li> <li> <p>The physical <code>ORIGIN</code> byte address.</p> </li> <li> <p>The physical <code>LENGTH</code> of the region, in bytes.</p> </li> </ol> <p>The following example defines two memory regions. All code that is read-only or executable will go to the <code>rom</code> by default, meanwhile the rest will go to the <code>ram</code>.</p> <pre><code>MEMORY {\n    rom (rx)  : ORIGIN = 0x00000000, LENGTH = 0x40000   /* Read-only and executable, 256K */\n    ram (!rx) : ORIGIN = 0x40000000, LENGTH = 0x400000  /* All other memory regions, 4M */\n}\n</code></pre>"},{"location":"linker/linker/#allocating-code-sections-into-memory-regions","title":"Allocating code sections into memory regions","text":"<p>A code section is a set of either instructions or variables under a common name (e.g <code>.text</code> or <code>.data</code>).</p> <p>The linker merges several input sections, the ones defined in your application code, into a single output section, specific to the linker script, which is then located into a determined memory region.</p> <p>The general syntax for declaring sections is as follows, and each component will be explained in detail in the following parts:</p> <pre><code>SECTIONS {\n    output_section [vma_address] [(type)] :\n    [AT(lma_address)]\n    [ALIGN(section_align)] {\n        input_section\n        ...\n    } [&gt;vma_region] [AT&gt;lma_region] [=fillexp]\n}\n</code></pre> <p>Besides, there is a special linker script variable called the location counter <code>.</code> or dot variable. It always holds the current VMA.</p>"},{"location":"linker/linker/#output-section-attributes","title":"Output section attributes","text":"<ul> <li> <p><code>output_section</code>: The name of the output section (normally .text, .data, .bss, .rodata, etc). This name is only relevant for the linker script, and has nothing to do with the sections' names defined in the application code.</p> </li> <li> <p><code>[vma_address] or [&gt;vma_region]</code>: Only one can be used. The value of the location counter <code>.</code> will be updated to match the initial address of the section's VMA.</p> <ul> <li><code>[vma_address]</code>: Sets the initial VMA with and hexadecimal address.</li> <li><code>[&gt;vma_region]</code>: Sets the initial VMA on the next free address in the memory region specified.</li> <li>By default, the VMA is set on the next free address of any memory region with compatible attributes, or at the current location counter <code>.</code> address.</li> </ul> </li> <li> <p><code>(type)</code>: Overrides the attributes of the section. By default, the output section will have the same attributes as the input section. The options are:</p> <ul> <li><code>NOLOAD</code>: The section will not be loaded into memory when the program is run. This is useful for the \".bss\" section for example, which is an uninitialized memory space that must exist, but doesn't need to be written at first.</li> </ul> </li> <li> <p><code>[AT(lma_address)]</code> or <code>[AT&gt;lma_region]</code>: Only one may be used.</p> <ul> <li><code>[AT(lma_address)]</code>: Sets the initial LMA with and hexadecimal address.</li> <li><code>[AT&gt;lma_region]</code>: Sets the initial LMA on the next free address in the memory region specified.</li> <li>By default, if the <code>vma_address</code> was provided, the VMA and LMA will be equal. Otherwise, it will be stored on the next free memory address of the last section's LMA.</li> </ul> </li> <li> <p><code>[ALIGN(section_align)]</code>: Enforce an alignment for the section, so that its initial memory address is a multiple of \"section_align\" bytes.</p> </li> <li> <p><code>[=fillexp]</code>: Any empty space will be filled with the pattern of <code>=fillexp</code>. By default, all \"0\" will be used.</p> </li> </ul> <p>Full list of output section attributes.</p>"},{"location":"linker/linker/#input-section-attributes","title":"Input section attributes","text":"<p>The input sections refer to the code sections defined in each module to be linked. For example, you would normally merge several <code>.text</code> input sections into one unified \".text\" output section.</p> <p>Input sections are defined by the following syntax, where:</p> <pre><code>&lt;filename&gt;(section_name)\n</code></pre> <ul> <li> <p><code>filename</code>: Refers to the name of the object file, e.g. \"a.o\". Normally, a wildcard <code>*</code> is used to refer to any filename. Files will be added in alphabetical order. Always make sure that the initialization code is specifically added as the first element.</p> </li> <li> <p><code>section_name</code>: Refers to the section to be loaded inside the file. Normally, you will see something like <code>*(.text*)</code>, which means \"from all files, load all code sections that start with <code>.text</code>, followed by whatever\".</p> </li> </ul> <pre><code>.text : {\n    *startup*(.text)    /* Startup code */\n    *(.text)            /* Load the rest of the code */\n}\n</code></pre> <p>The location counter <code>.</code> will be increased from the start address of the output section by the size of the input sections. You may define empty memory regions between input sections by updating the location counter value in between calls, as such:</p> <pre><code>.output_section 0 : {       /* VMA = 0 */\n    file1(.text)    /* Include section .text from file1 */\n    . += 0x1000;    /* Separate previous and next section with 0x1000 bytes */\n    file2(.text)    /* Locate next section VMA */\n}\n</code></pre>"},{"location":"linker/linker/#builtin-functions","title":"Builtin functions","text":"<p>There are some builtin functions that provide metadata to the linked binary or help arrange the memory sections. The following is a list of the most important ones.</p>"},{"location":"linker/linker/#for-initialization","title":"For initialization","text":"<p>BFD stands for \"Binary File Descriptor\", and is a short string to indicate the type of object file. For example \"elf32-littlearm\" tell us that the file is ELF (Executable and Linkable Format), for a 32 bit architecture, \"little\" endian, and for ARM processors.</p> <pre><code>ENTRY(&lt;symbol&gt;)             // First instruction to be executed. Entrypoint.\nINCLUDE &lt;filename&gt;          // Include linker script (copy contents).\nOUTPUT_FORMAT(&lt;bfdname&gt;)    // Format for executable output (elf32-littlearm)\nOUTPUT_ARCH(&lt;bfdarch&gt;)      // Architecture of the CPU (arm)\nTARGET(&lt;bfdname&gt;)           // Default format for input files (elf32-littlearm)\n</code></pre>"},{"location":"linker/linker/#for-memory","title":"For memory","text":"<pre><code>ORIGIN(&lt;memory&gt;)                // Returns the origin address of the memory region.\nLENGTH(&lt;memory&gt;)                // Returns the length of the memory region.\nREGION_ALIAS(&lt;alias&gt;, &lt;memory&gt;) // Alternative name for a memory region\n</code></pre>"},{"location":"linker/linker/#for-sections","title":"For sections","text":"<pre><code>LOADADDR(&lt;section&gt;)     // Returns the initial LMA of the named section.\nADDR(&lt;section&gt;)         // Returns the address (VMA) of the named section.\nALIGN(&lt;align&gt;)          // Returns the next multiple of \"align\" for the location counter (.), without modifying it, in bytes.\nALIGN(&lt;exp&gt;, &lt;align&gt;)   // Returns the next multiple of \"align\" for the \"exp\", in bytes.\nSIZEOF(&lt;section&gt;)       // Returns the size in bytes of the named output section.\n</code></pre>"},{"location":"linker/linker/#complete-example","title":"Complete example","text":"<p>The following example can be found in the \"linker\" folder in this repo. Consider this code and linker script:</p> <pre><code>// startup.S\n.text\n_start:\n    nop\n    nop\n    B main\n\nmain:\n    nop\n    nop\n\n.data\n    str: .ascii \"Hello\"\n    .balign 4\n    x: .word 0x44\n\n.bss\n    vector: .space 4096\n</code></pre> <pre><code>/* linker_script.ld */\nOUTPUT_FORMAT(\"elf32-littlearm\")\nOUTPUT_ARCH(arm)\nENTRY(_start)\n\nHIDDEN (ram_origin = 0x40000000);\nHIDDEN (ram_length = 0x10000000);\nHIDDEN (rom_origin = 0x00000000);\nHIDDEN (rom_length = 0x10000000);\n\nMEMORY {\n    ram (!RX) : ORIGIN = ram_origin, LENGTH = ram_length\n    rom (RX)  : ORIGIN = rom_origin, LENGTH = rom_length\n}\n\nSECTIONS {\n    .text : AT(0x02000000) ALIGN(4) {\n        *(.text*)\n    } &gt;ram\n\n    .data : AT(0x03000000) ALIGN(256) {\n         *(.data*)\n    } &gt;ram\n\n    .bss 0x43000000 (NOLOAD) : ALIGN(4) {\n        *(.bss*)\n    }\n}\n</code></pre> <p>After compiling, we can extract the following data from the binary headers:</p> <pre><code>Sections:\nIdx Name          Size      VMA       LMA       File off  Algn\n  0 .text         0000000c  40000000  02000000  00010000  2**2\n                  CONTENTS, ALLOC, LOAD, READONLY, CODE\n  1 .data         0000000c  40000100  03000000  00010100  2**8\n                  CONTENTS, ALLOC, LOAD, DATA\n  2 .bss          00001000  43000000  43000000  00020000  2**2\n                  ALLOC\n  3 .ARM.attributes 00000014  00000000  00000000  0001010c  2**0\n                  CONTENTS, READONLY\n</code></pre> <p>Lets analyze what is happening:</p> <ol> <li> <p>\"rom\" and \"ram\" memory regions are defined.</p> </li> <li> <p>Section \".text\" starts at LMA = 0x0200_0000, and VMA = 0x4000_0000 (ram_origin). Look at the attributes:</p> <ul> <li>CONTENTS: has something in it.</li> <li>ALLOC: Allocatable (reserve the space).</li> <li>LOAD: Copy the contents to memory.</li> <li>READONLY</li> <li>CODE: contains machine instructions.</li> </ul> </li> <li> <p>Later, the \".data\" section starts at and address multiple of 256 (with 8 left zeros). LMA = 0x0400_0000, VMA = 0x4000_0100. VMA between 0x4000_000c and 0x4000_0100 it's filled with \"0\".</p> </li> <li> <p>Finally, the section \".bss\" is stored in VMA = LMA = 0x4300_0000. Note that the sections appears as \"ALLOC\" only, which means that the LMA should be reserved uninitialized, and the \"NOLOAD\" type was specified.</p> </li> </ol> <p></p>"},{"location":"linker/virtual_memory/","title":"Virtual memory","text":"<p>In this section I will describe what virtual memory is, why it's needed, and how the page tables connect virtual memory to physical memory.</p>"},{"location":"linker/virtual_memory/#what-virtual-memory-is-and-why-its-needed","title":"What virtual memory is and why it's needed","text":"<p>So far, we have been working with 32-bit processors (ARMv7 Cortex-A). We have written our code using a 4GB address space, and the program could access all the memory space without a problem. In the linker script, we designated a LMA (Load Memory Address) where the code would be written, an a VMA (Virtual Memory Address), where the code would be executed. Later on, we used the <code>memcopy</code> function to copy the code and data from the ROM into the RAM to execute it.</p> <p>The physical memory (PM) is defined as the actual amount of RAM memory available for the CPU to execute code and load data. In the Cortex-A, it's usually something like 512KB.</p> <p>The virtual memory (VM) is defined as the amount of memory seen by a program. A program can be written with any amount of virtual memory in mind. For a 32-bit CPU, applications are usually written with a 4GB VA, so they can access any memory there, but they don't own that memory. For a 64-bit CPU, programs are written with a 2^64 VA space.</p> <p>The VA will be mapped into a PA by the operating system using pages and frames. So, a program might need more memory than the system actually has (8GB of VA, 16GB of VA), or there might be running multiple processes which, in total, need more than the PA available, but they all run in the computer anyways.</p> <p>You probably are familiar with the concept of swap memory. The computer may have some fast access RAM and slower access hard drive. If the RAM ever gets full, the lesser used processes are loaded into the hard drive to make room for the ones that need to be executed in the RAM. This is virtual memory, the ability to re-arrange the program memory into the physical memory \"by turns\".</p>"},{"location":"linker/virtual_memory/#constructing-virtual-addresses-va-pagination","title":"Constructing Virtual addresses (VA): pagination","text":"<p>Pagination is the process of separating the VA of the code into pages, each of a fixed size, and then allocating them into frames in the PA. The most common approach is to create 4KB pages.</p> <p>A Virtual Address might look like this:</p> Page table index Page offset <p>Where the \"page table index\" refers to the actual entry in the page table, and the \"page offset\" is the position in memory inside that page.</p> <p>An entry in the page table will look like this:</p> Frame PA Memory flags <p>Where the \"Frame PA\" is the MSB of the PA for the conversion from VA to PA, and the size of the memory flags is the same as the page offset's bits.</p>"},{"location":"linker/virtual_memory/#flat-page-table","title":"Flat page table","text":"<p>So, if we have a page of \\(4KB = 2^{12}\\), and a total virtual memory space of \\(4Gb = 2^{32}\\), that means that the page offset will be 12 bits long, and the page table index will be 20 bits long (the remaining bits). The total amount of pages needed by this application would be:</p> \\[Page\\space table\\space entries = \\frac{Virtual\\space Memory\\space size [byte]}{Page\\space size [byte/page]} = \\frac{2^{32}}{2^{12}} = 2^{20} = 1M [pages]\\] <p>And the total space ocuppied by the table will be equal to:</p> \\[Table\\space size = Page\\space table\\space entries [pages] \\cdot K[bytes/page] = 1M\\cdot4 = 4MB \\] <p>The virtual space memory is independent of the actual usage of that memory. For each program written, they will have a 4GB VA, and will occupy 4MB for their page table, no matter if the actual program uses 1Mb, 1GB or the whole 4GB. The table will be generated with empty spaces.</p>"},{"location":"linker/virtual_memory/#example-of-single-level-page-table","title":"Example of single level page table","text":"<p>We have a 16-bit (64KB) VA space, and a 20-bit (1MB) PA space. The pages have 14-bit size (16Kb). We have a page table for a program that looks like this:</p> 0x1F 0x3F 0x23 0x17 <p>Given that our program wants to access data with VA 0xF0F0 and 0x001F, where would they be in the PA?</p> <p>Well, because our page table has only 4 positions, the page table index will be only 2 bits long, leaving 14 bits of page offset:</p> <p>0xF0F0 = \"11|11_0000_1111_0000\", so table index is \"3\" (0x17), the PA forms concatenating the page table entry and the offset:</p> <p>VA = 0001_0111 &amp;&amp; 11_0000_1111_0000;  Discarding the two MSB...</p> <p>VA = 00| 0101_1111_0000_1111_0000  --&gt; VA = 0x5F0F0</p> <p>0x00FF = 00|00_0000_0001_1111, so table index is \"0\" (0x1F), the PA forms concatenating the page table entry and the offset:</p> <p>VA = 00| 0111_1100_0000_0001_1111 = 0x7C01F</p>"},{"location":"linker/virtual_memory/#multi-level-page-tables","title":"Multi-level page tables","text":"<p>If we have a VA of 4GB, and a program that only allocates 9KB of memory, we don't want to generate 1M page entries. We would want to generate only 3, cause this program only would need 3 pages. This can't be done with a flat page table, but can be done with a multi-level one.</p> <p>If we had a two page table structure, the VA address will look like this:</p> First level table index Second level table index Page offset <p>The first table entry will look like this:</p> Second table entry PA Memory flags <p>The second table entry will look like this:</p> Frame PA Memory flags"},{"location":"linker/virtual_memory/#example","title":"Example","text":"<p>If we had a 8-bit = 256B VA space, represent the flat page table and the double entry page tables, considering a page size of 16B.</p> <p>Since the page size is \"4\" bits, and the virtual address is \"8\" bits, then there will be 4 bits of page index (16 entries) and 4 bits of page offset:</p> <p>VA = |0100 (page index)| 1100 (page offset)</p> <p>If we were to use two levels of tables, we will still need 16 table entries that point to frame PA, but we will also a table that point to that second tables. Here, we can do a \"1\" bit order table, and 2 \"3bit\" second order, or do \"2\" bit first order and \"2\" bit second order, as shown in the image.</p> <p>The final result of a second order table is now using 4 more entries per program, so where is the memory optimization?</p> <p></p> <p>If a program only uses a few percent of it's total VA (let's say, the 64B in the previous example), then we will only need one of the four second level page tables. Using multi-layer page tables, the amount of space needed for the page tables has a correlation with the space occupied by the program.</p>"},{"location":"linker/virtual_memory/#the-tlb-table-look-aside-buffer","title":"The TLB: Table look-aside buffer","text":"<p>Using the page tables, each time a memory address needs to be accessed, the CPU should read from memory the first table, then the second table, obtain the PA, and then access that PA. Reading from memory is very slow, so how can we speed this up?</p> <p>The TLB is a special cache memory from 16 to 512 associative entries that hold the most recent page table translations (associative means that they are all checked simultaneously). So, to translate from VA to PA, it will go like this:</p> <ol> <li> <p>From the VA, check the table index and see if there is an entry match. If so, use the TLB translation.</p> </li> <li> <p>If there was a TLB miss, go check the page tables in memory, and add the translation to the TLB for future use (removing and old one). This is called a \"translation table walk\".</p> </li> </ol>"},{"location":"linker/virtual_memory/#memory-attributes","title":"Memory attributes","text":"<p>There are two main types of memory: The \"RAM\" memory, which hods all the instructions are variables of the current program, and the \"cache\", which is a higher speed, smaller memory space. Most values are written to the cache memory to speed up the code execution. However, sometimes the value in memory can be modified while the cache one don't, producing some read or write mismatches (for example, putting on a cache a register).</p>"},{"location":"linker/virtual_memory/#normal-memory","title":"Normal memory","text":"<p>Accesses can be repeated with no side effects, reading always return the last value written.</p> <p>The shareability properties are:</p> <ul> <li>Non-shareable: accessed by a single processor.</li> <li>Inner shareable: accessed by multiple processors of the same system.</li> <li>Outer shareable: accessed by other systems or peripherals.</li> </ul> <p>The cache properties define how the values are WRITTEN to memory. Reading operations are always done from cache if possible, or from memory otherwise.</p> <ul> <li> <p>Non cacheable: values are only written to the memory.</p> </li> <li> <p>Write through cacheable: writing to cache and memory occur \"simultaneously\", so memory is always coherent.</p> </li> <li> <p>Write back cacheable: the value is only written to the cache. Writing to memory is delayed until the cache gets full and the value needs to be removed from it. The cached value and the memory value might not be the same.</p> </li> <li> <p>Write allocate: save in the cache the address to be written to, if not already in the cache. This is beneficial if multiples operations need to be done on the same address.</p> </li> <li> <p>No write allocate: don't save in the cache the address to be written to.</p> </li> <li> <p>Strongly-ordered memory: An access to the location can cause side effects, or the value returned for a load can vary depending on the number of loads performed (I/O devices, registers). Always shareable.</p> </li> <li> <p>Device memory: same as strongly-ordered, but might not be shareable.</p> </li> <li>Shareable</li> <li>Not shareable</li> </ul>"},{"location":"linker/virtual_memory/#glossary","title":"Glossary","text":"<p>PM: Physical Memory PA: Physical Address VM: Virtual memory VA: Virtual address MMU: Memory Management Unit</p>"},{"location":"linker/virtual_memory/#bibliography","title":"Bibliography","text":"<p>ARMv7 programmer manual</p> <p>Memory types</p>"},{"location":"linters/","title":"Linters and Formatters","text":"<p>In this section we will review the author's choice of the best linters and formatters for each language, and how to set up them both in a local environment and as a CI pipeline.</p> <p>The preferred workflow goes like this:</p> <ol> <li>Work comfortably in your local environment, committing files as normal. The linting tool should be configured in your IDE to either highlight errors or autocorrect them on save.</li> <li>Before pushing code to the remote repository, manually run your linting and formatting tools, if desired.</li> <li>Always set a CI workflow up in the repository with linting and code-style analysis.</li> </ol> <p>Please review the guide for setting up the linter and formatter for each language in the following table. Then, the next sections discuss some of the author's personal opinions on this topic.</p>"},{"location":"linters/#general-vs-code-settings","title":"General VS Code settings","text":"<p>To be able to use auto-formatters in VS Code, you need to configure your file saving strategy to anything but <code>\"files.autoSave\": \"afterDelay\"</code>. Auto-formatters can still run after pressing manually <code>Ctrl + s</code>, but they won't run on autosaves.</p> <p>Therefore, the recommended setting is to use <code>\"files.autoSave\": \"onFocusChange\"</code>.</p>"},{"location":"linters/#vs-code-extension-list","title":"VS Code extension list","text":"Extension Author Code Spell Checker streetsidesoftware.com GitHub Actions github.com Trailing Spaces Shardul Mahadik"},{"location":"linters/#why-pre-commit-or-pre-push-hooks-arent-recommended","title":"Why pre-commit or pre-push hooks aren't recommended","text":"<p>Pre-commit hooks discourage making small incremental commits, because the linter and formatter need to run on every commit. Besides, if your local environment has any issues, they block you from being able to commit. Also, they can take quite some time to execute, and it's normally better to leave this job to the CI pipeline.</p>"},{"location":"linters/#why-githubs-super-linter-is-a-bad-idea","title":"Why Github's super-linter is a bad idea","text":"<p>GitHub's super-linter is a great tool, but it does too many things and you lose control on what it is doing. It bundles a whole bunch of linters for different languages and runs them all on your repository.</p> <p>The problem with this approach is that you ideally want to have the linter and formatter installed in your local environment, most likely integrated with your IDE, and this tool can only be executed from a Docker container.</p>"},{"location":"linters/c/","title":"C linters","text":"<p>There isn't really \"linting\" when it comes to compiled languages.  They are called static code analyzers, and we will use two: cppcheck and clang-tidy</p> <p>For formatting, we will use clang-format.</p> <p>These tools need to be installed by:</p> <pre><code>sudo apt install clang-format cppcheck clang-tidy\n</code></pre> <p>clangd</p> <p></p>"},{"location":"linters/c/#command-line-integration","title":"Command line integration","text":"<p>The static code analyzers can only be run from the command line.</p>"},{"location":"linters/c/#clang-format-cli","title":"Clang Format CLI","text":"<p>The best way to learn about the options and usage is to just call <code>clang-format --help</code> and read the commands.</p> <p>To format files:</p> <pre><code>clang-format -i --verbose \\\n    $(find . -path ./**build -prune \\\n    -o -path ./venv -prune \\\n    -o -name *.c -print \\\n    -o -name *.h -print \\\n    -o -name *.cpp -print)\n</code></pre> <p>To check for errors in style:</p> <pre><code>clang-format --dry-run --Werror --verbose \\\n    $(find . -path ./**build -prune \\\n    -o -path ./venv -prune \\\n    -o -name *.c -print \\\n    -o -name *.h -print \\\n    -o -name *.cpp -print)\n</code></pre> <p>Note</p> <p>Since <code>clang-format</code> does not support shell expansion for files, we use the <code>find</code> command to search for all <code>.c</code>, <code>.cpp</code> and <code>.h</code> files, excluding the ones found in any <code>build</code> directory or the python <code>venv</code>.</p> <p>You can customize your own style options by creating a <code>.clang-format</code> file in the root of the repository, as specified in the Clang-Format Style Options.</p> <p>Down below the recommended <code>.clang-format</code> file to be used is shown: you base your style on one of the predefined ones, and then tweak as you like.</p> <pre><code>BasedOnStyle:  LLVM\nIndentWidth: 4\n</code></pre> <p>To get the full style configuration from one of the main references, you can execute:</p> <pre><code>clang-format -style=llvm -dump-config &gt; .clang-format\n</code></pre>"},{"location":"linters/c/#clang-tidy-cli","title":"Clang Tidy CLI","text":""},{"location":"linters/c/#cppcheck-cli","title":"CppCheck CLI","text":"<p>The best way to learn about cppcheck is to just execute <code>cppcheck</code> and see all the command line options.</p> <p>The recommended execution command is as follows:</p> <pre><code>cppcheck --cppcheck-build-dir=&lt;build/cppcheck&gt; --check-level=&lt;normal | exhaustive&gt; --enable=all --disable=information --error-exitcode=1 -I &lt;header_dir&gt; .\n</code></pre> <p>Where:</p> <ul> <li><code>--cppcheck-build-dir</code>: By specifying a build dir, cppcheck stores artifacts for faster re-runs. This flag shouldn't be used in a CI runner.</li> <li><code>--check-level=&lt;normal | exhaustive&gt;</code>: Use \"normal\" for everyday, use \"exhaustive\" for CI.</li> <li><code>--enable=all</code>: Enable all checks.</li> <li><code>--disable=information</code>: Disable the \"information check\", which reports about cppcheck usage, not the code.</li> <li><code>--error-exitcode=1</code>: If any error is reported by cppcheck, return this exit code (by default, cppcheck always returns '0').</li> <li><code>-I</code>: Include header directories.</li> <li><code>.</code>: Will check from this path recursively all C source files.</li> </ul> <p>For any more details, go check the Cppcheck manual.</p>"},{"location":"linters/c/#vs-code-integration","title":"VS Code integration","text":"<p>Only the formatter can be integrated, since the static code analyzers need to be run specifically from the command line.</p> <p></p> <p>After installing the clang-format VS Code extension, add the following to the <code>.vscode/settings.json</code> file:</p> <pre><code>{\n    \"files.autoSave\": \"onFocusChange\",\n    \"editor.formatOnSave\": true,\n    \"editor.formatOnPaste\": true,\n    \"editor.formatOnSaveMode\": \"file\",\n    \"clang-format.style\": \"file\",\n    \"clang-format.fallbackStyle\": \"LLVM\",\n    \"[c]\": {\n        \"editor.defaultFormatter\": \"xaver.clang-format\"\n    },\n    \"[cpp]\": {\n        \"editor.defaultFormatter\": \"xaver.clang-format\"\n    },\n}\n</code></pre> <p>The extension is going to search for a <code>.clang-format</code> file in the root of the folder you have open with VS Code. If it doesn't find it, it will use the LLVM style by default.</p>"},{"location":"linters/c/#ci-integration","title":"CI integration","text":"<p>Normally, these tools are included in your compilation environment, so calling the formatter and static code analyzers are steps included in the build CI. Just for completeness, this is how a CI would look like:</p>"},{"location":"linters/latex/","title":"Latex","text":"<p>In this guide we will see how to setup a Latex environment to work with VSCode, and some troubleshooting.</p>"},{"location":"linters/latex/#installation","title":"Installation","text":"<p>First, install the VS Code extension:</p> <p></p> <p>You can see the latex compiler output in VSCode in the console menu within \"OUTPUT-&gt;LaTeX Workshop\"</p> <p>You MUST install TeX Live to compile Latex. Follow the instructions in the texlive page.</p> <p>https://www.tug.org/texlive/</p> <p>https://www.tug.org/texlive/quickinstall.html</p> <p>WARNING: This installation may take several hours.</p> <p></p> <p>After the installation is finished, remember to add the installation path to your PATH variable:</p> <pre><code>cd /tmp\nwget https://mirror.ctan.org/systems/texlive/tlnet/install-tl-unx.tar.gz\nzcat &lt; install-tl-unx.tar.gz | tar xf -\ncd install-tl-2*\nsudo perl ./install-tl --no-interaction\necho \"export PATH=\\\"/usr/local/texlive/$(date +%Y)/bin/$(uname -m)-$(uname -s | tr [:upper:] [:lower:]):\\${PATH}\\\"\" &gt;&gt; ~/.bashrc\n</code></pre> <pre><code>/usr/local/texlive/$(date +%Y)/bin/$(uname -m)-$(uname -s | tr [:upper:] [:lower:])\n</code></pre>"},{"location":"linters/latex/#usage","title":"Usage","text":"<pre><code>{\n    \"files.autoSave\": \"onFocusChange\",\n\n    \"[latex]\": {\n        \"editor.wordWrap\": \"wordWrapColumn\",\n        \"editor.wordWrapColumn\": 80,\n    },\n    \"latex-workshop.latex.outDir\": \"build\",\n    \"latex-workshop.latex.magic.args\": [\n        \"-output-directory=build\", // to change the output directory\n        \"%DOC%\",\n    ],\n}\n</code></pre>"},{"location":"linters/latex/#troubleshoot","title":"Troubleshoot","text":"<p>Recipe terminated with fatal error: spawn latexmk ENOENT.</p> <p>This error happens because you didn't install Latex.</p>"},{"location":"linters/markdown/","title":"MarkDown linters","text":"<p>Markdownlint has a list of <code>MDxxx</code> rules that should be followed. By default, it shows a wabbly line underneath every mistake, with an explanation of the rule being broken.</p> <p></p> <p>The following is the suggested configuration for this extension:</p> <ul> <li>Wraps words up to 80 columns.</li> <li>Auto-formats files on save (either with <code>Ctrl + s</code> or on focus change).</li> <li>Allows to define a configuration file at <code>.vscode/.markdownlint.json</code> to personalize the linting rules.</li> </ul> <pre><code>{\n    \"files.autoSave\": \"onFocusChange\",\n\n    \"markdownlint.configFile\": null, // \".vscode/.markdownlint.json\",\n    \"[markdown]\": {\n        \"editor.wordWrap\": \"wordWrapColumn\",\n        \"editor.wordWrapColumn\": 80,\n        \"editor.formatOnSave\": true,\n        \"editor.formatOnPaste\": true,\n        \"editor.formatOnSaveMode\": \"file\",\n        \"editor.defaultFormatter\": \"DavidAnson.vscode-markdownlint\"\n    },\n}\n</code></pre>"},{"location":"linters/markdown/#markdown-ci","title":"MarkDown CI","text":"<p>The markdownlint-cli-action is a GitHub action developed by the creator of markdownlint.</p> <p>A basic CI that does MarkDown linting on the whole repository looks like this:</p> <pre><code>name: Markdown Linter\non: [push, pull_request]\njobs:\n  markdown_linter:\n    runs-on: ubuntu-latest\n    env:\n      CONFIG_FILE: '.vscode/.markdownlint.json'\n    steps:\n      - name: \"Checkout repo\"\n        uses: actions/checkout@v5\n\n      - name: Create config file if it does not exist # (1)!\n        if: ${{ !hashFiles(env.CONFIG_FILE) }}\n        run: |\n          echo \"{\\\n            \\\"default\\\": true,\\\n            \\\"MD013\\\": false\\\n            }\" &gt; \"$CONFIG_FILE\"\n\n      - name: \"Markdown linter\"\n        uses: DavidAnson/markdownlint-cli2-action@v20\n        with:\n          globs: \"**/*.md\"\n          config: ${{ env.CONFIG_FILE }}\n</code></pre> <ol> <li>By default MD013, the line length rule, is enabled in the CI runner. Create a default configuration file to disable it.</li> </ol>"},{"location":"linters/python/","title":"Python linters","text":"<p>Ruff is a Python linter and formatter written in Rust.</p>"},{"location":"linters/python/#vs-code-integration","title":"VS Code integration","text":"<p>In the Ruff VS Code extension you can find the recommended configuration for the <code>.vscode/settings.json</code> file to enable automatic linting and formatting on file save:</p> <pre><code>{\n    \"[python]\": {\n        \"editor.formatOnSave\": true,\n        \"editor.formatOnPaste\": true,\n        \"editor.formatOnSaveMode\": \"file\",\n        \"editor.codeActionsOnSave\": {\n            \"source.fixAll\": \"always\",\n            \"source.organizeImports\": \"always\"\n        },\n        \"editor.defaultFormatter\": \"charliermarsh.ruff\"\n    },\n}\n</code></pre> <p></p> <p></p>"},{"location":"linters/python/#modifying-linting-and-formatting-rules","title":"Modifying linting and formatting rules","text":"<p>By default, Ruff doesn't have too much linting rules enabled. For example, it doesn't enforce arguments types and return values in functions.</p> <p>The recommended way of configuring Ruff is to enable all rules, and ignore the ones you don't really need. Create a <code>ruff.toml</code> file in the root directory of your repository, and fill it with something like this:</p> <pre><code>line-length = 80\nindent-width = 4\n\n[lint]\n\nselect = [\"ALL\"]\nignore = [\n    \"D203\", # Space for first line of docstring\n    \"D213\"  # First line of docstring on new line\n]\n\n[format]\nquote-style = \"double\"\nindent-style = \"space\"\n</code></pre> <p>You can ignore rules in a file-basis by adding a <code># noqa: &lt;rule&gt;</code> comment in the violating line as such:</p> <pre><code># D103 requires to have a docstring in the function.\ndef my_function() -&gt; None:  # noqa: D103\n    pass\n</code></pre>"},{"location":"linters/python/#ci-integration","title":"CI integration","text":"<p>In the Integrations section of the Ruff's documentation there are examples of CI workflows.</p> <p>Specifically, you can use the GitHub Action ruff-action as follows:</p> <pre><code>name: Python linter\non: [ push, pull_request ]\njobs:\n  ruff:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v5\n      - uses: astral-sh/ruff-action@v3\n</code></pre>"},{"location":"linters/python/#command-line-usage","title":"Command line usage","text":"<p>Since Ruff is a Python PIP package, it can be installed with:</p> <pre><code>pip install ruff\n</code></pre> <p>Then, files can be linted and formatted with the following commands:</p> <pre><code>ruff check [OPTIONS] [FILES]\nruff format [OPTIONS] [FILES]\n</code></pre> <p>If no files are given, these commands will check every Python file recursively from the current directory.</p>"},{"location":"mkdocs/","title":"MkDocs: The winner of static site documentation","text":"<p>As the time of writing this article, there were three main contenders:</p> <ol> <li> <p>MkDocs, specifically with Material theme.</p> </li> <li> <p>Sphinx.</p> </li> <li> <p>Docusaurus.</p> </li> </ol> <p>First, let's start by reviewing the pros and cons of each one, so that it's clear why MkDocs is the best of them all.</p>"},{"location":"mkdocs/#a-review-of-documentation-frameworks","title":"A review of documentation frameworks","text":""},{"location":"mkdocs/#sphinx-pythonic-with-restructuredtext","title":"Sphinx: pythonic with reStructuredText","text":"<p>Sphinx was made to be used with reStructuredText (rst). You can use Markdown as well, but rst is preferred. Also, it is mainly used for Python documentation.</p> <p>Personally, I don't really like the style of Sphinx documentation, since 95% of the time is used together with ReadTheDocs, being great examples the ReadTheDocs documentation itself or MicroPython docs.</p>"},{"location":"mkdocs/#docusaurus-better-for-web-developers","title":"Docusaurus: better for web developers","text":"<p>Docusaurus is really good looking, that can't be denied. The problem is its complexity: it is built upon Javascript and React. You can use Markdown to write your documentation, but you won't be able to utilize its full potential without having a background in React.</p>"},{"location":"mkdocs/#mkdocs-markdown-and-good-looking","title":"MkDocs: Markdown and good-looking","text":"<p>MkDocs is a simple and effective tool. Fully focused on Markdown, made with Python, and with the ability to locally host a server to see changes in the documentation in real time.</p> <p>The default theme for MkDocs is not great, but the Material theme is really good-looking.</p>"},{"location":"mkdocs/#setting-up-mkdocs","title":"Setting up MkDocs","text":"<p>First, install the <code>mkdocs</code> package in a virtual environment, and create a new mkdocs project in the current directory:</p> <pre><code>python3 -m venv venv\nsource venv/bin/activate\npip install mkdocs mkdocs-material\nmkdocs new .\n</code></pre> <p>That will create the <code>docs</code> folder and the <code>mkdocs.yml</code> file. After that, you can serve the documentation page in your local host with:</p> <pre><code>mkdocs serve --livereload\n</code></pre> <p>Finally, utilize the material theme by adding the following lines to the <code>mkdocs.yml</code> file:</p> <pre><code>theme:\n  name: material\n</code></pre> <p>More details can be found in the MkDocs getting started.</p>"},{"location":"mkdocs/#using-mkdocs","title":"Using MkDocs","text":"<p>The best to use MkDocs is a demand-based approach: when you want to do something specific, consult either the MkDocs docs or the Material docs.</p>"},{"location":"mkdocs/deployment/","title":"Documentation deployment","text":"<p>This guide shows you how to deploy your documentation online using different tools. Using GitHub pages is preferred, so it is shown first.</p>"},{"location":"mkdocs/deployment/#github-pages","title":"GitHub Pages","text":"<p>MkDocs has an in-built command to deploy to GitHub Pages: <code>mkdocs gh-deploy</code>. You can use this command on a CI in the same way as this documentation gets deployed, by copying the GitHub Action for MkDocs deployment.</p> <p>A new branch <code>gh-pages</code> will be created in your repository to host the documentation's webpage.</p>"},{"location":"mkdocs/deployment/#using-a-custom-domain","title":"Using a custom domain","text":"<p>By default, GitHub will assign the URL <code>https://&lt;github_username&gt;.github.io/&lt;repo_name&gt;/</code> to your page. To change it... TODO</p>"},{"location":"mkdocs/deployment/#readthedocs","title":"ReadTheDocs","text":"<p>Setting ReadTheDocs is quite easy, only two steps are needed:</p> <ol> <li> <p>Create a <code>.readthedocs.yaml</code> in the root of the repository like this one:</p> <pre><code>version: 2\n\nbuild:\nos: \"ubuntu-24.04\"\ntools:\n    python: \"3\"\njobs:\n    pre_install:\n    - pip install mkdocs-material\n\nmkdocs:\nconfiguration: mkdocs.yml\n</code></pre> </li> <li> <p>Create a ReadTheDocs account, log in, and create a new project pointing to the name of your repository.</p> </li> </ol> <p>However, having a separate account and using a different tool outside of GitHub or GitLab seems clunky, so I prefer to avoid this and leverage a full CI/CD pipeline with GitHub Pages.</p> <p>For more info, check the ReadTheDocs docs on MkDocs.</p>"},{"location":"pcb/common_circuits/","title":"Common electrical circuits","text":"<p>In this section I will describe some common electrical circuits and mathematical formulas involved.</p> <p>Before starting, I will say this only once: MOSFET &gt; BJT.</p> <p>BJT are easier to use, but:</p> <ul> <li>Require a base current to operate, making the IC consume more power.</li> <li>Have lower switching speeds, therefore consuming more power.</li> <li>Have lower maximum current thresholds.</li> </ul> <p>Ready, I said it. Moving on...</p>"},{"location":"pcb/common_circuits/#todo","title":"TODO","text":"<p>Digilent Pmod Interface Specification</p>"},{"location":"pcb/common_circuits/#choosing-mosfets","title":"Choosing MOSFETs","text":"<p>Discrete MOSFET's parameters are seldom given as an exact number, but rather as a range, or must deduced from a poor quality graph.</p> <p>My personal recommendation for the parameters is to get the typical values at 25\u00b0C, and do the worst case and best case calculations, and see if both cases can be tolerated.</p> <p>Let's look at a real example.</p> <p></p> <p></p>"},{"location":"pcb/common_circuits/#gpio-drivers","title":"GPIO drivers","text":"<p>A GPIO driver utilizes a transistor to drive a load using the power from an external source, instead of the power from the GPIO pin. We will make the distinction between the polarity of the GPIO pin:</p> <ul> <li>Positive GPIO driver: the load is energized when the GPIO pin is electrically \"HIGH\".</li> <li>Negative GPIO driver: the load is energized when the GPIO pin is electrically \"LOW\".</li> </ul>"},{"location":"pcb/common_circuits/#positive-gpio-driver","title":"Positive GPIO driver","text":"<p>Let it be a circuit as the one shown below: with the GPIO pin connected to the gate of an NMOS transistor. The load is composed of a bias resistor and a voltage source, a typical LED driver.</p> <p></p> <p>The objective is to choose \\(R_S\\) such as there is a desired drain current \\(I_D\\) through the load. Starting from the drain current equation for a saturated MOSFET:</p> \\[I_D = \\frac{1}{2} \\cdot k_p \\cdot (V_{GS} - V_{TH})^2\\] <p>Let it be: \\(V_{GS} = V_{GPIO} - I_D \\cdot R_S - V_L\\). Replacing...</p> \\[I_D = \\frac{1}{2} \\cdot k_p \\cdot (V_{GPIO} - I_D \\cdot R_S - V_L - V_{TH})^2\\] <p>By rearranging that expression, one gets:</p> \\[R_S = \\frac{V_{GPIO} - V_L - V_{TH} - \\sqrt{\\frac{I_D \\cdot 2}{k_p}}}{I_D}\\] <p>Both conditions for cutoff and saturation should be checked. For this configuration, the device is always saturated, assuming the worst case scenario, where \\(V_{DD} = V_{GPIO}\\):</p> \\[V_{DS} &gt; V_{OV}\\] \\[V_{DD} - V_S &gt; V_{DD} - V_S - V_{TH}\\] \\[ 0 &gt; - V_{TH}\\] <p>Which is always true. For cutoff:</p> \\[ V_{OV} &gt; 0 \\] \\[ V_{GS} - V_{TH} &gt; 0 \\] \\[ V_{GPIO} - I_D \\cdot R_S - V_L - V_{TH} &gt; 0 \\] <p>By using a PMOS at the output and an NMOS to invert the input, you can use \\(V_{DD}\\) instead of \\(V_{GPIO}\\) in the current equation and the cutoff inequation, in the case that the latter is not met.</p> <p></p> <p>The value of the \\(R_1\\) resistor must be as high as possible, but at least an order of magnitude less than the \\(M2\\) cutoff resistance \\(R_{Doff}\\). Otherwise, the actual tension at the gate of M1 will be given by a resistor divider, not the source.</p>"},{"location":"pcb/common_circuits/#negative-gpio-driver","title":"Negative GPIO driver","text":"<p>By using a PMOS instead of an NMOS, you can drive the load with a \\(V_{GPIO}=0V\\).</p> <p></p> <p>This driver already uses \\(V_{DD}\\) as the source, but you may want to use exclusively NMOS, as shown below:</p> <p></p>"},{"location":"qemu/","title":"QEMU","text":"<p>The Quick EMUlator (QEMU) performs system emulation, i.e. allows you to run a completely different CPU architecture (such as ARM, MIPS, RISC-V, AVR, etc) with a different OS than those of the host machine.</p> <p>Check the list of supported guest architectures.</p> <p>QEMU is the most suitable for running pre-configured boards, not custom hardware or boards. I will comment on this briefly but first, let's take a look on how to run a simple simulation for bare-metal and embedded Linux.</p> <p>For each type of machine architecture, e.g ARM, RISC-V, AVR, etc; QEMU has its own QEMU System Emulator Target or binary. For example, <code>qemu-system-arm</code>, <code>qemu-system-avr</code> or <code>qemu-system-riscv32</code>.</p> <p>After choosing the architecture, the next step is to choose the board model. Let's look at the example of ARM, since most architectures behave similarly, and we will see why QEMU does not support custom boards.</p> <p>As quoted from the documentation \"you must specify which board model you want to use with <code>-M</code> or <code>--machine</code>; there is no default\". And then, it says: \"check whether QEMU lists that machine [...]. If it is listed, then you can probably use that board model. If it is not listed, then unfortunately your image will almost certainly not boot on QEMU.\"</p> <p>Therefore, the documentation is clearly stating that if your code can't run on any of the predefined board models, then it won't run on QEMU. The documentation does not provide any links to a section about modeling your own boards.</p> <p>Each board has a set of predefined devices simulated, as can be seen, for example, for the Raspberry Pi boards or the ARM Realview Boards.</p>"},{"location":"qemu/#some-example-runs","title":"Some example runs","text":"<p>The list of command line arguments.</p> <p>The most important ones are:</p> <ul> <li> <p><code>-machine|-M &lt;board&gt;</code>: Select which board to use. Consult list with <code>qemu-system-arm -machine help</code>.</p> </li> <li> <p><code>-m &lt;mem_size&gt;&lt;M|G&gt;</code>: Set startup RAM size in Megabytes <code>M</code> or Gigabytes <code>G</code>.</p> </li> <li> <p><code>-nographic</code>: Disable graphical output, redirecting the emulated serial port to the console.</p> </li> <li> <p><code>-serial &lt;dev&gt;</code>: Redirects the virtual serial port to host character device <code>dev</code>. By default it goes to <code>stdio</code>. Some options are:</p> </li> <li> <p><code>stdio</code>: Standard input/output.</p> </li> <li><code>file:&lt;filename&gt;</code>: Write output to filename. No character can be read.</li> <li><code>tcp:&lt;host_ip&gt;&lt;host_port&gt;[,server=on]</code>: Connect to a TCP socket. By default, it sends data to the specified IP and port, unless <code>server=on</code> is specified, where QEMU will halt until a connection is established from a client.</li> <li><code>telnet:&lt;host_ip&gt;&lt;host_port&gt;[,server=on]</code> Same as tcp, but with the telnet protocol.</li> <li> <p><code>null</code>: Equivalent to redirecting to <code>/dev/null</code>.</p> </li> <li> <p><code>-monitor &lt;dev&gt;</code>: Redirect the QEMU monitor to host device \"dev\". Same options as with \"serial\". More on the QEMU monitor later.</p> </li> <li> <p><code>-S</code>: Do not start CPU at startup (you must type \"c\" in the monitor)</p> </li> <li> <p><code>-S -gdb &lt;dev&gt;</code>: Accepts a gdb connection on device \"dev\". To halt execution until a gdb connection is established, use <code>-S</code> as well.</p> </li> <li> <p><code>-no-reboot</code>: Exit instead of rebooting.</p> </li> <li> <p><code>-kernel &lt;bzImage&gt;</code>. Use bzImage as kernel image.</p> </li> <li> <p><code>-append &lt;cmdline&gt;</code>: Use cmdline as kernel command line.</p> </li> <li> <p><code>-initrd &lt;file&gt;</code>: Use file as initial ram disk.</p> </li> <li> <p><code>-dtb &lt;file&gt;</code>: Use file as a device tree binary (dtb) image and pass it to the kernel on boot.</p> </li> <li> <p><code>-device loader,addr=&lt;addr&gt;,data=&lt;data&gt;,data-len=&lt;data_len&gt;</code>: Load data in address.</p> </li> </ul> <p>TODO</p> <p>https://www.qemu.org/docs/master/system/generic-loader.html</p> <pre><code>qemu-system-arm -machine realview-pb-a8\n</code></pre> <pre><code>coproc qemu-system-arm \\\n    -M realview-pb-a8 \\\n    -m 32M \\\n    -no-reboot -nographic \\\n    -monitor telnet:127.0.0.1:1234,server,nowait \\\n    -S -gdb tcp::2159 \\\n    -kernel ${bin_file} &amp;&gt;/dev/null\n</code></pre>"},{"location":"qemu/baremetal_bootloaders/","title":"Baremetal bootloaders","text":"<p>After doing a lot of research on the topic, it seems that there are only two alternatives when it comes to simple bare-metal designs:</p> <ol> <li> <p>Write your own bootloader from scratch.</p> </li> <li> <p>Use a vendor IDE that already has the bootloader written.</p> </li> </ol> <p>I will shortly demonstrate this approach coming from different vendors, but the core of this article is about writing your own bootloaders, to avoid being shackled to a vendor IDE.</p> <p>TL;DR: vendor IDEs are \"too generic\". If you know your micro or board well, then yuo should be able to customize everything to your needs. When something is too generic, it is prone to faults and bad optimizations.</p>"},{"location":"qemu/baremetal_bootloaders/#case-studies-of-vendor-ides","title":"Case studies of vendor IDEs","text":""},{"location":"qemu/baremetal_bootloaders/#stm32cubeide","title":"STM32CUBEIDE","text":"<p>Files generated when created a project are in the folder.</p>"},{"location":"qemu/baremetal_bootloaders/#arduino-ide","title":"Arduino IDE","text":"<p>The case of the Arduino bootloader is quite special.</p> <p>When writing code from the Arduino IDE, the bootloader is expected to already be installed by default. The Arduino boards have a USB-to-Serial chip, and the bootloader receives the code through the UART, writes those bits to the FLASH memory, and then executes.</p> <p>Arduino won't share a copy of its bootloader and Linker script, but we can find an alternative:</p> <p>https://github.com/Optiboot/optiboot/tree/master</p>"},{"location":"qemu/baremetal_bootloaders/#platformio","title":"PlatformIO","text":"<p>From PlatformIO</p> <p>https://github.com/platformio/platform-ststm32/tree/develop/examples/stm32cube-hal-blink</p> <p>After running the steps, we can find the linker script and the bootloader files. They have been copied to the folder.</p> <p>Toolchain:</p> <p>~/.platformio/packages/toolchain-gccarmnoneeabi</p> <p>Linker:</p> <p>/home/nicolas.cotti/.platformio/packages/tool-ldscripts-ststm32/stm32f4/STM32F401RETX_FLASH.ld</p> <p>Bootloader:</p> <p>/home/nicolas.cotti/.platformio/packages/framework-stm32cubef4/Drivers/CMSIS/Device/ST/STM32F4xx/Source/Templates/gcc/startup_stm32f401xe.S</p>"},{"location":"qemu/bootloader/","title":"Bootloaders","text":"<p>Das U-Boot.</p> <p>Download Github. Checkout last release</p> <pre><code>git clone https://github.com/u-boot/u-boot.git\n# release is v&lt;year&gt;.&lt;month&gt;\ngit checkout v2026.01\n</code></pre> <p>First we need to build U-Boot.</p> <p>For that, look at the default configuration files for boards under the <code>configs/</code> directory. Find the most \"similar\" one and then run:</p> <pre><code>make &lt;board_name&gt;_defconfig\n</code></pre> <p>Dont' find your specific board? Try using the \"qemu-*\" ones.</p> <p>For the realview board:</p> <pre><code>make qemu_arm_defconfig\n</code></pre> <p>Then, we are presented with the <code>make nconfig</code> GUI menu.</p> <p>You need to build it with your cross-compiler.</p>"},{"location":"qemu/cross_compiling/","title":"Cross Compiling","text":"<p>Bootlin's Embedded Linux Training</p> <p>Cross compilation is one of the four main tools that any embedded Linux developer needs.</p> <p></p> <p></p> <p>The Binutils is a set of tools to generate and manipulate binaries (usually with the ELF format) for a given CPU architecture. They include tools such as the assembler <code>as</code>, linker <code>ld</code>, <code>objcopy</code>, <code>objdump</code>, etc.</p> <p>A toolchain is identified by a tuple like:</p> <pre><code>&lt;arch&gt;-&lt;OS&gt;-&lt;ABI&gt;\n&lt;arch&gt;-&lt;vendor&gt;-&lt;OS&gt;-&lt;ABI&gt;\n</code></pre>"},{"location":"qemu/cross_compiling/#getting-the-toolchain","title":"Getting the toolchain","text":"<p>There are three approaches to getting a cross-compilation toolchain:</p> <ol> <li> <p>Getting a pre-compiled toolchain, such as the Bootlin's toolchains or Linaro's toolchains. This is the simplest and most convenient solution, but you can't fine tune the toolchain to your needs.</p> </li> <li> <p>Building the toolchain as a part of a build system, such as Buildroot or Yocto Project. This approach has its own section.</p> </li> <li> <p>Using Crosstool-NG</p> </li> </ol>"},{"location":"qemu/cross_compiling/#crosstool-ng","title":"Crosstool-NG","text":"<p>Crosstool-NG aims at building toolchains. Nothing more, nothing less. It is quite straightforward to install and use, provided that you know what you need from your toolchain.</p> <p>I suggest reading the documentation, but here is a TL,DR:</p>"},{"location":"qemu/cross_compiling/#installation","title":"Installation","text":"<pre><code>VERSION=\"1.28.0\"\nwget \"http://crosstool-ng.org/download/crosstool-ng/crosstool-ng-${VERSION}.tar.bz2\"\ntar -xf \"crosstool-ng-${VERSION}.tar.bz2\"\ncd \"crosstool-ng-${VERSION}\"\n\nsudo apt update &amp;&amp; sudo apt install -y \\\n    gcc g++ gperf bison flex texinfo help2man make libncurses-dev \\\n    python3-dev autoconf automake libtool libtool-bin gawk wget bzip2 \\\n    xz-utils unzip patch libstdc++6 rsync git meson ninja-build\n./configure --enable-local\nmake\ncat ./bash-completion/ct-ng &gt;&gt; \"${HOME}/.bashrc\"\n</code></pre>"},{"location":"qemu/cross_compiling/#first-step-configuration","title":"First step configuration","text":"<p>Instead of starting from scratch, the best way to start is to check a similar toolchain, and adapt it to your needs:</p> <pre><code>./ct-ng list-samples\n</code></pre> <pre><code>./ct-ng show-&lt;tuple&gt;\n\n./ct-ng show-arm-none-eabi\n[L...]   arm-none-eabi\n    Languages       : C,C++\n    OS              : bare-metal\n    Binutils        : binutils-2.45\n    Compiler        : gcc-15.2.0\n    Linkers         :\n    C library       : newlib-4.5.0.20241231 picolibc-1.8.10\n    Debug tools     :\n    Companion libs  : gmp-6.3.0 isl-0.27 mpc-1.3.1 mpfr-4.2.2 newlib-nano-4.5.0.20241231 newlib-nano-4.5.0.20241231 zlib-1.3.1 zstd-1.5.7\n    Companion tools :\n\n./ct-ng show-mips-unknown-linux-gnu\n[L...]   mips-unknown-linux-gnu\n    Languages       : C,C++\n    OS              : linux-6.16\n    Binutils        : binutils-2.45\n    Compiler        : gcc-15.2.0\n    Linkers         :\n    C library       : glibc-2.42\n    Debug tools     : duma-2_5_21 gdb-16.3 strace-6.16\n    Companion libs  : expat-2.7.1 gettext-0.26 gmp-6.3.0 isl-0.27 libiconv-1.18 mpc-1.3.1 mpfr-4.2.2 ncurses-6.5 zlib-1.3.1 zstd-1.5.7\n    Companion tools :\n</code></pre> <p>Once a sample was decided as a base, run:</p> <pre><code>./ct-ng &lt;tuple&gt;\n</code></pre> <p>Then you can start making configurations in the usual GUI menu:</p> <pre><code>./ct-ng nconfig\n</code></pre>"},{"location":"qemu/cross_compiling/#second-step-configuration","title":"Second step configuration","text":"<p>Once the default toolchain was selected, is time to fine tune the actual toolchain in the menuconfig. I have done it a few times, there aren't a lot of options and aren't hard to understand, just go one by one.</p> <p>The only hard one mugh be</p> <p>After that, build the toolchain with:</p> <p>' -marm -march=armv5te+fp -mfloat-abi=softfp' --&gt; lib/arm/v5te/softfp (gcc)   lib/arm/v5te/softfp (os) [EXTRA]       ' -marm -march=armv5te+fp -mfloat-abi=hard' --&gt; lib/arm/v5te/hard (gcc)   lib/arm/v5te/hard (os) [EXTRA]       ' -mthumb -mfloat-abi=soft' --&gt; lib/thumb/nofp (gcc)   lib/thumb/nofp (os) [EXTRA]       ' -mthumb -march=armv7 -mfloat-abi=soft' --&gt; lib/thumb/v7/nofp (gcc)   lib/thumb/v7/nofp (os) [EXTRA]       ' -mthumb -march=armv7+fp -mfloat-abi=softfp' --&gt; lib/thumb/v7+fp/softfp (gcc)   lib/thumb/v7+fp/softfp (os) [EXTRA]       ' -mthumb -march=armv7+fp -mfloat-abi=hard' --&gt; lib/thumb/v7+fp/hard (gcc)   lib/thumb/v7+fp/hard (os) [EXTRA]       ' -mthumb -march=armv7-r+fp.sp -mfloat-abi=softfp' --&gt; lib/thumb/v7-r+fp.sp/softfp (gcc)   lib/thumb/v7-r+fp.sp/softfp (os) [EXTRA]       ' -mthumb -march=armv7-r+fp.sp -mfloat-abi=hard' --&gt; lib/thumb/v7-r+fp.sp/hard (gcc)   lib/thumb/v7-r+fp.sp/hard (os) [EXTRA]       ' -mthumb -march=armv7-a -mfloat-abi=soft' --&gt; lib/thumb/v7-a/nofp (gcc)   lib/thumb/v7-a/nofp (os) [EXTRA]       ' -mthumb -march=armv7-a+fp -mfloat-abi=softfp' --&gt; lib/thumb/v7-a+fp/softfp (gcc)   lib/thumb/v7-a+fp/softfp (os) [EXTRA]       ' -mthumb -march=armv7-a+fp -mfloat-abi=hard' --&gt; lib/thumb/v7-a+fp/hard (gcc)   lib/thumb/v7-a+fp/hard (os) [EXTRA]       ' -mthumb -march=armv7-a+simd -mfloat-abi=softfp' --&gt; lib/thumb/v7-a+simd/softfp (gcc)   lib/thumb/v7-a+simd/softfp (os) [EXTRA]       ' -mthumb -march=armv7-a+simd -mfloat-abi=hard' --&gt; lib/thumb/v7-a+simd/hard (gcc)   lib/thumb/v7-a+simd/hard (os) [EXTRA]       ' -mthumb -march=armv7ve+simd -mfloat-abi=softfp' --&gt; lib/thumb/v7ve+simd/softfp (gcc)   lib/thumb/v7ve+simd/softfp (os) [EXTRA]       ' -mthumb -march=armv7ve+simd -mfloat-abi=hard' --&gt; lib/thumb/v7ve+simd/hard (gcc)   lib/thumb/v7ve+simd/hard (os) [EXTRA]       ' -mthumb -march=armv8-a -mfloat-abi=soft' --&gt; lib/thumb/v8-a/nofp (gcc)   lib/thumb/v8-a/nofp (os) [EXTRA]       ' -mthumb -march=armv8-a+simd -mfloat-abi=softfp' --&gt; lib/thumb/v8-a+simd/softfp (gcc)   lib/thumb/v8-a+simd/softfp (os) [EXTRA]       ' -mthumb -march=armv8-a+simd -mfloat-abi=hard' --&gt; lib/thumb/v8-a+simd/hard (gcc)   lib/thumb/v8-a+simd/hard (os) [EXTRA]       ' -mthumb -march=armv6s-m -mfloat-abi=soft' --&gt; lib/thumb/v6-m/nofp (gcc)   lib/thumb/v6-m/nofp (os) [EXTRA]       ' -mthumb -march=armv7-m -mfloat-abi=soft' --&gt; lib/thumb/v7-m/nofp (gcc)   lib/thumb/v7-m/nofp (os) [EXTRA]       ' -mthumb -march=armv7e-m -mfloat-abi=soft' --&gt; lib/thumb/v7e-m/nofp (gcc)   lib/thumb/v7e-m/nofp (os) [EXTRA]       ' -mthumb -march=armv7e-m+fp -mfloat-abi=softfp' --&gt; lib/thumb/v7e-m+fp/softfp (gcc)   lib/thumb/v7e-m+fp/softfp (os) [EXTRA]       ' -mthumb -march=armv7e-m+fp -mfloat-abi=hard' --&gt; lib/thumb/v7e-m+fp/hard (gcc)   lib/thumb/v7e-m+fp/hard (os) [EXTRA]       ' -mthumb -march=armv7e-m+fp.dp -mfloat-abi=softfp' --&gt; lib/thumb/v7e-m+dp/softfp (gcc)   lib/thumb/v7e-m+dp/softfp (os) [EXTRA]       ' -mthumb -march=armv7e-m+fp.dp -mfloat-abi=hard' --&gt; lib/thumb/v7e-m+dp/hard (gcc)   lib/thumb/v7e-m+dp/hard (os) [EXTRA]       ' -mthumb -march=armv8-m.base -mfloat-abi=soft' --&gt; lib/thumb/v8-m.base/nofp (gcc)   lib/thumb/v8-m.base/nofp (os) [EXTRA]       ' -mthumb -march=armv8-m.main -mfloat-abi=soft' --&gt; lib/thumb/v8-m.main/nofp (gcc)   lib/thumb/v8-m.main/nofp (os) [EXTRA]       ' -mthumb -march=armv8-m.main+fp -mfloat-abi=softfp' --&gt; lib/thumb/v8-m.main+fp/softfp (gcc)   lib/thumb/v8-m.main+fp/softfp (os) [EXTRA]       ' -mthumb -march=armv8-m.main+fp -mfloat-abi=hard' --&gt; lib/thumb/v8-m.main+fp/hard (gcc)   lib/thumb/v8-m.main+fp/hard (os) [EXTRA]       ' -mthumb -march=armv8-m.main+fp.dp -mfloat-abi=softfp' --&gt; lib/thumb/v8-m.main+dp/softfp (gcc)   lib/thumb/v8-m.main+dp/softfp (os) [EXTRA]       ' -mthumb -march=armv8-m.main+fp.dp -mfloat-abi=hard' --&gt; lib/thumb/v8-m.main+dp/hard (gcc)   lib/thumb/v8-m.main+dp/hard (os)</p>"},{"location":"qemu/cross_compiling/#newlib-embedded-c-libray","title":"Newlib: embedded C libray","text":"<p>Newlib is a a more compact version of the C library specially designed for embedded systems.</p> <p>You can use a great subset of the C library functions, provided that you implement the System Calls (syscalls). In the documentation there is a list of all the syscalls and the required syscalls for each function.</p> <p>You don't need to provide a full implementation if, for example, you don't support filesystems, but at least a mock implementation must be provided to link to the library.</p> <p>Check the initialization script \"crt0.S\", and the linker flag that supress it. It could be a great example of bootloader.</p> <p>Explain why linking directly with \"ld\" is a bad idea.</p> <p>Linking everything together... arm-cotti-eabi-gcc: fatal error: environment variable 'GCC_EXEC_PREFIX' not defined</p> <p>Move the toolchain to anywhere else from its default location</p>"},{"location":"qemu/cross_compiling/#some-examples","title":"Some examples","text":""},{"location":"qemu/cross_compiling/#realview-pb-a8","title":"Realview pb a8","text":"<p>realview-pb-a8       ARM RealView Platform Baseboard for Cortex-A8</p> <p>[RealView Platform Baseboard for Cortex-A8][https://developer.arm.com/documentation/dui0417/d]</p> <p>When looking at the memory map of the device, we find that the address <code>0x7000_0000-0x7FFF_FFFF</code> is an SDRAM, that is also a mirror of the <code>0x0000_0000-0xFFFF_FFFF</code>, so writing to any of these two is equivalent.</p> <p>Because we are dealing with a Cortex-A8, the architecture expects to see a vector table at address <code>0x0000_0000</code> like this:</p> <p>For the cortex A8 of the realview in baremetal, the closest choice is:</p> <pre><code>\n</code></pre> <p>TODO</p> <p>El problema ac\u00e1 es que no quiero escribir una aplicaci\u00f3n baremetal en assembler, quiero probar mi toolchain con algo en C. Necesito un bootloader sencillito.</p> <p>[realview_user_manual]</p>"},{"location":"qemu/renode/","title":"Renode","text":"<p>Renode</p>"},{"location":"testing/gtest/","title":"GoogleTest","text":"<p>GoogleTest (gtest) is a tool for unit and integration testing for C++ code. Only available with the CMake buildsystem.</p>"},{"location":"testing/gtest/#how-to-setup","title":"How to setup","text":"<p>As shown in the Quickstart Guide, first prepare a <code>CMakeLists.txt</code> file, including the gtest dependency. After that, a standard CMake project can be built with the following commands:</p> <pre><code>mkdir build\ncd build\ncmake ..\ncmake --build .\n</code></pre> <p>And the tests can be executed with:</p> <pre><code>ctest\n</code></pre>"},{"location":"testing/gtest/#gtest-api-reference","title":"Gtest API reference","text":"<p>In a test file, the include the header <code>#include \"gtest/gtest.h\"</code>. Test functions are declared with the <code>TEST</code> macro with two arguments: The name of the group of tests, and the name of the individual test:</p> <pre><code>TEST(GroupTestName, TestName) {}\n</code></pre> <p>After that, the test is normal C++ code, where you can call the assertion functions to check whether your code behaves as expected.</p> <pre><code>EXPECT_EQ(first_expression, second_expression);\nEXPECT_TRUE(expression);\nEXPECT_FALSE(expression);\nEXPECT_STREQ(first_string, second_string);\nEXPECT_THROW(expression, error_to_be_catched_in_a_try_catch)\n</code></pre> <p>The difference between <code>ASSERT_X</code> and <code>EXPECT_X</code> functions is that the former stops execution if the condition is not met, while the latter continues until the end of the test.</p>"}]}